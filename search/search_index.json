{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"AXIS","text":"<p>Agent X-Ray Interface &amp; Statistics</p> <p>AXIS gives AI teams full visibility into model quality \u2014 from evaluation to production monitoring \u2014 so they can ship better models faster. Built as the visualization layer for the AXION evaluation engine, AXIS turns raw evaluation data into actionable insights through interactive dashboards, human-in-the-loop workflows, and real-time observability.</p> <p> Get started  View on GitHub</p>"},{"location":"#why-axis","title":"Why AXIS?","text":""},{"location":"#comprehensive","title":"Comprehensive","text":"<p>11 integrated modules covering the full AI evaluation lifecycle \u2014 from batch evaluation and scoring to production monitoring, calibration, annotation, and decision memory.</p>"},{"location":"#configurable","title":"Configurable","text":"<p>YAML-driven theming, agent registries, and data source configuration. Swap databases, customize branding, and extend functionality without touching code.</p>"},{"location":"#open-extensible","title":"Open &amp; Extensible","text":"<p>Self-hosted, API-first architecture. FastAPI backend with auto-generated OpenAPI docs, Zustand stores for clean state management, and a modular component library.</p>"},{"location":"#platform-overview","title":"Platform Overview","text":"\u2039 \u203a Live Evaluation Scorecard"},{"location":"#evaluate","title":"Evaluate","text":"<p>Upload evaluation data, run batch evaluations, and explore results through interactive tree visualizations, analytics dashboards with 8+ chart types, and AI-generated reports with structured cross-metric pattern insights.</p> <p> Learn more</p>"},{"location":"#production","title":"Production","text":"<p>Executive overview combining Agent KPIs, AI quality monitoring, and human feedback signals in a single dashboard with sparkline trends.</p> <p> Learn more</p>"},{"location":"#monitoring","title":"Monitoring","text":"<p>Deep-dive production observability \u2014 time-series score trends, metric breakdowns, latency distributions, and anomaly alerts.</p> <p> Learn more</p>"},{"location":"#annotation","title":"Annotation","text":"<p>Human-in-the-loop quality assessment with 3 annotation formats, tag-based critiques, and CSV export.</p> <p> Learn more</p>"},{"location":"#caliberhq","title":"CaliberHQ","text":"<p>LLM judge calibration \u2014 3-step workflow with annotation, EvidencePipeline-powered pattern discovery with learning insights, and alignment validation via Cohen's Kappa and confusion matrices.</p> <p> Learn more</p>"},{"location":"#simulation","title":"Simulation","text":"<p>Synthetic persona-based agent testing with configurable personas, knowledge base upload, and conversation replay.</p> <p> Learn more</p>"},{"location":"#memory","title":"Memory","text":"<p>Decision memory dashboard with rule extraction, hard stops, batch analysis, and knowledge graph visualization.</p> <p> Learn more</p>"},{"location":"#human-signals","title":"Human Signals","text":"<p>Data-driven HITL dashboard with dynamic KPI strips, signal trend charts, classification distributions, and case-level drill-down.</p> <p> Learn more</p>"},{"location":"#tech-stack","title":"Tech Stack","text":"Layer Technologies Frontend Next.js 14 (App Router), TypeScript, Tailwind CSS State Zustand, TanStack React Query Charts Plotly.js, D3.js Backend FastAPI, Python 3.12 Data Pandas, NumPy, Scikit-Learn Config Pydantic Settings, python-dotenv"},{"location":"#quick-start","title":"Quick Start","text":"<pre><code># Clone and install\ngit clone https://github.com/ax-foundry/axis.git\ncd axis\nmake install\n\n# Start development servers\nmake dev\n</code></pre> <ul> <li>Frontend: http://localhost:3500</li> <li>Backend: http://localhost:8500</li> <li>API Docs: http://localhost:8500/docs</li> </ul> <p> Full installation guide</p>"},{"location":"404/","title":"Page Not Found","text":"<p>The page you're looking for doesn't exist or has been moved.</p> <p> Back to Home</p>"},{"location":"404/#popular-pages","title":"Popular Pages","text":"<ul> <li>Getting Started \u2014 Install and run AXIS locally</li> <li>User Guide \u2014 Feature walkthroughs for every module</li> <li>Configuration \u2014 Environment variables, YAML configs, theming</li> <li>API Reference \u2014 REST API and code-level documentation</li> <li>Architecture \u2014 System design and data flow</li> </ul>"},{"location":"contributing/","title":"Contributing","text":"<p>Thank you for your interest in contributing to AXIS.</p>"},{"location":"contributing/#getting-started","title":"Getting Started","text":"<ol> <li>Fork the repository and clone your fork</li> <li>Follow the development setup guide to configure your environment</li> <li>Create a feature branch from <code>master</code></li> </ol>"},{"location":"contributing/#development-workflow","title":"Development Workflow","text":"<pre><code># Install dependencies and pre-commit hooks\nmake install\n\n# Start development servers\nmake dev\n\n# Run linters before committing\nmake lint-fix\n\n# Run tests\nmake test\n</code></pre>"},{"location":"contributing/#code-standards","title":"Code Standards","text":"<ul> <li>Backend: Follow the code conventions for Python/FastAPI</li> <li>Frontend: Follow the code conventions for TypeScript/Next.js</li> <li>Design: Follow the design system for UI components</li> </ul>"},{"location":"contributing/#pull-request-process","title":"Pull Request Process","text":"<ol> <li>Ensure all linters pass: <code>make lint</code></li> <li>Ensure all type checks pass: <code>make typecheck</code></li> <li>Ensure all tests pass: <code>make test</code></li> <li>Update documentation if your change affects user-facing behavior</li> <li>Submit a pull request against <code>master</code></li> </ol>"},{"location":"contributing/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>The repository uses pre-commit to run automated checks on every commit:</p> Hook Purpose Trailing whitespace Remove trailing whitespace End-of-file fixer Ensure files end with newline YAML/JSON validation Check syntax Large file detection Prevent accidental large commits Merge conflict detection Catch unresolved conflicts Private key detection Prevent credential leaks Ruff lint + format Python code quality Prettier Frontend formatting ESLint Frontend linting"},{"location":"contributing/#reporting-issues","title":"Reporting Issues","text":"<p>Open an issue on GitHub with:</p> <ul> <li>A clear description of the problem or feature request</li> <li>Steps to reproduce (for bugs)</li> <li>Expected vs. actual behavior</li> <li>Environment details (OS, Python version, Node version)</li> </ul>"},{"location":"api-reference/","title":"API Reference","text":"<p>AXIS exposes a REST API via FastAPI and provides Python and TypeScript libraries for extending the platform.</p>"},{"location":"api-reference/#rest-api","title":"REST API","text":"<p>FastAPI automatically generates interactive API documentation:</p> <ul> <li>Swagger UI: http://localhost:8500/docs</li> <li>ReDoc: http://localhost:8500/redoc</li> </ul> <p>See the REST API overview for endpoint summaries and tag descriptions.</p>"},{"location":"api-reference/#backend-python","title":"Backend (Python)","text":"<p>Auto-generated reference from Python docstrings:</p> Module Description Config Application settings and constants Data Processor CSV parsing, format detection, data transformation Database Service PostgreSQL connection management and queries Eval Runner Service Batch evaluation execution Human Signals Service Human signals processing Memory Service Decision memory and rule extraction Graph Service FalkorDB knowledge graph operations Schemas Pydantic data models"},{"location":"api-reference/#frontend-typescript","title":"Frontend (TypeScript)","text":"<p>Hand-written reference for key frontend modules:</p> Module Description API Client <code>fetchApi</code> client and endpoint functions Hooks React Query hooks for data fetching Stores Zustand state management stores Types TypeScript type definitions"},{"location":"api-reference/rest-api/","title":"REST API","text":"<p>AXIS uses FastAPI which auto-generates OpenAPI documentation. When the backend is running, access the interactive docs at:</p> <ul> <li>Swagger UI: http://localhost:8500/docs</li> <li>ReDoc: http://localhost:8500/redoc</li> </ul>"},{"location":"api-reference/rest-api/#endpoint-groups","title":"Endpoint Groups","text":"Tag Prefix Description <code>config</code> <code>/api/config</code> Theme configuration and app settings <code>data</code> <code>/api/data</code> CSV upload, format detection, data processing <code>analytics</code> <code>/api/analytics</code> Statistical aggregations, charts, KPIs <code>ai</code> <code>/api/ai</code> AI Copilot with streaming SSE responses <code>align</code> <code>/api/align</code> Calibration and alignment workflows <code>reports</code> <code>/api/reports</code> Report generation and issue extraction <code>database</code> <code>/api/database</code> PostgreSQL connection, schema browsing, import <code>human-signals</code> <code>/api/human-signals</code> Human signals upload and processing <code>monitoring</code> <code>/api/monitoring</code> Monitoring data upload and management <code>monitoring-analytics</code> <code>/api/monitoring/analytics</code> Summary KPIs, trends, breakdowns, latency, classification, correlation, analysis <code>eval-runner</code> <code>/api/eval-runner</code> Batch evaluation execution via Axion <code>memory</code> <code>/api/memory</code> Decision memory, rules, hard stops, batches <code>graph</code> <code>/api/memory/graph</code> Knowledge graph queries and visualization <code>kpi</code> <code>/api/kpi</code> Agent KPI categories, trends, and filter values for the Production dashboard <code>agent-replay</code> <code>/api/agent-replay</code> Langfuse trace replay: search, detail, node inspection, reviews <code>store</code> <code>/api/store</code> DuckDB analytics store: sync, status, metadata, paginated data, watermark management"},{"location":"api-reference/rest-api/#health-checks","title":"Health Checks","text":"<pre><code># Simple health check\ncurl http://localhost:8500/\n\n# Detailed health check\ncurl http://localhost:8500/health\n</code></pre>"},{"location":"api-reference/rest-api/#authentication","title":"Authentication","text":"<p>AXIS does not currently implement authentication. Secure access at the network level using a reverse proxy or firewall rules.</p>"},{"location":"api-reference/rest-api/#response-format","title":"Response Format","text":"<p>Most endpoints return a consistent shape:</p> SuccessError <pre><code>{\n  \"success\": true,\n  \"data\": { ... },\n  \"message\": \"Optional message\"\n}\n</code></pre> <pre><code>{\n  \"detail\": \"Description of what went wrong\"\n}\n</code></pre>"},{"location":"api-reference/rest-api/#streaming-sse","title":"Streaming (SSE)","text":"<p>Several endpoints use Server-Sent Events for real-time streaming:</p>"},{"location":"api-reference/rest-api/#ai-copilot-sse","title":"AI Copilot SSE","text":"<p>The copilot endpoint (<code>POST /api/ai/copilot/stream</code>) streams thoughts and responses:</p> <pre><code>event: thought\ndata: {\"content\": \"Analyzing the data...\"}\n\nevent: response\ndata: {\"result\": \"Here are the findings...\"}\n\nevent: done\ndata:\n</code></pre>"},{"location":"api-reference/rest-api/#report-generation-sse","title":"Report Generation SSE","text":"<p>The report endpoint (<code>POST /api/reports/generate/stream</code>) streams progress, structured insights, and the final report:</p> <pre><code>event: thought\ndata: {\"content\": \"Extracting issues from evaluation data...\"}\n\nevent: thought\ndata: {\"content\": \"Analyzing patterns across metrics...\"}\n\nevent: insights\ndata: {\"patterns\": [...], \"learnings\": [...], \"total_issues_analyzed\": 42, \"pipeline_metadata\": {...}}\n\nevent: response\ndata: {\"success\": true, \"report_text\": \"...\", \"issues_analyzed\": 42, \"metrics_covered\": [...], \"insights\": {...}}\n\nevent: done\ndata:\n</code></pre> <p>The <code>insights</code> event delivers structured cross-metric pattern analysis before the final report. If insight extraction fails, the event is skipped and the report still completes successfully.</p> <p>Reverse proxy configuration</p> <p>If using Nginx, disable proxy buffering for SSE paths (<code>/api/ai/</code>, <code>/api/reports/</code>) to ensure events stream correctly. See the production deployment guide for details.</p>"},{"location":"api-reference/rest-api/#key-endpoint-details","title":"Key Endpoint Details","text":""},{"location":"api-reference/rest-api/#config-endpoints","title":"Config Endpoints","text":"Endpoint Method Description <code>/api/config/theme</code> GET Active palette, all palettes, and branding text <code>/api/config/visibility</code> GET Visibility config for KPIs, monitoring metrics, signals <code>/api/config/agents</code> GET Agent registry (name, label, role, avatar, trace_names) <code>/api/config/features</code> GET Feature flags (<code>eval_runner_enabled</code>, <code>copilot_enabled</code>) <code>/api/config/plugins</code> GET All discovered plugins with enabled/disabled status <code>/api/config/memory</code> GET Memory module config (deprecated \u2014 use <code>/api/memory/config</code>)"},{"location":"api-reference/rest-api/#data-endpoints","title":"Data Endpoints","text":"Endpoint Method Description <code>/api/data/upload</code> POST Upload and process a CSV file <code>/api/data/detect-format</code> POST Detect CSV format without full processing <code>/api/data/convert-tree</code> POST Convert tree format data to wide format for analytics <code>/api/data/prepare-analytics</code> POST Prepare uploaded data for analytics visualization <code>/api/data/example/{dataset_name}</code> GET Load a built-in example dataset <code>/api/data/eval-db-config</code> GET Get the evaluation database auto-load configuration <code>/api/data/eval-db-import</code> POST Auto-import evaluation data from the configured database"},{"location":"api-reference/rest-api/#analytics-endpoints","title":"Analytics Endpoints","text":"Endpoint Method Description <code>/api/analytics/summary</code> POST Calculate summary statistics for metrics <code>/api/analytics/distribution</code> POST Distribution data for a specific metric. <code>metric</code>, <code>bins</code> (default 20) <code>/api/analytics/comparison</code> POST Compare metrics across groups. <code>group_by</code>, <code>metrics</code> <code>/api/analytics/correlation</code> POST Correlation matrix between selected metrics <code>/api/analytics/radar</code> POST Radar chart data for multi-metric comparison <code>/api/analytics/scatter</code> POST Scatter plot data. <code>x_metric</code>, <code>y_metric</code>, <code>color_by</code>"},{"location":"api-reference/rest-api/#ai-copilot-endpoints","title":"AI Copilot Endpoints","text":"Endpoint Method Description <code>/api/ai/chat</code> POST Chat with the AI copilot <code>/api/ai/query</code> POST Query evaluation data using natural language <code>/api/ai/analyze</code> POST Generate automated analysis of evaluation data <code>/api/ai/status</code> GET Check AI service status and configuration <code>/api/ai/copilot/stream</code> POST Stream copilot responses with real-time thoughts (SSE) <code>/api/ai/copilot/chat</code> POST Non-streaming copilot endpoint for simple requests <code>/api/ai/copilot/skills</code> GET List available copilot skills/tools"},{"location":"api-reference/rest-api/#calibration-align-endpoints","title":"Calibration (Align) Endpoints","text":"Endpoint Method Description <code>/api/align/evaluate</code> POST Run LLM judge evaluation on a dataset <code>/api/align/metrics</code> POST Calculate alignment metrics (Cohen's Kappa, confusion matrix) <code>/api/align/analyze-misalignment</code> POST Analyze patterns in misaligned cases <code>/api/align/optimize-prompt</code> POST Generate an optimized judge prompt from misalignment patterns <code>/api/align/suggest-examples</code> POST Suggest few-shot examples from annotated data <code>/api/align/cluster-patterns</code> POST Discover error patterns and learning insights from annotations using the EvidencePipeline. Accepts optional <code>domain_context</code> for domain-aware analysis <code>/api/align/models</code> GET List available LLM models <code>/api/align/save-config</code> POST Save a judge configuration <code>/api/align/configs</code> GET List all saved judge configurations <code>/api/align/configs/{config_id}</code> GET Get a specific saved configuration <code>/api/align/configs/{config_id}</code> DELETE Delete a saved configuration <code>/api/align/defaults</code> GET Default prompt templates and evaluation criteria <code>/api/align/status</code> GET Align service status and configured providers"},{"location":"api-reference/rest-api/#report-endpoints","title":"Report Endpoints","text":"Endpoint Method Description <code>/api/reports/generate/stream</code> POST Stream report generation with real-time thoughts, structured insights, and final report (SSE). Runs issue extraction, then LLM report and InsightExtractor pattern analysis concurrently <code>/api/reports/generate</code> POST Non-streaming report generation with optional structured insights <code>/api/reports/extract-issues</code> POST Extract issues without LLM generation (preview before report) <code>/api/reports/status</code> GET Report generation service status <p>Both generate endpoints validate the specific requested LLM <code>provider</code> (not just \"any provider configured\") and return a clear error if the requested provider is not available.</p>"},{"location":"api-reference/rest-api/#database-endpoints","title":"Database Endpoints","text":"Endpoint Method Description <code>/api/database/defaults</code> GET Default connection values from YAML config or env vars. <code>store</code> param: <code>data</code>, <code>monitoring</code>, <code>human_signals</code> <code>/api/database/connect</code> POST Test connection and return a handle (15-min TTL) <code>/api/database/{handle}/tables</code> GET List available tables in the connected database <code>/api/database/{handle}/schema</code> GET Column schema and sample values for a table <code>/api/database/{handle}/distinct-values</code> POST Distinct values for a column (for filter dropdowns) <code>/api/database/{handle}/preview</code> POST Preview data with optional column mappings <code>/api/database/{handle}/query</code> POST Preview results of a SQL query <code>/api/database/{handle}/query-import</code> POST Import data from a SQL query <code>/api/database/{handle}/import</code> POST Import data from a table into AXIS <code>/api/database/{handle}</code> DELETE Disconnect and invalidate a connection handle <code>/api/database/stats</code> GET Connection pool statistics"},{"location":"api-reference/rest-api/#eval-runner-endpoints","title":"Eval Runner Endpoints","text":"Endpoint Method Description <code>/api/eval-runner/metrics</code> GET All available evaluation metrics <code>/api/eval-runner/example/sample</code> GET Load the built-in example evaluation dataset <code>/api/eval-runner/upload</code> POST Upload a CSV dataset for evaluation <code>/api/eval-runner/test-connection</code> POST Test agent connection with a sample query <code>/api/eval-runner/run</code> POST Run evaluation synchronously and return results <code>/api/eval-runner/run/stream</code> POST Run evaluation with SSE streaming progress updates <code>/api/eval-runner/export/{run_id}/csv</code> GET Export evaluation results as CSV <code>/api/eval-runner/export/{run_id}/json</code> GET Export evaluation results as JSON <p>Requires <code>eval_runner_enabled: true</code> in <code>eval_db.yaml</code>.</p>"},{"location":"api-reference/rest-api/#human-signals-endpoints","title":"Human Signals Endpoints","text":"Endpoint Method Description <code>/api/human-signals/upload</code> POST Upload and process a human signals CSV file <code>/api/human-signals/example/{dataset_name}</code> GET Load an example human signals dataset <code>/api/human-signals/db-config</code> GET Human signals database auto-load configuration <code>/api/human-signals/db-import</code> POST Auto-import human signals data from the configured database <code>/api/human-signals/cases</code> GET Query pre-aggregated cases from DuckDB. <code>page</code>, <code>page_size</code> <code>/api/human-signals/metric-schema</code> GET Human signals metric schema from DuckDB metadata"},{"location":"api-reference/rest-api/#monitoring-endpoints","title":"Monitoring Endpoints","text":"Endpoint Method Description <code>/api/monitoring/upload</code> POST Upload and process a monitoring CSV file <code>/api/monitoring/example/{dataset_name}</code> GET Load an example monitoring dataset <code>/api/monitoring/db-config</code> GET Monitoring database auto-load configuration <code>/api/monitoring/db-import</code> POST Auto-import monitoring data from the configured database"},{"location":"api-reference/rest-api/#memory-endpoints","title":"Memory Endpoints","text":"Endpoint Method Description <code>/api/memory/config</code> GET Memory module configuration (field roles, labels, filters) <code>/api/memory/summary</code> GET Aggregate summary: counts, action distribution, product distribution <code>/api/memory/rules</code> GET Filterable list of all extracted rules <code>/api/memory/rules/quality</code> GET Rules split by decision quality (aligned, divergent, partial) <code>/api/memory/rules/soft-thresholds</code> GET Rules with soft thresholds <code>/api/memory/hard-stops</code> GET Unmitigated decline rules (hard stops) <code>/api/memory/batches</code> GET Pipeline batch history <code>/api/memory/trace</code> GET Decision trace path for a single rule <code>/api/memory/conflicts</code> GET Contradictory actions within the same risk factor <code>/api/memory/status-counts</code> GET Count rules by ingestion status <code>/api/memory/upload</code> POST Upload a CSV file containing rule extractions <code>/api/memory/rules</code> POST Create a new rule <code>/api/memory/rules/{rule_id}</code> PUT Update an extracted rule <code>/api/memory/rules/{rule_id}</code> DELETE Delete a rule"},{"location":"api-reference/rest-api/#knowledge-graph-endpoints","title":"Knowledge Graph Endpoints","text":"Endpoint Method Description <code>/api/memory/graph/status</code> GET FalkorDB connection health <code>/api/memory/graph/summary</code> GET Graph summary statistics (node/edge counts) <code>/api/memory/graph/</code> GET Full graph or filtered subset. <code>limit</code>, <code>risk_factor</code>, <code>product_type</code>, <code>action</code>, <code>node_type</code> <code>/api/memory/graph/search</code> GET Search nodes by name (case-insensitive substring) <code>/api/memory/graph/neighborhood</code> GET Neighborhood subgraph around a specific node. <code>node_id</code>, <code>depth</code>"},{"location":"api-reference/rest-api/#store-endpoints","title":"Store Endpoints","text":"Endpoint Method Description <code>/api/store/sync</code> POST Sync all datasets. <code>?full=true</code> forces full rebuild <code>/api/store/sync/{dataset}</code> POST Sync single dataset (monitoring, human_signals, eval) <code>/api/store/sync/{dataset}/reset-watermark</code> POST Clear watermarks \u2014 next sync does full rebuild <code>/api/store/status</code> GET Per-table sync status with watermarks and refresh intervals <code>/api/store/metadata/{dataset}</code> GET Columns, time range, filter values, summary stats <code>/api/store/data/{dataset}</code> GET Paginated data with filters, sorting, column projection, search"},{"location":"api-reference/rest-api/#monitoring-analytics-endpoints","title":"Monitoring Analytics Endpoints","text":"Endpoint Method Description <code>/api/monitoring/analytics/summary</code> GET Lightweight KPIs (total, avg score, pass rate, latency p50/p95/p99) <code>/api/monitoring/analytics/trends</code> GET Time-series by granularity (hourly/daily/weekly) <code>/api/monitoring/analytics/metric-breakdown</code> GET Pass rate and average per metric with optional group-by <code>/api/monitoring/analytics/latency-distribution</code> GET Histogram with percentiles and optional group-by <code>/api/monitoring/analytics/class-distribution</code> GET Score distributions grouped by dimension <code>/api/monitoring/analytics/correlation</code> GET Correlation matrix between metrics <code>/api/monitoring/analytics/classification-breakdown</code> GET Category value counts for CLASSIFICATION metrics <code>/api/monitoring/analytics/classification-trends</code> GET Time-series for CLASSIFICATION categories <code>/api/monitoring/analytics/analysis-insights</code> GET Paginated ANALYSIS metric records with signals <p>All monitoring analytics endpoints accept common filter parameters: <code>environment</code>, <code>source_name</code>, <code>source_component</code>, <code>source_type</code>, <code>metric_name</code>, <code>metric_category</code>, <code>time_start</code>, <code>time_end</code>.</p>"},{"location":"api-reference/rest-api/#kpi-endpoints","title":"KPI Endpoints","text":"Endpoint Method Description <code>/api/kpi/categories</code> GET Category panels with KPI cards, sparklines, and trend directions <code>/api/kpi/trends</code> GET Trend data for expanded panels (lazy-loaded). <code>kpi_names</code> is comma-separated <code>/api/kpi/filters</code> GET Available filter values for dropdowns <p>KPI endpoints accept filter parameters: <code>source_name</code>, <code>kpi_category</code>, <code>environment</code>, <code>source_type</code>, <code>time_start</code>, <code>time_end</code>.</p>"},{"location":"api-reference/rest-api/#agent-replay-endpoints","title":"Agent Replay Endpoints","text":"Endpoint Method Description <code>/api/agent-replay/status</code> GET Replay service status (Langfuse connectivity, search DB availability) <code>/api/agent-replay/agents</code> GET List of configured agents (discovered from <code>LANGFUSE_*</code> env vars) <code>/api/agent-replay/search</code> GET Search traces by ID or business field. <code>search_by</code>: <code>trace_id</code> or <code>field</code> <code>/api/agent-replay/traces</code> GET List recent traces with optional <code>name</code>, <code>tags</code>, <code>agent</code> filters <code>/api/agent-replay/traces/{trace_id}</code> GET Full trace detail with observation tree <code>/api/agent-replay/traces/{trace_id}/nodes/{node_id}</code> GET Single observation node detail (input, output, metadata) <code>/api/agent-replay/traces/{trace_id}/steps/{index}</code> GET Step detail by index <code>/api/agent-replay/reviews</code> POST Submit a review (verdict, failure step, rationale) <code>/api/agent-replay/traces/{trace_id}/reviews</code> GET Retrieve reviews for a trace <code>/api/agent-replay/datasets</code> GET List available Langfuse datasets <p>All Agent Replay endpoints require <code>AGENT_REPLAY_ENABLED=true</code>. The optional <code>agent</code> query parameter selects per-agent Langfuse credentials and search DB overrides.</p>"},{"location":"api-reference/backend/config/","title":"Config","text":"<p>Application settings, constants, and configuration management.</p>"},{"location":"api-reference/backend/config/#app.config-classes","title":"Classes","text":""},{"location":"api-reference/backend/config/#app.config.Settings","title":"<code>Settings</code>","text":"<p>               Bases: <code>BaseSettings</code></p> <p>Application settings loaded from environment variables.</p>"},{"location":"api-reference/backend/config/#app.config.BaseDBImportConfig","title":"<code>BaseDBImportConfig(url=None, host=None, port=5432, database=None, username=None, password=None, ssl_mode='prefer', db_type='postgres', dataset_query=None, results_query=None, query_timeout=60, row_limit=10000, column_rename_map=dict(), partition_column=None, refresh_interval_minutes=0, incremental_column=None, tables=list(), filters=list())</code>  <code>dataclass</code>","text":"<p>Base database import configuration with shared fields.</p> <p>All database configs (eval, monitoring, human_signals) inherit from this.</p>"},{"location":"api-reference/backend/config/#app.config.BaseDBImportConfig-attributes","title":"Attributes","text":""},{"location":"api-reference/backend/config/#app.config.BaseDBImportConfig.is_configured","title":"<code>is_configured</code>  <code>property</code>","text":"<p>Check if enough config is provided to connect.</p>"},{"location":"api-reference/backend/config/#app.config.BaseDBImportConfig.has_query","title":"<code>has_query</code>  <code>property</code>","text":"<p>Check if both split SQL queries are configured.</p>"},{"location":"api-reference/backend/config/#app.config.HumanSignalsDBConfig","title":"<code>HumanSignalsDBConfig(url=None, host=None, port=5432, database=None, username=None, password=None, ssl_mode='prefer', db_type='postgres', dataset_query=None, results_query=None, query_timeout=60, row_limit=10000, column_rename_map=dict(), partition_column=None, refresh_interval_minutes=0, incremental_column=None, tables=list(), filters=list(), enabled=False, auto_connect=False, auto_load=False, schema_name='public', table=None, visible_metrics=list(), visible_kpis=list())</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseDBImportConfig</code></p> <p>Human signals database configuration loaded from YAML or env vars.</p>"},{"location":"api-reference/backend/config/#app.config.HumanSignalsDBConfig-attributes","title":"Attributes","text":""},{"location":"api-reference/backend/config/#app.config.HumanSignalsDBConfig.should_auto_load","title":"<code>should_auto_load</code>  <code>property</code>","text":"<p>Check if auto-load is enabled (either via auto_load or legacy auto_connect).</p>"},{"location":"api-reference/backend/config/#app.config.AnomalyDetectionConfig","title":"<code>AnomalyDetectionConfig(enabled=False, min_data_points=5, z_score_enabled=True, z_score_threshold=2.0, z_score_severity='warning', z_score_lookback_window=20, z_score_metrics=list(), ma_enabled=True, ma_window_size=5, ma_deviation_threshold=0.15, ma_severity='warning', ma_metrics=list(), roc_enabled=True, roc_threshold=0.3, roc_severity='error', roc_metrics=list())</code>  <code>dataclass</code>","text":"<p>Anomaly detection settings for monitoring trend data.</p>"},{"location":"api-reference/backend/config/#app.config.MonitoringDBConfig","title":"<code>MonitoringDBConfig(url=None, host=None, port=5432, database=None, username=None, password=None, ssl_mode='prefer', db_type='postgres', dataset_query=None, results_query=None, query_timeout=60, row_limit=10000, column_rename_map=dict(), partition_column=None, refresh_interval_minutes=0, incremental_column=None, tables=list(), filters=list(), enabled=False, auto_connect=False, auto_load=False, schema_name='public', table=None, thresholds_default_good=0.7, thresholds_default_pass=0.5, thresholds_per_source=dict(), anomaly_detection=AnomalyDetectionConfig(), visible_metrics=list())</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseDBImportConfig</code></p> <p>Monitoring database configuration loaded from YAML or env vars.</p>"},{"location":"api-reference/backend/config/#app.config.MonitoringDBConfig-attributes","title":"Attributes","text":""},{"location":"api-reference/backend/config/#app.config.MonitoringDBConfig.should_auto_load","title":"<code>should_auto_load</code>  <code>property</code>","text":"<p>Check if auto-load is enabled (either via auto_load or legacy auto_connect).</p>"},{"location":"api-reference/backend/config/#app.config.EvalDBConfig","title":"<code>EvalDBConfig(url=None, host=None, port=5432, database=None, username=None, password=None, ssl_mode='prefer', db_type='postgres', dataset_query=None, results_query=None, query_timeout=60, row_limit=10000, column_rename_map=dict(), partition_column=None, refresh_interval_minutes=0, incremental_column=None, tables=list(), filters=list(), enabled=False, auto_load=False, eval_runner_enabled=True)</code>  <code>dataclass</code>","text":"<p>               Bases: <code>BaseDBImportConfig</code></p> <p>Evaluation database configuration loaded from YAML or env vars.</p>"},{"location":"api-reference/backend/config/#app.config.KpiDBConfig","title":"<code>KpiDBConfig(enabled=False, auto_load=False, url=None, host=None, port=5432, database=None, username=None, password=None, ssl_mode='prefer', query=None, query_timeout=60, row_limit=50000, columns=dict(), db_type='postgres', partition_column=None, refresh_interval_minutes=0, incremental_column=None, visible_kpis=list(), visible_kpis_per_source=dict(), card_display_value='latest', trend_lines=(lambda: ['daily', 'avg_7d', 'avg_30d'])(), kpi_overrides=dict(), display_per_source=dict(), categories=dict(), composition_charts=list())</code>  <code>dataclass</code>","text":"<p>Agent KPI database configuration loaded from YAML or env vars.</p> <p>Simplified from EvalDBConfig: single query (no dataset/results split).</p>"},{"location":"api-reference/backend/config/#app.config.KpiDBConfig-attributes","title":"Attributes","text":""},{"location":"api-reference/backend/config/#app.config.KpiDBConfig.is_configured","title":"<code>is_configured</code>  <code>property</code>","text":"<p>Check if enough config is provided to connect.</p>"},{"location":"api-reference/backend/config/#app.config.KpiDBConfig.has_query","title":"<code>has_query</code>  <code>property</code>","text":"<p>Check if a SQL query is configured.</p>"},{"location":"api-reference/backend/config/#app.config.KpiDBConfig.should_auto_load","title":"<code>should_auto_load</code>  <code>property</code>","text":"<p>Check if auto-load is enabled and configured.</p>"},{"location":"api-reference/backend/config/#app.config.DuckDBConfig","title":"<code>DuckDBConfig(enabled=True, path='data/local_store.duckdb', sync_mode='startup', auto_sync_on_startup=True, sync_chunk_size=10000, max_sync_rows=2000000, query_concurrency=8, sync_workers=1)</code>  <code>dataclass</code>","text":"<p>DuckDB embedded analytics store configuration.</p>"},{"location":"api-reference/backend/config/#app.config.ThemePalette","title":"<code>ThemePalette(name='Sage Green', primary='#8B9F4F', primaryLight='#A4B86C', primaryDark='#6B7A3A', primarySoft='#B8C78A', primaryPale='#D4E0B8', accentGold='#D4AF37', accentSilver='#B8C5D3', heroImage=None, logoUrl=None, faviconUrl=None, appIconUrl=None, heroContrast=None, heroSaturation=None, heroBrightness=None, heroOpacity=None, heroMode=None)</code>  <code>dataclass</code>","text":"<p>Theme palette colors.</p>"},{"location":"api-reference/backend/config/#app.config.ThemePalette-functions","title":"Functions","text":""},{"location":"api-reference/backend/config/#app.config.ThemePalette.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert palette to dict for JSON serialization.</p> Source code in <code>backend/app/config.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert palette to dict for JSON serialization.\"\"\"\n    return {\n        \"name\": self.name,\n        \"primary\": self.primary,\n        \"primaryLight\": self.primaryLight,\n        \"primaryDark\": self.primaryDark,\n        \"primarySoft\": self.primarySoft,\n        \"primaryPale\": self.primaryPale,\n        \"accentGold\": self.accentGold,\n        \"accentSilver\": self.accentSilver,\n        \"heroImage\": self.heroImage,\n        \"logoUrl\": self.logoUrl,\n        \"faviconUrl\": self.faviconUrl,\n        \"appIconUrl\": self.appIconUrl,\n        \"heroContrast\": self.heroContrast,\n        \"heroSaturation\": self.heroSaturation,\n        \"heroBrightness\": self.heroBrightness,\n        \"heroOpacity\": self.heroOpacity,\n        \"heroMode\": self.heroMode,\n    }\n</code></pre>"},{"location":"api-reference/backend/config/#app.config.BrandingConfig","title":"<code>BrandingConfig(app_name='AXIS', tagline='AI Evaluation Platform', subtitle='The AI Evaluation Studio', description='Agent X-ray Interface &amp; Statistics', report_footer='Report generated by AXIS AI Evaluation Platform', docs_url='https://ax-foundry.github.io/axis/', footer_name='', footer_icon='')</code>  <code>dataclass</code>","text":"<p>Branding text used throughout the application.</p>"},{"location":"api-reference/backend/config/#app.config.BrandingConfig-functions","title":"Functions","text":""},{"location":"api-reference/backend/config/#app.config.BrandingConfig.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert to dict for JSON serialization.</p> Source code in <code>backend/app/config.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert to dict for JSON serialization.\"\"\"\n    return {\n        \"app_name\": self.app_name,\n        \"tagline\": self.tagline,\n        \"subtitle\": self.subtitle,\n        \"description\": self.description,\n        \"report_footer\": self.report_footer,\n        \"docs_url\": self.docs_url,\n        \"footer_name\": self.footer_name or self.app_name,\n        \"footer_icon\": self.footer_icon or None,\n    }\n</code></pre>"},{"location":"api-reference/backend/config/#app.config.ThemeConfig","title":"<code>ThemeConfig(active='professional_blue', palettes=(lambda: dict(DEFAULT_PALETTES))(), branding=BrandingConfig())</code>  <code>dataclass</code>","text":"<p>Theme configuration loaded from YAML or env vars.</p>"},{"location":"api-reference/backend/config/#app.config.ThemeConfig-functions","title":"Functions","text":""},{"location":"api-reference/backend/config/#app.config.ThemeConfig.get_active_palette","title":"<code>get_active_palette()</code>","text":"<p>Get the currently active palette.</p> Source code in <code>backend/app/config.py</code> <pre><code>def get_active_palette(self) -&gt; ThemePalette:\n    \"\"\"Get the currently active palette.\"\"\"\n    return self.palettes.get(self.active, self.palettes.get(\"sage_green\", ThemePalette()))\n</code></pre>"},{"location":"api-reference/backend/config/#app.config.ThemeConfig.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert config to dict for JSON serialization.</p> Source code in <code>backend/app/config.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert config to dict for JSON serialization.\"\"\"\n    return {\n        \"active\": self.active,\n        \"palettes\": {name: palette.to_dict() for name, palette in self.palettes.items()},\n        \"branding\": self.branding.to_dict(),\n    }\n</code></pre>"},{"location":"api-reference/backend/config/#app.config.AgentConfig","title":"<code>AgentConfig(name='', label='', role=None, avatar=None, description=None, biography=None, active=True, trace_names=list())</code>  <code>dataclass</code>","text":"<p>Agent display configuration for the SourceSelector.</p>"},{"location":"api-reference/backend/config/#app.config.AgentConfig-functions","title":"Functions","text":""},{"location":"api-reference/backend/config/#app.config.AgentConfig.to_dict","title":"<code>to_dict()</code>","text":"<p>Convert to dict for JSON serialization.</p> Source code in <code>backend/app/config.py</code> <pre><code>def to_dict(self) -&gt; dict[str, Any]:\n    \"\"\"Convert to dict for JSON serialization.\"\"\"\n    return {\n        \"name\": self.name,\n        \"label\": self.label,\n        \"role\": self.role,\n        \"avatar\": self.avatar,\n        \"description\": self.description,\n        \"biography\": self.biography,\n        \"active\": self.active,\n        \"trace_names\": self.trace_names,\n    }\n</code></pre>"},{"location":"api-reference/backend/config/#app.config.Columns","title":"<code>Columns</code>","text":"<p>Column names for data processing. Mirrors Dash Config class.</p>"},{"location":"api-reference/backend/config/#app.config.Thresholds","title":"<code>Thresholds(PASSING_RATE=0.5, GREEN_THRESHOLD=0.7, RED_THRESHOLD=0.3)</code>  <code>dataclass</code>","text":"<p>Evaluation thresholds.</p>"},{"location":"api-reference/backend/config/#app.config.Colors","title":"<code>Colors()</code>  <code>dataclass</code>","text":"<p>Color palette for charts and UI.</p>"},{"location":"api-reference/backend/config/#app.config.Colors-functions","title":"Functions","text":""},{"location":"api-reference/backend/config/#app.config.Colors.get","title":"<code>get(name)</code>  <code>classmethod</code>","text":"<p>Get color by name.</p> Source code in <code>backend/app/config.py</code> <pre><code>@classmethod\ndef get(cls, name: str) -&gt; str:\n    \"\"\"Get color by name.\"\"\"\n    if name not in cls.PALETTE:\n        raise ValueError(f\"Color '{name}' not found in palette.\")\n    return cls.PALETTE[name]\n</code></pre>"},{"location":"api-reference/backend/config/#app.config-functions","title":"Functions","text":""},{"location":"api-reference/backend/config/#app.config.resolve_config_path","title":"<code>resolve_config_path(filename)</code>","text":"<p>Resolve config file path from custom/config/.</p> Source code in <code>backend/app/config.py</code> <pre><code>def resolve_config_path(filename: str) -&gt; Path:\n    \"\"\"Resolve config file path from custom/config/.\"\"\"\n    return _CONFIG_DIR / filename\n</code></pre>"},{"location":"api-reference/backend/config/#app.config.require_config_path","title":"<code>require_config_path(filename)</code>","text":"<p>Resolve and validate a config file exists.</p> <p>Raises FileNotFoundError with setup hint.</p> Source code in <code>backend/app/config.py</code> <pre><code>def require_config_path(filename: str) -&gt; Path:\n    \"\"\"Resolve and validate a config file exists.\n\n    Raises FileNotFoundError with setup hint.\n    \"\"\"\n    path = resolve_config_path(filename)\n    if not path.exists():\n        raise FileNotFoundError(\n            f\"Config file not found: {path}. Run 'make setup' to create config files.\"\n        )\n    return path\n</code></pre>"},{"location":"api-reference/backend/config/#app.config.get_import_config","title":"<code>get_import_config(store)</code>","text":"<p>Return the DB import config for a given target store.</p> <p>Raises ValueError on unknown store.</p> Source code in <code>backend/app/config.py</code> <pre><code>def get_import_config(store: str) -&gt; BaseDBImportConfig:\n    \"\"\"Return the DB import config for a given target store.\n\n    Raises ValueError on unknown store.\n    \"\"\"\n    registry: dict[str, BaseDBImportConfig] = {\n        \"data\": eval_db_config,\n        \"monitoring\": monitoring_db_config,\n        \"human_signals\": human_signals_db_config,\n    }\n    if store not in registry:\n        raise ValueError(f\"Unknown store: {store!r}. Valid stores: {list(registry.keys())}\")\n    return registry[store]\n</code></pre>"},{"location":"api-reference/backend/config/#app.config.load_human_signals_db_config","title":"<code>load_human_signals_db_config()</code>","text":"<p>Load human signals database config from YAML file first, then env vars.</p> <p>YAML takes precedence if it exists.</p> Source code in <code>backend/app/config.py</code> <pre><code>def load_human_signals_db_config() -&gt; HumanSignalsDBConfig:\n    \"\"\"Load human signals database config from YAML file first, then env vars.\n\n    YAML takes precedence if it exists.\n    \"\"\"\n    config = HumanSignalsDBConfig()\n\n    # Try loading from YAML config file first\n    if HUMAN_SIGNALS_CONFIG_PATH.exists():\n        try:\n            with HUMAN_SIGNALS_CONFIG_PATH.open() as f:\n                yaml_config: dict[str, Any] = yaml.safe_load(f) or {}\n\n            if yaml_config.get(\"human_signals_db\"):\n                db_config = yaml_config[\"human_signals_db\"]\n                base = _parse_base_fields(db_config)\n\n                config = HumanSignalsDBConfig(\n                    **base,\n                    enabled=db_config.get(\"enabled\", False),\n                    auto_connect=db_config.get(\"auto_connect\", False),\n                    auto_load=db_config.get(\"auto_load\", False),\n                    schema_name=db_config.get(\"schema\", \"public\"),\n                    table=db_config.get(\"table\"),\n                    visible_metrics=db_config.get(\"visible_metrics\", []) or [],\n                    visible_kpis=db_config.get(\"visible_kpis\", []) or [],\n                )\n                logger.info(f\"Loaded human signals DB config from {HUMAN_SIGNALS_CONFIG_PATH}\")\n                return config\n        except Exception as e:\n            logger.warning(f\"Failed to load YAML config: {e}\")\n\n    # Fall back to env vars\n    if settings.human_signals_db_url or settings.human_signals_db_host:\n        config = HumanSignalsDBConfig(\n            enabled=True,\n            auto_connect=settings.human_signals_db_auto_connect,\n            auto_load=False,\n            host=settings.human_signals_db_host,\n            port=settings.human_signals_db_port,\n            database=settings.human_signals_db_name,\n            username=settings.human_signals_db_user,\n            password=settings.human_signals_db_password,\n            schema_name=settings.human_signals_db_schema,\n            table=settings.human_signals_db_table,\n            ssl_mode=settings.human_signals_db_ssl_mode,\n            url=settings.human_signals_db_url,\n        )\n        logger.info(\"Loaded human signals DB config from environment variables\")\n\n    return config\n</code></pre>"},{"location":"api-reference/backend/config/#app.config.load_monitoring_db_config","title":"<code>load_monitoring_db_config()</code>","text":"<p>Load monitoring database config from YAML file first, then env vars.</p> <p>YAML takes precedence if it exists.</p> Source code in <code>backend/app/config.py</code> <pre><code>def load_monitoring_db_config() -&gt; MonitoringDBConfig:\n    \"\"\"Load monitoring database config from YAML file first, then env vars.\n\n    YAML takes precedence if it exists.\n    \"\"\"\n    config = MonitoringDBConfig()\n\n    # Try loading from YAML config file first\n    if MONITORING_CONFIG_PATH.exists():\n        try:\n            with MONITORING_CONFIG_PATH.open() as f:\n                yaml_config: dict[str, Any] = yaml.safe_load(f) or {}\n\n            if yaml_config.get(\"monitoring_db\"):\n                db_config = yaml_config[\"monitoring_db\"]\n                base = _parse_base_fields(db_config)\n\n                t_good, t_pass, t_per_source = _parse_thresholds(db_config)\n                anomaly_cfg = _parse_anomaly_detection(db_config)\n\n                config = MonitoringDBConfig(\n                    **base,\n                    enabled=db_config.get(\"enabled\", False),\n                    auto_connect=db_config.get(\"auto_connect\", False),\n                    auto_load=db_config.get(\"auto_load\", False),\n                    schema_name=db_config.get(\"schema\", \"public\"),\n                    table=db_config.get(\"table\"),\n                    thresholds_default_good=t_good,\n                    thresholds_default_pass=t_pass,\n                    thresholds_per_source=t_per_source,\n                    anomaly_detection=anomaly_cfg,\n                    visible_metrics=db_config.get(\"visible_metrics\", []) or [],\n                )\n                logger.info(f\"Loaded monitoring DB config from {MONITORING_CONFIG_PATH}\")\n                return config\n        except Exception as e:\n            logger.warning(f\"Failed to load monitoring YAML config: {e}\")\n\n    # Fall back to env vars\n    if settings.monitoring_db_url or settings.monitoring_db_host:\n        config = MonitoringDBConfig(\n            enabled=True,\n            auto_connect=settings.monitoring_db_auto_connect,\n            auto_load=False,\n            host=settings.monitoring_db_host,\n            port=settings.monitoring_db_port,\n            database=settings.monitoring_db_name,\n            username=settings.monitoring_db_user,\n            password=settings.monitoring_db_password,\n            schema_name=settings.monitoring_db_schema,\n            table=settings.monitoring_db_table,\n            ssl_mode=settings.monitoring_db_ssl_mode,\n            url=settings.monitoring_db_url,\n        )\n        logger.info(\"Loaded monitoring DB config from environment variables\")\n\n    return config\n</code></pre>"},{"location":"api-reference/backend/config/#app.config.load_eval_db_config","title":"<code>load_eval_db_config()</code>","text":"<p>Load eval database config from YAML file first, then env vars.</p> <p>YAML takes precedence if it exists.</p> Source code in <code>backend/app/config.py</code> <pre><code>def load_eval_db_config() -&gt; EvalDBConfig:\n    \"\"\"Load eval database config from YAML file first, then env vars.\n\n    YAML takes precedence if it exists.\n    \"\"\"\n    config = EvalDBConfig()\n\n    # Try loading from YAML config file first\n    if EVAL_DB_CONFIG_PATH.exists():\n        try:\n            with EVAL_DB_CONFIG_PATH.open() as f:\n                yaml_config: dict[str, Any] = yaml.safe_load(f) or {}\n\n            if yaml_config.get(\"eval_db\"):\n                db_config = yaml_config[\"eval_db\"]\n                base = _parse_base_fields(db_config)\n\n                config = EvalDBConfig(\n                    **base,\n                    enabled=db_config.get(\"enabled\", False),\n                    auto_load=db_config.get(\"auto_load\", False),\n                    eval_runner_enabled=db_config.get(\"eval_runner_enabled\", True),\n                )\n                logger.info(f\"Loaded eval DB config from {EVAL_DB_CONFIG_PATH}\")\n                return config\n        except Exception as e:\n            logger.warning(f\"Failed to load eval DB YAML config: {e}\")\n\n    # Fall back to env vars\n    if settings.eval_db_url or settings.eval_db_host:\n        query_timeout = min(settings.eval_db_query_timeout, 120)\n        row_limit = min(settings.eval_db_row_limit, 50000)\n\n        config = EvalDBConfig(\n            enabled=True,\n            auto_load=settings.eval_db_auto_load,\n            url=settings.eval_db_url,\n            host=settings.eval_db_host,\n            port=settings.eval_db_port,\n            database=settings.eval_db_name,\n            username=settings.eval_db_user,\n            password=settings.eval_db_password,\n            ssl_mode=settings.eval_db_ssl_mode,\n            dataset_query=settings.eval_db_dataset_query,\n            results_query=settings.eval_db_results_query,\n            query_timeout=query_timeout,\n            row_limit=row_limit,\n        )\n        logger.info(\"Loaded eval DB config from environment variables\")\n\n    return config\n</code></pre>"},{"location":"api-reference/backend/config/#app.config.load_kpi_db_config","title":"<code>load_kpi_db_config()</code>","text":"<p>Load KPI database config from YAML file first, then env vars.</p> <p>YAML takes precedence if it exists.</p> Source code in <code>backend/app/config.py</code> <pre><code>def load_kpi_db_config() -&gt; KpiDBConfig:\n    \"\"\"Load KPI database config from YAML file first, then env vars.\n\n    YAML takes precedence if it exists.\n    \"\"\"\n    config = KpiDBConfig()\n\n    if KPI_DB_CONFIG_PATH.exists():\n        try:\n            with KPI_DB_CONFIG_PATH.open() as f:\n                yaml_config: dict[str, Any] = yaml.safe_load(f) or {}\n\n            if yaml_config.get(\"kpi_db\"):\n                db_config = yaml_config[\"kpi_db\"]\n                query_timeout = min(db_config.get(\"query_timeout\", 60), 120)\n                row_limit = min(db_config.get(\"row_limit\", 50000), 50000)\n\n                config = KpiDBConfig(\n                    enabled=db_config.get(\"enabled\", False),\n                    auto_load=db_config.get(\"auto_load\", False),\n                    url=db_config.get(\"url\"),\n                    host=db_config.get(\"host\"),\n                    port=db_config.get(\"port\", 5432),\n                    database=db_config.get(\"database\"),\n                    username=db_config.get(\"username\"),\n                    password=db_config.get(\"password\"),\n                    ssl_mode=db_config.get(\"ssl_mode\", \"prefer\"),\n                    query=db_config.get(\"query\"),\n                    query_timeout=query_timeout,\n                    row_limit=row_limit,\n                    columns=db_config.get(\"columns\", {}),\n                    partition_column=db_config.get(\"partition_column\"),\n                    refresh_interval_minutes=db_config.get(\"refresh_interval_minutes\", 0),\n                    incremental_column=db_config.get(\"incremental_column\"),\n                    visible_kpis=db_config.get(\"visible_kpis\", []) or [],\n                    visible_kpis_per_source=_parse_visible_kpis_per_source(\n                        db_config.get(\"visible_kpis_per_source\")\n                    ),\n                    card_display_value=(\n                        str(db_config[\"card_display_value\"])\n                        if db_config.get(\"card_display_value\") in VALID_CARD_DISPLAY_VALUES\n                        else \"latest\"\n                    ),\n                    trend_lines=[\n                        str(t)\n                        for t in (db_config.get(\"trend_lines\") or [])\n                        if str(t) in VALID_TREND_LINES\n                    ]\n                    or [\"daily\", \"avg_7d\", \"avg_30d\"],\n                    kpi_overrides=_parse_kpi_overrides(db_config.get(\"kpi_overrides\")),\n                    display_per_source=_parse_display_per_source(\n                        db_config.get(\"display_per_source\")\n                    ),\n                    categories=_parse_categories(db_config.get(\"categories\")),\n                    composition_charts=_parse_composition_charts(\n                        db_config.get(\"composition_charts\")\n                    ),\n                )\n                logger.info(f\"Loaded KPI DB config from {KPI_DB_CONFIG_PATH}\")\n                return config\n        except Exception as e:\n            logger.warning(f\"Failed to load KPI DB YAML config: {e}\")\n\n    # Fall back to env vars\n    if settings.kpi_db_url or settings.kpi_db_host:\n        config = KpiDBConfig(\n            enabled=True,\n            auto_load=settings.kpi_db_auto_load,\n            url=settings.kpi_db_url,\n            host=settings.kpi_db_host,\n            port=settings.kpi_db_port,\n            database=settings.kpi_db_name,\n            username=settings.kpi_db_user,\n            password=settings.kpi_db_password,\n            ssl_mode=settings.kpi_db_ssl_mode,\n        )\n        logger.info(\"Loaded KPI DB config from environment variables\")\n\n    return config\n</code></pre>"},{"location":"api-reference/backend/config/#app.config.load_duckdb_config","title":"<code>load_duckdb_config()</code>","text":"<p>Load DuckDB config from YAML file with hardcoded defaults.</p> Source code in <code>backend/app/config.py</code> <pre><code>def load_duckdb_config() -&gt; DuckDBConfig:\n    \"\"\"Load DuckDB config from YAML file with hardcoded defaults.\"\"\"\n    config = DuckDBConfig()\n\n    if DUCKDB_CONFIG_PATH.exists():\n        try:\n            with DUCKDB_CONFIG_PATH.open() as f:\n                yaml_config: dict[str, Any] = yaml.safe_load(f) or {}\n\n            if yaml_config.get(\"duckdb\"):\n                db_config = yaml_config[\"duckdb\"]\n                legacy_auto_sync = db_config.get(\"auto_sync_on_startup\")\n                if \"sync_mode\" in db_config:\n                    sync_mode = db_config.get(\"sync_mode\", \"startup\")\n                else:\n                    # Backward compatibility: infer mode from legacy boolean.\n                    sync_mode = \"startup\" if legacy_auto_sync is not False else \"manual\"\n                config = DuckDBConfig(\n                    enabled=db_config.get(\"enabled\", True),\n                    path=db_config.get(\"path\", \"data/local_store.duckdb\"),\n                    sync_mode=sync_mode,\n                    auto_sync_on_startup=legacy_auto_sync if legacy_auto_sync is not None else True,\n                    sync_chunk_size=db_config.get(\"sync_chunk_size\", 10_000),\n                    max_sync_rows=db_config.get(\"max_sync_rows\", 2_000_000),\n                    query_concurrency=db_config.get(\"query_concurrency\", 8),\n                    sync_workers=db_config.get(\"sync_workers\", 1),\n                )\n                logger.info(f\"Loaded DuckDB config from {DUCKDB_CONFIG_PATH}\")\n                return config\n        except Exception as e:\n            logger.warning(f\"Failed to load DuckDB YAML config: {e}\")\n\n    return config\n</code></pre>"},{"location":"api-reference/backend/config/#app.config.load_theme_config","title":"<code>load_theme_config()</code>","text":"<p>Load theme configuration from YAML file first, then env vars.</p> <p>Env vars can override individual colors.</p> Source code in <code>backend/app/config.py</code> <pre><code>def load_theme_config() -&gt; ThemeConfig:\n    \"\"\"Load theme configuration from YAML file first, then env vars.\n\n    Env vars can override individual colors.\n    \"\"\"\n    config = ThemeConfig()\n\n    # Try loading from YAML config file first\n    if THEME_CONFIG_PATH.exists():\n        try:\n            with THEME_CONFIG_PATH.open() as f:\n                yaml_config: dict[str, Any] = yaml.safe_load(f) or {}\n\n            if yaml_config.get(\"theme\"):\n                theme_data = yaml_config[\"theme\"]\n\n                # Load active palette name\n                if theme_data.get(\"active\"):\n                    config.active = theme_data[\"active\"]\n\n                # Load custom palettes\n                if theme_data.get(\"palettes\"):\n                    for palette_name, palette_data in theme_data[\"palettes\"].items():\n                        config.palettes[palette_name] = ThemePalette(\n                            name=palette_data.get(\"name\", palette_name),\n                            primary=palette_data.get(\"primary\", \"#8B9F4F\"),\n                            primaryLight=palette_data.get(\"primaryLight\", \"#A4B86C\"),\n                            primaryDark=palette_data.get(\"primaryDark\", \"#6B7A3A\"),\n                            primarySoft=palette_data.get(\"primarySoft\", \"#B8C78A\"),\n                            primaryPale=palette_data.get(\"primaryPale\", \"#D4E0B8\"),\n                            accentGold=palette_data.get(\"accentGold\", \"#D4AF37\"),\n                            accentSilver=palette_data.get(\"accentSilver\", \"#B8C5D3\"),\n                            heroImage=palette_data.get(\"heroImage\"),\n                            logoUrl=palette_data.get(\"logoUrl\"),\n                            faviconUrl=palette_data.get(\"faviconUrl\"),\n                            appIconUrl=palette_data.get(\"appIconUrl\"),\n                            heroContrast=palette_data.get(\"heroContrast\"),\n                            heroSaturation=palette_data.get(\"heroSaturation\"),\n                            heroBrightness=palette_data.get(\"heroBrightness\"),\n                            heroOpacity=palette_data.get(\"heroOpacity\"),\n                            heroMode=palette_data.get(\"heroMode\"),\n                        )\n\n                # Load branding config\n                if theme_data.get(\"branding\"):\n                    branding_data = theme_data[\"branding\"]\n                    config.branding = BrandingConfig(\n                        app_name=branding_data.get(\"app_name\", \"AXIS\"),\n                        tagline=branding_data.get(\"tagline\", \"AI Evaluation Platform\"),\n                        subtitle=branding_data.get(\"subtitle\", \"The AI Evaluation Studio\"),\n                        description=branding_data.get(\n                            \"description\", \"Agent X-ray Interface &amp; Statistics\"\n                        ),\n                        report_footer=branding_data.get(\n                            \"report_footer\",\n                            \"Report generated by AXIS AI Evaluation Platform\",\n                        ),\n                        docs_url=branding_data.get(\n                            \"docs_url\",\n                            \"https://ax-foundry.github.io/axis/\",\n                        ),\n                        footer_name=branding_data.get(\"footer_name\", \"\"),\n                        footer_icon=branding_data.get(\"footer_icon\", \"\"),\n                    )\n\n                logger.info(f\"Loaded theme config from {THEME_CONFIG_PATH}\")\n        except Exception as e:\n            logger.warning(f\"Failed to load theme YAML config: {e}\")\n\n    # Override with env vars if set\n    if settings.axis_theme_active:\n        config.active = settings.axis_theme_active\n        logger.info(f\"Theme active palette overridden by env: {config.active}\")\n\n    # If individual color env vars are set, create/modify the active palette\n    # Check if any env override is set\n    has_overrides = any(\n        v is not None\n        for v in [\n            settings.axis_theme_primary,\n            settings.axis_theme_primary_light,\n            settings.axis_theme_primary_dark,\n            settings.axis_theme_primary_soft,\n            settings.axis_theme_primary_pale,\n            settings.axis_theme_accent_gold,\n            settings.axis_theme_accent_silver,\n            settings.axis_theme_hero_image,\n            settings.axis_theme_logo_url,\n            settings.axis_theme_favicon_url,\n            settings.axis_theme_app_icon_url,\n            settings.axis_theme_hero_contrast,\n            settings.axis_theme_hero_saturation,\n            settings.axis_theme_hero_brightness,\n            settings.axis_theme_hero_opacity,\n            settings.axis_theme_hero_mode,\n        ]\n    )\n\n    if has_overrides:\n        # Get current active palette as base\n        base_palette = config.get_active_palette()\n\n        # Create new palette with overrides (access settings directly for type safety)\n        config.palettes[config.active] = ThemePalette(\n            name=base_palette.name,\n            primary=settings.axis_theme_primary or base_palette.primary,\n            primaryLight=settings.axis_theme_primary_light or base_palette.primaryLight,\n            primaryDark=settings.axis_theme_primary_dark or base_palette.primaryDark,\n            primarySoft=settings.axis_theme_primary_soft or base_palette.primarySoft,\n            primaryPale=settings.axis_theme_primary_pale or base_palette.primaryPale,\n            accentGold=settings.axis_theme_accent_gold or base_palette.accentGold,\n            accentSilver=settings.axis_theme_accent_silver or base_palette.accentSilver,\n            heroImage=settings.axis_theme_hero_image or base_palette.heroImage,\n            logoUrl=settings.axis_theme_logo_url or base_palette.logoUrl,\n            faviconUrl=settings.axis_theme_favicon_url or base_palette.faviconUrl,\n            appIconUrl=settings.axis_theme_app_icon_url or base_palette.appIconUrl,\n            heroContrast=settings.axis_theme_hero_contrast\n            if settings.axis_theme_hero_contrast is not None\n            else base_palette.heroContrast,\n            heroSaturation=settings.axis_theme_hero_saturation\n            if settings.axis_theme_hero_saturation is not None\n            else base_palette.heroSaturation,\n            heroBrightness=settings.axis_theme_hero_brightness\n            if settings.axis_theme_hero_brightness is not None\n            else base_palette.heroBrightness,\n            heroOpacity=settings.axis_theme_hero_opacity\n            if settings.axis_theme_hero_opacity is not None\n            else base_palette.heroOpacity,\n            heroMode=settings.axis_theme_hero_mode or base_palette.heroMode,\n        )\n        logger.info(\"Theme palette overridden by environment variables\")\n\n    return config\n</code></pre>"},{"location":"api-reference/backend/config/#app.config.load_agents_config","title":"<code>load_agents_config()</code>","text":"<p>Load agent registry from YAML config file.</p> <p>Returns an empty list if the file doesn't exist or is malformed.</p> Source code in <code>backend/app/config.py</code> <pre><code>def load_agents_config() -&gt; list[AgentConfig]:\n    \"\"\"Load agent registry from YAML config file.\n\n    Returns an empty list if the file doesn't exist or is malformed.\n    \"\"\"\n    if not AGENTS_CONFIG_PATH.exists():\n        logger.info(f\"No agents config found at {AGENTS_CONFIG_PATH}, using empty registry\")\n        return []\n\n    try:\n        with AGENTS_CONFIG_PATH.open() as f:\n            yaml_config: dict[str, Any] = yaml.safe_load(f) or {}\n\n        agents_data = yaml_config.get(\"agents\", [])\n        if not isinstance(agents_data, list):\n            logger.warning(\"agents.yaml 'agents' key is not a list, using empty registry\")\n            return []\n\n        agents = []\n        for entry in agents_data:\n            if isinstance(entry, dict) and entry.get(\"name\"):\n                agents.append(\n                    AgentConfig(\n                        name=entry[\"name\"],\n                        label=str(entry.get(\"label\", entry[\"name\"])),\n                        role=entry.get(\"role\"),\n                        avatar=entry.get(\"avatar\"),\n                        description=entry.get(\"description\"),\n                        biography=entry.get(\"biography\"),\n                        active=entry.get(\"active\", True),\n                        trace_names=entry.get(\"trace_names\", []),\n                    )\n                )\n\n        logger.info(f\"Loaded {len(agents)} agent(s) from {AGENTS_CONFIG_PATH}\")\n        return agents\n    except Exception as e:\n        logger.warning(f\"Failed to load agents config: {e}\")\n        return []\n</code></pre>"},{"location":"api-reference/backend/data-processor/","title":"Data Processor","text":"<p>CSV parsing, format detection, data transformation, and column normalization.</p>"},{"location":"api-reference/backend/data-processor/#app.services.data_processor-classes","title":"Classes","text":""},{"location":"api-reference/backend/data-processor/#app.services.data_processor-functions","title":"Functions","text":""},{"location":"api-reference/backend/data-processor/#app.services.data_processor.detect_data_format","title":"<code>detect_data_format(df)</code>","text":"<p>Detect the format of uploaded data.</p> <p>Returns one of: - \"eval_runner\": New evaluation runner output format with run_id, dataset_id, passed - \"tree_format\": Hierarchical metrics with parent relationships - \"flat_format\": Simple metric scores in long format - \"simple_judgment\": Binary pass/fail judgments - \"fresh_annotation\": Raw outputs for annotation - \"unknown\": Could not detect format</p> Source code in <code>backend/app/services/data_processor.py</code> <pre><code>def detect_data_format(df: pd.DataFrame) -&gt; str:\n    \"\"\"Detect the format of uploaded data.\n\n    Returns one of:\n    - \"eval_runner\": New evaluation runner output format with run_id, dataset_id, passed\n    - \"tree_format\": Hierarchical metrics with parent relationships\n    - \"flat_format\": Simple metric scores in long format\n    - \"simple_judgment\": Binary pass/fail judgments\n    - \"fresh_annotation\": Raw outputs for annotation\n    - \"unknown\": Could not detect format\n    \"\"\"\n    # Check for new eval_runner format (has run_id, dataset_id, passed fields)\n    eval_runner_fields = [\"run_id\", \"dataset_id\", \"passed\"]\n    if all(col in df.columns for col in eval_runner_fields):\n        return \"eval_runner\"\n\n    # Check for tree format\n    tree_columns = [Columns.METRIC_NAME, Columns.PARENT, Columns.METRIC_TYPE, Columns.METRIC_SCORE]\n    if all(col in df.columns for col in tree_columns):\n        return \"tree_format\"\n\n    # Check for flat scores format\n    if Columns.METRIC_NAME in df.columns and Columns.METRIC_SCORE in df.columns:\n        return \"flat_format\"\n\n    # Check for simple judgment format\n    if \"judgment\" in df.columns:\n        return \"simple_judgment\"\n\n    # Check for fresh annotation format\n    required_fresh = [\n        Columns.DATASET_ID,\n        Columns.EXPERIMENT_NAME,\n        Columns.QUERY,\n        Columns.ACTUAL_OUTPUT,\n    ]\n    if all(col in df.columns for col in required_fresh):\n        return \"fresh_annotation\"\n\n    return \"unknown\"\n</code></pre>"},{"location":"api-reference/backend/data-processor/#app.services.data_processor.detect_tree_format","title":"<code>detect_tree_format(df)</code>","text":"<p>Check if the uploaded data is in tree format.</p> Source code in <code>backend/app/services/data_processor.py</code> <pre><code>def detect_tree_format(df: pd.DataFrame) -&gt; bool:\n    \"\"\"Check if the uploaded data is in tree format.\"\"\"\n    tree_columns = [Columns.METRIC_NAME, Columns.PARENT, Columns.METRIC_TYPE, Columns.METRIC_SCORE]\n    return all(col in df.columns for col in tree_columns)\n</code></pre>"},{"location":"api-reference/backend/data-processor/#app.services.data_processor.add_default_product","title":"<code>add_default_product(df)</code>","text":"<p>Add default metadata values.</p> Source code in <code>backend/app/services/data_processor.py</code> <pre><code>def add_default_product(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Add default metadata values.\"\"\"\n    needs_default = Columns.METADATA not in df.columns or (\n        pd.isnull(df[Columns.METADATA].values[0]) if len(df) &gt; 0 else True\n    )\n    if Columns.ADD_DEFAULT_PRODUCT and needs_default:\n        df[Columns.METADATA] = \"{}\"\n    return df\n</code></pre>"},{"location":"api-reference/backend/data-processor/#app.services.data_processor.add_columns_to_flat_format","title":"<code>add_columns_to_flat_format(df)</code>","text":"<p>Add empty columns to flat format dataset for tree visualization compatibility.</p> Source code in <code>backend/app/services/data_processor.py</code> <pre><code>def add_columns_to_flat_format(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Add empty columns to flat format dataset for tree visualization compatibility.\"\"\"\n    df = df.copy()\n    df[Columns.METRIC_TYPE] = \"metric\"\n    df = add_default_product(df)\n    df[Columns.PARENT] = None\n    df[Columns.WEIGHT] = None\n    return df\n</code></pre>"},{"location":"api-reference/backend/data-processor/#app.services.data_processor.back_compatible_naming","title":"<code>back_compatible_naming(df)</code>","text":"<p>Apply backwards-compatible column renames.</p> Source code in <code>backend/app/services/data_processor.py</code> <pre><code>def back_compatible_naming(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Apply backwards-compatible column renames.\"\"\"\n    renames = {\n        \"experiment_name\": \"evaluation_name\",\n        \"experiment_metadata\": \"evaluation_metadata\",\n    }\n    return df.rename(columns=renames)\n</code></pre>"},{"location":"api-reference/backend/data-processor/#app.services.data_processor.safe_literal_eval","title":"<code>safe_literal_eval(val)</code>","text":"<p>Safely evaluate a string as a Python literal.</p> Source code in <code>backend/app/services/data_processor.py</code> <pre><code>def safe_literal_eval(val: Any) -&gt; Any:\n    \"\"\"Safely evaluate a string as a Python literal.\"\"\"\n    try:\n        return ast.literal_eval(val)\n    except (ValueError, SyntaxError):\n        return val\n</code></pre>"},{"location":"api-reference/backend/data-processor/#app.services.data_processor.setup_fresh_annotation","title":"<code>setup_fresh_annotation(df_raw)</code>","text":"<p>Set up fresh annotation format.</p> Source code in <code>backend/app/services/data_processor.py</code> <pre><code>def setup_fresh_annotation(df_raw: pd.DataFrame) -&gt; pd.DataFrame | None:\n    \"\"\"Set up fresh annotation format.\"\"\"\n    try:\n        df = df_raw.copy()\n\n        # Validate required columns\n        required_cols = [\n            Columns.DATASET_ID,\n            Columns.EXPERIMENT_NAME,\n            Columns.QUERY,\n            Columns.ACTUAL_OUTPUT,\n        ]\n        missing_cols = [col for col in required_cols if col not in df.columns]\n\n        if missing_cols:\n            return None\n\n        # Add empty critique column\n        if Columns.CRITIQUE not in df.columns:\n            df[Columns.CRITIQUE] = \"\"\n\n        # Add experiment metadata if missing\n        if Columns.EXPERIMENT_METADATA not in df.columns:\n            df[Columns.EXPERIMENT_METADATA] = \"{}\"\n\n        return df\n\n    except Exception:\n        return None\n</code></pre>"},{"location":"api-reference/backend/data-processor/#app.services.data_processor.process_uploaded_data","title":"<code>process_uploaded_data(df_raw)</code>","text":"<p>Process uploaded data and return processed dataframe, format, and message.</p> <p>Parameters:</p> Name Type Description Default <code>df_raw</code> <code>DataFrame</code> <p>Raw DataFrame from uploaded file</p> required <p>Returns:</p> Type Description <code>tuple[DataFrame | None, str | None, str]</code> <p>Tuple of (processed_df, format_type, message)</p> Source code in <code>backend/app/services/data_processor.py</code> <pre><code>def process_uploaded_data(df_raw: pd.DataFrame) -&gt; tuple[pd.DataFrame | None, str | None, str]:\n    \"\"\"Process uploaded data and return processed dataframe, format, and message.\n\n    Args:\n        df_raw: Raw DataFrame from uploaded file\n\n    Returns:\n        Tuple of (processed_df, format_type, message)\n    \"\"\"\n    try:\n        df_raw = back_compatible_naming(df_raw)\n\n        # First check if this is tree format data\n        if detect_tree_format(df_raw):\n            df = df_raw.copy()\n\n            # Clean the parent column - convert empty strings to None\n            df[Columns.PARENT] = df[Columns.PARENT].replace(\"\", None)\n            # Use mask to set NaN values to None (mask sets where condition is True)\n            df[Columns.PARENT] = df[Columns.PARENT].mask(pd.isna(df[Columns.PARENT]), None)\n\n            # Ensure we have required columns for the app\n            if Columns.DATASET_ID not in df.columns:\n                df[Columns.DATASET_ID] = \"test_case_1\"\n\n            if Columns.EXPERIMENT_NAME not in df.columns:\n                df[Columns.EXPERIMENT_NAME] = \"Experiment 1\"\n\n            if Columns.QUERY not in df.columns:\n                df[Columns.QUERY] = \"\"\n\n            if Columns.ACTUAL_OUTPUT not in df.columns:\n                df[Columns.ACTUAL_OUTPUT] = \"\"\n\n            if Columns.EXPECTED_OUTPUT not in df.columns:\n                df[Columns.EXPECTED_OUTPUT] = \"\"\n\n            if Columns.EXPERIMENT_METADATA not in df.columns:\n                df[Columns.EXPERIMENT_METADATA] = \"{}\"\n\n            # Add default metadata if nothing passed\n            df = add_default_product(df)\n\n            # Handle retrieved content if it exists\n            if Columns.RETRIEVED_CONTENT in df.columns:\n                df[Columns.RETRIEVED_CONTENT] = df[Columns.RETRIEVED_CONTENT].apply(\n                    lambda x: safe_literal_eval(x) if pd.notna(x) else []\n                )\n\n            # Add a critique column if it doesn't exist\n            if Columns.CRITIQUE not in df.columns:\n                df[Columns.CRITIQUE] = \"\"\n\n            root_nodes = df[df[Columns.PARENT].isna()][Columns.METRIC_NAME].unique()\n            message = f\"Tree format with {len(df)} nodes, root: {', '.join(root_nodes)}\"\n            return df, \"tree_format\", message\n\n        # If not tree format, detect other formats\n        data_format = detect_data_format(df_raw)\n\n        if data_format == \"flat_format\":\n            # Add columns for tree visual\n            df_raw = add_columns_to_flat_format(df_raw)\n            return process_uploaded_data(df_raw)\n\n        elif data_format == \"simple_judgment\":\n            df = df_raw.copy()\n            if \"judgment\" not in df.columns:\n                return (\n                    None,\n                    None,\n                    \"Simple judgment format requires a 'judgment' column with 1/0 values\",\n                )\n\n            if Columns.CRITIQUE not in df.columns:\n                df[Columns.CRITIQUE] = \"\"\n\n            message = f\"Simple judgment format with {len(df)} evaluations\"\n            return df, \"simple_judgment\", message\n\n        elif data_format == \"fresh_annotation\":\n            annotation_df = setup_fresh_annotation(df_raw)\n            if annotation_df is None:\n                return None, None, \"Failed to set up fresh annotation format\"\n\n            message = f\"Fresh annotation for {len(annotation_df)} model outputs\"\n            return annotation_df, \"fresh_annotation\", message\n\n        else:\n            return (\n                None,\n                None,\n                \"Could not detect valid data format. Please check the sample formats.\",\n            )\n\n    except Exception as e:\n        return None, None, f\"Error processing file: {e!s}\"\n</code></pre>"},{"location":"api-reference/backend/data-processor/#app.services.data_processor.convert_to_csv","title":"<code>convert_to_csv(annotations)</code>","text":"<p>Convert annotations to CSV format for download.</p> Source code in <code>backend/app/services/data_processor.py</code> <pre><code>def convert_to_csv(annotations: dict[str, Any]) -&gt; str:\n    \"\"\"Convert annotations to CSV format for download.\"\"\"\n    if not annotations:\n        return \"\"\n\n    df = pd.DataFrame.from_dict(annotations, orient=\"index\")\n    result = df.to_csv(index=False)\n    return result if result is not None else \"\"\n</code></pre>"},{"location":"api-reference/backend/data-processor/#app.services.data_processor.get_metrics_for_format","title":"<code>get_metrics_for_format(df, data_format)</code>","text":"<p>Get metrics based on data format.</p> Source code in <code>backend/app/services/data_processor.py</code> <pre><code>def get_metrics_for_format(df: pd.DataFrame, data_format: str) -&gt; list[str]:\n    \"\"\"Get metrics based on data format.\"\"\"\n    if data_format == \"simple_judgment\":\n        return [\"judgment\"]\n    elif data_format == \"fresh_annotation\":\n        # Find all numeric columns except ID that aren't metadata\n        return [\n            col\n            for col in df.columns\n            if pd.api.types.is_numeric_dtype(df[col])\n            and col\n            not in [\n                Columns.DATASET_ID,\n                Columns.EXPERIMENT_NAME,\n                Columns.QUERY,\n                Columns.ACTUAL_OUTPUT,\n            ]\n        ]\n    elif data_format == \"tree_format\":\n        # For tree format, we'll handle this differently in the tree visualization\n        return []\n    else:  # flat\n        return [\n            col\n            for col in df.columns\n            if pd.api.types.is_numeric_dtype(df[col]) and col != Columns.DATASET_ID\n        ]\n</code></pre>"},{"location":"api-reference/backend/data-processor/#app.services.data_processor.identify_metric_component_mapping","title":"<code>identify_metric_component_mapping(df)</code>","text":"<p>Identify metrics and components in tree format data.</p> Source code in <code>backend/app/services/data_processor.py</code> <pre><code>def identify_metric_component_mapping(df: pd.DataFrame) -&gt; dict[str, list[str]]:\n    \"\"\"Identify metrics and components in tree format data.\"\"\"\n    metric_options = list(df[df[Columns.METRIC_TYPE] == \"metric\"][Columns.METRIC_NAME].unique())\n    component_options = list(\n        df[df[Columns.METRIC_TYPE] == \"component\"][Columns.METRIC_NAME].unique()\n    )\n    return {\"metrics\": metric_options, \"components\": component_options}\n</code></pre>"},{"location":"api-reference/backend/data-processor/#app.services.data_processor.drop_latency","title":"<code>drop_latency(df)</code>","text":"<p>Drop Latency Column if passed through config.</p> Source code in <code>backend/app/services/data_processor.py</code> <pre><code>def drop_latency(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Drop Latency Column if passed through config.\"\"\"\n    import contextlib\n\n    if (\n        Columns.DROP_LATENCY\n        and Columns.LATENCY.lower() in [col.lower() for col in df.columns]\n        and len(df) &gt; 0\n        and df[Columns.LATENCY].max() &gt; 1\n    ):\n        for col in [Columns.LATENCY, \"PERFORMANCE\"]:\n            with contextlib.suppress(KeyError, ValueError):\n                df = df.drop(col, axis=1)\n    return df\n</code></pre>"},{"location":"api-reference/backend/data-processor/#app.services.data_processor.convert_tree_to_wide_format","title":"<code>convert_tree_to_wide_format(df, metric_type=None, include_conversation=False)</code>","text":"<p>Convert tree format to wide format for analytics.</p> <p>Parameters:</p> Name Type Description Default <code>df</code> <code>DataFrame</code> <p>Input dataframe in tree format</p> required <code>metric_type</code> <code>str | None</code> <p>Optional metric type filter</p> <code>None</code> <code>include_conversation</code> <code>bool</code> <p>Whether to include conversation column</p> <code>False</code> <p>Returns:</p> Type Description <code>DataFrame</code> <p>Wide-format dataframe</p> Source code in <code>backend/app/services/data_processor.py</code> <pre><code>def convert_tree_to_wide_format(\n    df: pd.DataFrame, metric_type: str | None = None, include_conversation: bool = False\n) -&gt; pd.DataFrame:\n    \"\"\"Convert tree format to wide format for analytics.\n\n    Args:\n        df: Input dataframe in tree format\n        metric_type: Optional metric type filter\n        include_conversation: Whether to include conversation column\n\n    Returns:\n        Wide-format dataframe\n    \"\"\"\n    try:\n        metric_df = df[df[Columns.METRIC_TYPE] == metric_type].copy() if metric_type else df.copy()\n        if metric_df.empty:\n            return pd.DataFrame()\n\n        metric_df = add_default_product(metric_df)\n\n        index_cols = [\n            col\n            for col in [\n                Columns.DATASET_ID,\n                Columns.EXPERIMENT_NAME,\n                Columns.QUERY,\n                Columns.ACTUAL_OUTPUT,\n                Columns.EXPERIMENT_METADATA,\n                Columns.METADATA,\n            ]\n            if col in metric_df.columns\n        ]\n\n        if include_conversation and Columns.CONVERSATION in metric_df.columns:\n            index_cols.append(Columns.CONVERSATION)\n\n        if len(index_cols) &lt; 2:\n            return pd.DataFrame()\n\n        wide_df = metric_df.pivot_table(\n            index=index_cols,\n            columns=Columns.METRIC_NAME,\n            values=Columns.METRIC_SCORE,\n            aggfunc=\"first\",\n        ).reset_index()\n\n        wide_df = drop_latency(wide_df)\n        wide_df.columns.name = None\n        return wide_df\n\n    except Exception:\n        return pd.DataFrame()\n</code></pre>"},{"location":"api-reference/backend/data-processor/#app.services.data_processor.prepare_data_for_analytics","title":"<code>prepare_data_for_analytics(data, data_format, metric_type=None, include_conversation=False)</code>","text":"<p>Prepare data for analytics display.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <code>list[dict[str, Any]]</code> <p>List or dict-like structure containing analytics data</p> required <code>data_format</code> <code>str</code> <p>'tree_format' or 'simple_judgment'</p> required <code>metric_type</code> <code>str | None</code> <p>Filter for specific metric type</p> <code>None</code> <code>include_conversation</code> <code>bool</code> <p>Whether to include conversation column in output</p> <code>False</code> <p>Returns:</p> Name Type Description <code>Tuple</code> <code>tuple[DataFrame, list[str], dict[str, list[str]]]</code> <p>(processed DataFrame, metric_columns list, mapping dict)</p> Source code in <code>backend/app/services/data_processor.py</code> <pre><code>def prepare_data_for_analytics(\n    data: list[dict[str, Any]],\n    data_format: str,\n    metric_type: str | None = None,\n    include_conversation: bool = False,\n) -&gt; tuple[pd.DataFrame, list[str], dict[str, list[str]]]:\n    \"\"\"Prepare data for analytics display.\n\n    Args:\n        data: List or dict-like structure containing analytics data\n        data_format: 'tree_format' or 'simple_judgment'\n        metric_type: Filter for specific metric type\n        include_conversation: Whether to include conversation column in output\n\n    Returns:\n        Tuple: (processed DataFrame, metric_columns list, mapping dict)\n    \"\"\"\n    if not data:\n        return pd.DataFrame(), [], {}\n\n    df = pd.DataFrame(data)\n    df = back_compatible_naming(df)\n    mapping = (\n        identify_metric_component_mapping(df)\n        if Columns.METRIC_TYPE in df.columns\n        else {\"metrics\": [], \"components\": []}\n    )\n\n    if data_format == \"tree_format\":\n        df = convert_tree_to_wide_format(df, metric_type, include_conversation)\n        if df.empty:\n            return pd.DataFrame(), [], mapping\n\n    elif data_format == \"simple_judgment\":\n        df = df.copy()\n        metric_columns = [\"judgment\"]\n        return df, metric_columns, mapping\n\n    index_cols = [\n        Columns.DATASET_ID,\n        Columns.EXPERIMENT_NAME,\n        Columns.QUERY,\n        Columns.ACTUAL_OUTPUT,\n        Columns.EXPECTED_OUTPUT,\n        Columns.EXPERIMENT_METADATA,\n        Columns.METADATA,\n    ]\n    if include_conversation and Columns.CONVERSATION in df.columns:\n        index_cols.append(Columns.CONVERSATION)\n    if data_format != \"tree_format\":\n        index_cols.append(Columns.CRITIQUE)\n\n    metric_columns = [\n        col\n        for col in df.columns\n        if col not in index_cols and pd.api.types.is_numeric_dtype(df[col])\n    ]\n\n    if include_conversation and Columns.CONVERSATION in df.columns:\n        df[Columns.CONVERSATION] = df[Columns.CONVERSATION].map(\n            lambda x: ast.literal_eval(x) if isinstance(x, str) else x\n        )\n\n    return df, metric_columns, mapping\n</code></pre>"},{"location":"api-reference/backend/data-processor/#app.services.data_processor.parse_json","title":"<code>parse_json(data)</code>","text":"<p>Parses a string that may be malformed, double-encoded, or a Python literal.</p> <p>This version correctly handles python-specific values like nan, inf, and booleans.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>A dictionary object. Returns an empty dict ({}) if all parsing attempts fail.</p> Source code in <code>backend/app/services/data_processor.py</code> <pre><code>def parse_json(data: str) -&gt; dict[str, Any]:\n    \"\"\"Parses a string that may be malformed, double-encoded, or a Python literal.\n\n    This version correctly handles python-specific values like nan, inf, and booleans.\n\n    Returns:\n        A dictionary object. Returns an empty dict ({}) if all parsing attempts fail.\n    \"\"\"\n    if not isinstance(data, str) or not data.strip():\n        return {}\n\n    s = data.strip()\n\n    try:\n        loaded = json.loads(s)\n        if isinstance(loaded, dict):\n            return loaded\n        return {}\n    except json.JSONDecodeError:\n        pass\n\n    try:\n        s = re.sub(r\"\\btrue\\b\", \"True\", s)\n        s = re.sub(r\"\\bfalse\\b\", \"False\", s)\n        s = s.replace(\"nan\", \"None\").replace(\"inf\", \"None\").replace(\"-inf\", \"None\")\n        result = ast.literal_eval(s)\n        if isinstance(result, dict):\n            return result\n        if isinstance(result, str):\n            loaded = json.loads(result)\n            if isinstance(loaded, dict):\n                return loaded\n            return {}\n\n    except (ValueError, SyntaxError, MemoryError, json.JSONDecodeError):\n        return {}\n\n    return {}\n</code></pre>"},{"location":"api-reference/backend/data-processor/#app.services.data_processor.process_database_data","title":"<code>process_database_data(df)</code>","text":"<p>Process data coming from database format.</p> Source code in <code>backend/app/services/data_processor.py</code> <pre><code>def process_database_data(df: pd.DataFrame) -&gt; pd.DataFrame:\n    \"\"\"Process data coming from database format.\"\"\"\n    renames = {\n        \"question_id\": Columns.DATASET_ID,\n        \"retriever\": Columns.EXPERIMENT_NAME,\n        \"input\": Columns.QUERY,\n        \"name\": Columns.METRIC_NAME,\n        \"score\": Columns.METRIC_SCORE,\n        \"reason\": Columns.EXPLANATION,\n        \"retrieval_chunks\": Columns.RETRIEVED_CONTENT,\n    }\n    df = df.rename(columns=renames)\n    df = add_columns_to_flat_format(df)\n    return df\n</code></pre>"},{"location":"api-reference/backend/database-service/","title":"Database Service","text":"<p>PostgreSQL connection management, schema introspection, and data import.</p>"},{"location":"api-reference/backend/database-service/#app.services.database_service-classes","title":"Classes","text":""},{"location":"api-reference/backend/database-service/#app.services.database_service.DatabaseServiceError","title":"<code>DatabaseServiceError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for database service errors.</p>"},{"location":"api-reference/backend/database-service/#app.services.database_service.ConnectionExpiredError","title":"<code>ConnectionExpiredError</code>","text":"<p>               Bases: <code>DatabaseServiceError</code></p> <p>Raised when a connection handle has expired.</p>"},{"location":"api-reference/backend/database-service/#app.services.database_service.TableNotFoundError","title":"<code>TableNotFoundError</code>","text":"<p>               Bases: <code>DatabaseServiceError</code></p> <p>Raised when a table is not found.</p>"},{"location":"api-reference/backend/database-service/#app.services.database_service.InvalidColumnError","title":"<code>InvalidColumnError</code>","text":"<p>               Bases: <code>DatabaseServiceError</code></p> <p>Raised when an invalid column is referenced.</p>"},{"location":"api-reference/backend/database-service/#app.services.database_service.QuerySafetyError","title":"<code>QuerySafetyError</code>","text":"<p>               Bases: <code>DatabaseServiceError</code></p> <p>Raised when a query violates safety constraints.</p>"},{"location":"api-reference/backend/database-service/#app.services.database_service-functions","title":"Functions","text":""},{"location":"api-reference/backend/database-service/#app.services.database_service.connect","title":"<code>connect(conn)</code>  <code>async</code>","text":"<p>Test connection and create a handle if successful.</p> <p>Parameters:</p> Name Type Description Default <code>conn</code> <code>DatabaseConnectionRequest</code> <p>Database connection request</p> required <p>Returns:</p> Type Description <code>tuple[str, str | None]</code> <p>Tuple of (handle, version) where version is the database version string</p> <p>Raises:</p> Type Description <code>DatabaseServiceError</code> <p>If connection fails</p> Source code in <code>backend/app/services/database_service.py</code> <pre><code>async def connect(conn: DatabaseConnectionRequest) -&gt; tuple[str, str | None]:\n    \"\"\"Test connection and create a handle if successful.\n\n    Args:\n        conn: Database connection request\n\n    Returns:\n        Tuple of (handle, version) where version is the database version string\n\n    Raises:\n        DatabaseServiceError: If connection fails\n    \"\"\"\n    store = get_connection_store()\n    backend = get_backend(conn.db_type)\n\n    encoded_password = quote_plus(conn.password.get_secret_value())\n    url = (\n        f\"postgresql://{conn.username}:{encoded_password}\"\n        f\"@{conn.host}:{conn.port}/{conn.database}\"\n    )\n    ssl_mode = conn.ssl_mode.value if conn.ssl_mode.value != \"disable\" else None\n\n    try:\n        version = await backend.test_connection(\n            url,\n            ssl_mode=ssl_mode,\n            connect_timeout=CONNECT_TIMEOUT,\n            statement_timeout_ms=QUERY_TIMEOUT_MS,\n        )\n\n        handle = store.create_handle(\n            host=conn.host,\n            port=conn.port,\n            database=conn.database,\n            username=conn.username,\n            password=conn.password.get_secret_value(),\n            ssl_mode=conn.ssl_mode.value,\n            db_type=conn.db_type,\n        )\n\n        logger.info(f\"Database connection successful: {conn.database}\")\n        return handle, version\n\n    except TimeoutError:\n        raise DatabaseServiceError(\n            f\"Connection timed out after {CONNECT_TIMEOUT} seconds. \"\n            \"Please verify the host is reachable from this server.\"\n        )\n    except Exception as e:\n        error_msg = str(e)\n        if \"password\" in error_msg.lower():\n            error_msg = \"Authentication failed. Please check your credentials.\"\n        elif \"could not connect\" in error_msg.lower() or \"connection refused\" in error_msg.lower():\n            error_msg = (\n                \"Could not connect to database. Please verify: \"\n                \"1) Host and port are correct, \"\n                \"2) Database is running and accepting connections, \"\n                \"3) Firewall allows connections from this server.\"\n            )\n        elif \"does not exist\" in error_msg.lower():\n            error_msg = f\"Database '{conn.database}' does not exist.\"\n        else:\n            logger.error(f\"Database connection error: {e}\")\n            error_msg = f\"Connection failed: {error_msg}\"\n        raise DatabaseServiceError(error_msg)\n</code></pre>"},{"location":"api-reference/backend/database-service/#app.services.database_service.list_tables","title":"<code>list_tables(handle)</code>  <code>async</code>","text":"<p>List tables with estimated row counts.</p> <p>Parameters:</p> Name Type Description Default <code>handle</code> <code>str</code> <p>Connection handle</p> required <p>Returns:</p> Type Description <code>list[TableInfo]</code> <p>List of table information</p> <p>Raises:</p> Type Description <code>ConnectionExpiredError</code> <p>If handle is invalid or expired</p> Source code in <code>backend/app/services/database_service.py</code> <pre><code>async def list_tables(handle: str) -&gt; list[TableInfo]:\n    \"\"\"List tables with estimated row counts.\n\n    Args:\n        handle: Connection handle\n\n    Returns:\n        List of table information\n\n    Raises:\n        ConnectionExpiredError: If handle is invalid or expired\n    \"\"\"\n    conn_info = _get_connection_info(handle)\n    url = _build_url(conn_info)\n    ssl = conn_info.ssl_mode if conn_info.ssl_mode != \"disable\" else None\n    backend = get_backend(conn_info.db_type)\n    catalog = get_catalog(conn_info.db_type)\n\n    try:\n        async with backend.pooled_connection(\n            url, ssl_mode=ssl, statement_timeout_ms=QUERY_TIMEOUT_MS\n        ) as pg:\n            rows = await catalog.list_tables(pg)\n\n            tables = [\n                TableInfo(\n                    schema_name=row[\"schema_name\"],\n                    name=row[\"table_name\"],\n                    row_count_estimate=max(0, int(row[\"row_estimate\"])),\n                )\n                for row in rows\n            ]\n\n            logger.debug(f\"Found {len(tables)} tables/views for handle {handle[:8]}...\")\n            return tables\n\n    except Exception as e:\n        logger.error(f\"Error listing tables: {e}\")\n        raise DatabaseServiceError(f\"Failed to list tables/views: {e}\")\n</code></pre>"},{"location":"api-reference/backend/database-service/#app.services.database_service.get_schema","title":"<code>get_schema(handle, table)</code>  <code>async</code>","text":"<p>Get column schema and sample values for a table.</p> <p>Parameters:</p> Name Type Description Default <code>handle</code> <code>str</code> <p>Connection handle</p> required <code>table</code> <code>TableIdentifier</code> <p>Table identifier</p> required <p>Returns:</p> Type Description <code>TableSchemaResponse</code> <p>Table schema response with columns and sample values</p> <p>Raises:</p> Type Description <code>ConnectionExpiredError</code> <p>If handle is invalid or expired</p> <code>TableNotFoundError</code> <p>If table doesn't exist</p> Source code in <code>backend/app/services/database_service.py</code> <pre><code>async def get_schema(handle: str, table: TableIdentifier) -&gt; TableSchemaResponse:\n    \"\"\"Get column schema and sample values for a table.\n\n    Args:\n        handle: Connection handle\n        table: Table identifier\n\n    Returns:\n        Table schema response with columns and sample values\n\n    Raises:\n        ConnectionExpiredError: If handle is invalid or expired\n        TableNotFoundError: If table doesn't exist\n    \"\"\"\n    conn_info = _get_connection_info(handle)\n    url = _build_url(conn_info)\n    ssl = conn_info.ssl_mode if conn_info.ssl_mode != \"disable\" else None\n    backend = get_backend(conn_info.db_type)\n    catalog = get_catalog(conn_info.db_type)\n\n    try:\n        async with backend.pooled_connection(\n            url, ssl_mode=ssl, statement_timeout_ms=QUERY_TIMEOUT_MS\n        ) as pg:\n            # Verify table exists\n            if not await catalog.table_exists(pg, table.schema_name, table.name):\n                raise TableNotFoundError(f\"Table '{table.schema_name}.{table.name}' not found\")\n\n            # Get column information\n            column_rows = await catalog.get_columns(pg, table.schema_name, table.name)\n\n            columns = [\n                ColumnInfo(\n                    name=r[\"column_name\"],\n                    data_type=r[\"data_type\"],\n                    nullable=r[\"is_nullable\"] == \"YES\",\n                )\n                for r in column_rows\n            ]\n\n            # Get sample values (first 5 rows)\n            sample_values: dict[str, list[Any]] = {}\n            if columns:\n                column_names = [col.name for col in columns]\n                quoted_columns = \", \".join(\n                    [backend.quote_identifier(name) for name in column_names]\n                )\n                quoted_table = backend.quote_table(table.schema_name, table.name)\n\n                sample_rows = await pg.fetch_all(\n                    f\"SELECT {quoted_columns} FROM {quoted_table} LIMIT 5\"\n                )\n\n                for col in columns:\n                    sample_values[col.name] = [_serialize_value(r[col.name]) for r in sample_rows]\n\n            return TableSchemaResponse(\n                success=True,\n                columns=columns,\n                sample_values=sample_values,\n            )\n\n    except TableNotFoundError:\n        raise\n    except Exception as e:\n        logger.error(f\"Error getting schema: {e}\")\n        raise DatabaseServiceError(f\"Failed to get table schema: {e}\")\n</code></pre>"},{"location":"api-reference/backend/database-service/#app.services.database_service.get_distinct_values","title":"<code>get_distinct_values(handle, table, column, limit=100)</code>  <code>async</code>","text":"<p>Get distinct values for a column (for filter dropdowns).</p> <p>Parameters:</p> Name Type Description Default <code>handle</code> <code>str</code> <p>Connection handle</p> required <code>table</code> <code>TableIdentifier</code> <p>Table identifier</p> required <code>column</code> <code>str</code> <p>Column name</p> required <code>limit</code> <code>int</code> <p>Maximum values to return</p> <code>100</code> <p>Returns:</p> Type Description <code>list[str]</code> <p>List of distinct values as strings</p> <p>Raises:</p> Type Description <code>ConnectionExpiredError</code> <p>If handle is invalid or expired</p> <code>InvalidColumnError</code> <p>If column doesn't exist</p> Source code in <code>backend/app/services/database_service.py</code> <pre><code>async def get_distinct_values(\n    handle: str, table: TableIdentifier, column: str, limit: int = 100\n) -&gt; list[str]:\n    \"\"\"Get distinct values for a column (for filter dropdowns).\n\n    Args:\n        handle: Connection handle\n        table: Table identifier\n        column: Column name\n        limit: Maximum values to return\n\n    Returns:\n        List of distinct values as strings\n\n    Raises:\n        ConnectionExpiredError: If handle is invalid or expired\n        InvalidColumnError: If column doesn't exist\n    \"\"\"\n    conn_info = _get_connection_info(handle)\n    url = _build_url(conn_info)\n    ssl = conn_info.ssl_mode if conn_info.ssl_mode != \"disable\" else None\n    backend = get_backend(conn_info.db_type)\n    catalog = get_catalog(conn_info.db_type)\n\n    try:\n        async with backend.pooled_connection(\n            url, ssl_mode=ssl, statement_timeout_ms=QUERY_TIMEOUT_MS\n        ) as pg:\n            # Verify column exists\n            missing = await catalog.validate_columns(pg, table.schema_name, table.name, [column])\n            if missing:\n                raise InvalidColumnError(\n                    f\"Column '{column}' not found in table '{table.schema_name}.{table.name}'\"\n                )\n\n            # Get distinct values\n            quoted_table = backend.quote_table(table.schema_name, table.name)\n            quoted_column = backend.quote_identifier(column)\n            cast_col = backend.cast_to_text(quoted_column)\n            ph = backend.param_placeholder()\n\n            rows = await pg.fetch_all(\n                f\"SELECT DISTINCT {cast_col} AS val FROM {quoted_table} \"\n                f\"WHERE {quoted_column} IS NOT NULL \"\n                f\"ORDER BY {cast_col} \"\n                f\"LIMIT {ph}\",\n                (limit,),\n            )\n\n            return [str(r[\"val\"]) for r in rows]\n\n    except InvalidColumnError:\n        raise\n    except Exception as e:\n        logger.error(f\"Error getting distinct values: {e}\")\n        raise DatabaseServiceError(f\"Failed to get distinct values: {e}\")\n</code></pre>"},{"location":"api-reference/backend/database-service/#app.services.database_service.preview_data","title":"<code>preview_data(handle, table, mappings, filters=None, limit=10)</code>  <code>async</code>","text":"<p>Preview data with column mappings applied.</p> <p>Parameters:</p> Name Type Description Default <code>handle</code> <code>str</code> <p>Connection handle</p> required <code>table</code> <code>TableIdentifier</code> <p>Table identifier</p> required <code>mappings</code> <code>list[ColumnMapping]</code> <p>Column mappings to apply</p> required <code>filters</code> <code>list[FilterCondition] | None</code> <p>Optional filter conditions</p> <code>None</code> <code>limit</code> <code>int</code> <p>Number of rows to preview</p> <code>10</code> <p>Returns:</p> Type Description <code>list[dict[str, Any]]</code> <p>List of dictionaries with mapped column names</p> <p>Raises:</p> Type Description <code>ConnectionExpiredError</code> <p>If handle is invalid or expired</p> <code>InvalidColumnError</code> <p>If a mapped column doesn't exist</p> Source code in <code>backend/app/services/database_service.py</code> <pre><code>async def preview_data(\n    handle: str,\n    table: TableIdentifier,\n    mappings: list[ColumnMapping],\n    filters: list[FilterCondition] | None = None,\n    limit: int = 10,\n) -&gt; list[dict[str, Any]]:\n    \"\"\"Preview data with column mappings applied.\n\n    Args:\n        handle: Connection handle\n        table: Table identifier\n        mappings: Column mappings to apply\n        filters: Optional filter conditions\n        limit: Number of rows to preview\n\n    Returns:\n        List of dictionaries with mapped column names\n\n    Raises:\n        ConnectionExpiredError: If handle is invalid or expired\n        InvalidColumnError: If a mapped column doesn't exist\n    \"\"\"\n    conn_info = _get_connection_info(handle)\n    url = _build_url(conn_info)\n    ssl = conn_info.ssl_mode if conn_info.ssl_mode != \"disable\" else None\n    backend = get_backend(conn_info.db_type)\n    catalog = get_catalog(conn_info.db_type)\n\n    try:\n        async with backend.pooled_connection(\n            url, ssl_mode=ssl, statement_timeout_ms=QUERY_TIMEOUT_MS\n        ) as pg:\n            source_columns = [m.source for m in mappings]\n            await _validate_columns(pg, catalog, table, source_columns)\n\n            if filters:\n                filter_columns = [f.column for f in filters]\n                await _validate_columns(pg, catalog, table, filter_columns)\n\n            return await _execute_select(pg, backend, table, mappings, filters, limit)\n\n    except InvalidColumnError:\n        raise\n    except Exception as e:\n        logger.error(f\"Error previewing data: {e}\")\n        raise DatabaseServiceError(f\"Failed to preview data: {e}\")\n</code></pre>"},{"location":"api-reference/backend/database-service/#app.services.database_service.import_data","title":"<code>import_data(handle, table, mappings, filters=None, limit=10000, dedupe_on_id=True)</code>  <code>async</code>","text":"<p>Import data from database with column mappings.</p> <p>Parameters:</p> Name Type Description Default <code>handle</code> <code>str</code> <p>Connection handle</p> required <code>table</code> <code>TableIdentifier</code> <p>Table identifier</p> required <code>mappings</code> <code>list[ColumnMapping]</code> <p>Column mappings to apply</p> required <code>filters</code> <code>list[FilterCondition] | None</code> <p>Optional filter conditions</p> <code>None</code> <code>limit</code> <code>int</code> <p>Maximum rows to import</p> <code>10000</code> <code>dedupe_on_id</code> <code>bool</code> <p>Whether to deduplicate by id column</p> <code>True</code> <p>Returns:</p> Type Description <code>list[dict[str, Any]]</code> <p>List of dictionaries with mapped column names</p> <p>Raises:</p> Type Description <code>ConnectionExpiredError</code> <p>If handle is invalid or expired</p> <code>InvalidColumnError</code> <p>If a mapped column doesn't exist</p> Source code in <code>backend/app/services/database_service.py</code> <pre><code>async def import_data(\n    handle: str,\n    table: TableIdentifier,\n    mappings: list[ColumnMapping],\n    filters: list[FilterCondition] | None = None,\n    limit: int = 10000,\n    dedupe_on_id: bool = True,\n) -&gt; list[dict[str, Any]]:\n    \"\"\"Import data from database with column mappings.\n\n    Args:\n        handle: Connection handle\n        table: Table identifier\n        mappings: Column mappings to apply\n        filters: Optional filter conditions\n        limit: Maximum rows to import\n        dedupe_on_id: Whether to deduplicate by id column\n\n    Returns:\n        List of dictionaries with mapped column names\n\n    Raises:\n        ConnectionExpiredError: If handle is invalid or expired\n        InvalidColumnError: If a mapped column doesn't exist\n    \"\"\"\n    conn_info = _get_connection_info(handle)\n    url = _build_url(conn_info)\n    ssl = conn_info.ssl_mode if conn_info.ssl_mode != \"disable\" else None\n    backend = get_backend(conn_info.db_type)\n    catalog = get_catalog(conn_info.db_type)\n\n    try:\n        async with backend.pooled_connection(\n            url, ssl_mode=ssl, statement_timeout_ms=QUERY_TIMEOUT_MS\n        ) as pg:\n            source_columns = [m.source for m in mappings]\n            await _validate_columns(pg, catalog, table, source_columns)\n\n            if filters:\n                filter_columns = [f.column for f in filters]\n                await _validate_columns(pg, catalog, table, filter_columns)\n\n            all_data: list[dict[str, Any]] = []\n            offset = 0\n\n            while True:\n                chunk = await _execute_select(\n                    pg,\n                    backend,\n                    table,\n                    mappings,\n                    filters,\n                    min(CHUNK_SIZE, limit - len(all_data)),\n                    offset,\n                )\n\n                if not chunk:\n                    break\n\n                all_data.extend(chunk)\n                offset += len(chunk)\n\n                if len(all_data) &gt;= limit:\n                    break\n\n            # Apply deduplication if requested\n            if dedupe_on_id and all_data:\n                id_target = None\n                for m in mappings:\n                    if m.target == \"id\":\n                        id_target = \"id\"\n                        break\n\n                if id_target:\n                    # Long format: dedup on (id, metric_name) to keep all metrics\n                    has_metric_name = \"metric_name\" in all_data[0]\n                    seen_ids: set[Any] = set()\n                    deduped_data: list[dict[str, Any]] = []\n                    for row in all_data:\n                        dedup_key: Any\n                        if has_metric_name:\n                            dedup_key = (row.get(id_target), row.get(\"metric_name\"))\n                        else:\n                            dedup_key = row.get(id_target)\n                        if dedup_key not in seen_ids:\n                            seen_ids.add(dedup_key)\n                            deduped_data.append(row)\n                    all_data = deduped_data\n\n            logger.info(\n                f\"Imported {len(all_data)} rows from \"\n                f\"{table.schema_name}.{table.name} (handle {handle[:8]}...)\"\n            )\n\n            return all_data\n\n    except InvalidColumnError:\n        raise\n    except Exception as e:\n        logger.error(f\"Error importing data: {e}\")\n        raise DatabaseServiceError(f\"Failed to import data: {e}\")\n</code></pre>"},{"location":"api-reference/backend/database-service/#app.services.database_service.execute_query","title":"<code>execute_query(handle, query, limit=10, timeout_ms=60000)</code>  <code>async</code>","text":"<p>Execute an arbitrary SELECT query with safety guards.</p> <p>Safety layers: 1. Session-level read-only mode 2. Session-level statement timeout 3. Single-statement enforcement (done at schema validation) 4. LIMIT appended to query</p> <p>Parameters:</p> Name Type Description Default <code>handle</code> <code>str</code> <p>Connection handle</p> required <code>query</code> <code>str</code> <p>SQL query (already validated by schema)</p> required <code>limit</code> <code>int</code> <p>Maximum rows to return</p> <code>10</code> <code>timeout_ms</code> <code>int</code> <p>Statement timeout in milliseconds</p> <code>60000</code> <p>Returns:</p> Type Description <code>list[dict[str, Any]]</code> <p>List of result dictionaries</p> Source code in <code>backend/app/services/database_service.py</code> <pre><code>async def execute_query(\n    handle: str,\n    query: str,\n    limit: int = 10,\n    timeout_ms: int = 60000,\n) -&gt; list[dict[str, Any]]:\n    \"\"\"Execute an arbitrary SELECT query with safety guards.\n\n    Safety layers:\n    1. Session-level read-only mode\n    2. Session-level statement timeout\n    3. Single-statement enforcement (done at schema validation)\n    4. LIMIT appended to query\n\n    Args:\n        handle: Connection handle\n        query: SQL query (already validated by schema)\n        limit: Maximum rows to return\n        timeout_ms: Statement timeout in milliseconds\n\n    Returns:\n        List of result dictionaries\n    \"\"\"\n    conn_info = _get_connection_info(handle)\n    url = _build_url(conn_info)\n    ssl = conn_info.ssl_mode if conn_info.ssl_mode != \"disable\" else None\n    backend = get_backend(conn_info.db_type)\n\n    try:\n        async with backend.pooled_connection(\n            url, ssl_mode=ssl, statement_timeout_ms=timeout_ms\n        ) as pg:\n            # Layer 2: Session-level read-only + timeout\n            await pg.execute(\"SET default_transaction_read_only = on\")\n            await pg.execute(f\"SET statement_timeout = '{timeout_ms}'\")\n\n            # Append LIMIT (query already has trailing ; stripped by schema validator)\n            ph = backend.param_placeholder()\n            limited_query = f\"{query} LIMIT {ph}\"\n\n            rows = await pg.fetch_all(limited_query, (limit,))\n            return [{k: _serialize_value(v) for k, v in row.items()} for row in rows]\n\n    except QuerySafetyError:\n        raise\n    except Exception as e:\n        logger.error(f\"Error executing query: {e}\")\n        raise DatabaseServiceError(f\"Query execution failed: {e}\")\n</code></pre>"},{"location":"api-reference/backend/database-service/#app.services.database_service.preview_data_all_columns","title":"<code>preview_data_all_columns(handle, table, filters=None, limit=10)</code>  <code>async</code>","text":"<p>Preview all columns from a table (no mapping step).</p> <p>Parameters:</p> Name Type Description Default <code>handle</code> <code>str</code> <p>Connection handle</p> required <code>table</code> <code>TableIdentifier</code> <p>Table identifier</p> required <code>filters</code> <code>list[FilterCondition] | None</code> <p>Optional filter conditions</p> <code>None</code> <code>limit</code> <code>int</code> <p>Number of rows to preview</p> <code>10</code> <p>Returns:</p> Type Description <code>list[dict[str, Any]]</code> <p>List of raw dictionaries with all columns</p> Source code in <code>backend/app/services/database_service.py</code> <pre><code>async def preview_data_all_columns(\n    handle: str,\n    table: TableIdentifier,\n    filters: list[FilterCondition] | None = None,\n    limit: int = 10,\n) -&gt; list[dict[str, Any]]:\n    \"\"\"Preview all columns from a table (no mapping step).\n\n    Args:\n        handle: Connection handle\n        table: Table identifier\n        filters: Optional filter conditions\n        limit: Number of rows to preview\n\n    Returns:\n        List of raw dictionaries with all columns\n    \"\"\"\n    conn_info = _get_connection_info(handle)\n    url = _build_url(conn_info)\n    ssl = conn_info.ssl_mode if conn_info.ssl_mode != \"disable\" else None\n    backend = get_backend(conn_info.db_type)\n    catalog = get_catalog(conn_info.db_type)\n\n    try:\n        async with backend.pooled_connection(\n            url, ssl_mode=ssl, statement_timeout_ms=QUERY_TIMEOUT_MS\n        ) as pg:\n            if filters:\n                filter_columns = [f.column for f in filters]\n                await _validate_columns(pg, catalog, table, filter_columns)\n\n            qi = backend.quote_identifier\n            ph = backend.param_placeholder()\n            quoted_table = backend.quote_table(table.schema_name, table.name)\n\n            where_clause = \"\"\n            params: list[Any] = []\n            if filters:\n                conditions = []\n                for f in filters:\n                    conditions.append(f\"{qi(f.column)} = {ph}\")\n                    params.append(f.value)\n                where_clause = \"WHERE \" + \" AND \".join(conditions)\n\n            params.append(limit)\n            query_str = f\"SELECT * FROM {quoted_table} {where_clause} LIMIT {ph}\"\n            rows = await pg.fetch_all(query_str, tuple(params))\n            return [{k: _serialize_value(v) for k, v in row.items()} for row in rows]\n\n    except InvalidColumnError:\n        raise\n    except Exception as e:\n        logger.error(f\"Error previewing data (all columns): {e}\")\n        raise DatabaseServiceError(f\"Failed to preview data: {e}\")\n</code></pre>"},{"location":"api-reference/backend/database-service/#app.services.database_service.import_data_all_columns","title":"<code>import_data_all_columns(handle, table, filters=None, limit=10000, dedupe_on_id=True)</code>  <code>async</code>","text":"<p>Import all columns from a table (no mapping step).</p> <p>Parameters:</p> Name Type Description Default <code>handle</code> <code>str</code> <p>Connection handle</p> required <code>table</code> <code>TableIdentifier</code> <p>Table identifier</p> required <code>filters</code> <code>list[FilterCondition] | None</code> <p>Optional filter conditions</p> <code>None</code> <code>limit</code> <code>int</code> <p>Maximum rows to import</p> <code>10000</code> <code>dedupe_on_id</code> <code>bool</code> <p>Whether to deduplicate by dataset_id or id column</p> <code>True</code> <p>Returns:</p> Type Description <code>list[dict[str, Any]]</code> <p>List of raw dictionaries</p> Source code in <code>backend/app/services/database_service.py</code> <pre><code>async def import_data_all_columns(\n    handle: str,\n    table: TableIdentifier,\n    filters: list[FilterCondition] | None = None,\n    limit: int = 10000,\n    dedupe_on_id: bool = True,\n) -&gt; list[dict[str, Any]]:\n    \"\"\"Import all columns from a table (no mapping step).\n\n    Args:\n        handle: Connection handle\n        table: Table identifier\n        filters: Optional filter conditions\n        limit: Maximum rows to import\n        dedupe_on_id: Whether to deduplicate by dataset_id or id column\n\n    Returns:\n        List of raw dictionaries\n    \"\"\"\n    conn_info = _get_connection_info(handle)\n    url = _build_url(conn_info)\n    ssl = conn_info.ssl_mode if conn_info.ssl_mode != \"disable\" else None\n    backend = get_backend(conn_info.db_type)\n    catalog = get_catalog(conn_info.db_type)\n\n    try:\n        async with backend.pooled_connection(\n            url, ssl_mode=ssl, statement_timeout_ms=QUERY_TIMEOUT_MS\n        ) as pg:\n            if filters:\n                filter_columns = [f.column for f in filters]\n                await _validate_columns(pg, catalog, table, filter_columns)\n\n            qi = backend.quote_identifier\n            ph = backend.param_placeholder()\n            quoted_table = backend.quote_table(table.schema_name, table.name)\n\n            where_clause = \"\"\n            base_params: list[Any] = []\n            if filters:\n                conditions = []\n                for f in filters:\n                    conditions.append(f\"{qi(f.column)} = {ph}\")\n                    base_params.append(f.value)\n                where_clause = \"WHERE \" + \" AND \".join(conditions)\n\n            all_data: list[dict[str, Any]] = []\n            offset = 0\n\n            while True:\n                chunk_limit = min(CHUNK_SIZE, limit - len(all_data))\n                params = [*base_params, chunk_limit, offset]\n                query_str = f\"SELECT * FROM {quoted_table} {where_clause} LIMIT {ph} OFFSET {ph}\"\n                chunk = await pg.fetch_all(query_str, tuple(params))\n\n                if not chunk:\n                    break\n\n                all_data.extend({k: _serialize_value(v) for k, v in row.items()} for row in chunk)\n                offset += len(chunk)\n\n                if len(all_data) &gt;= limit:\n                    break\n\n            # Deduplicate\n            if dedupe_on_id and all_data:\n                id_key = None\n                for candidate in (\"dataset_id\", \"id\"):\n                    if candidate in all_data[0]:\n                        id_key = candidate\n                        break\n                if id_key:\n                    # Long format (metric_name column): dedup on (id, metric_name)\n                    # to preserve one row per metric per record.\n                    has_metric_name = \"metric_name\" in all_data[0]\n                    seen: set[Any] = set()\n                    deduped: list[dict[str, Any]] = []\n                    for row in all_data:\n                        dedup_key: Any\n                        if has_metric_name:\n                            dedup_key = (row.get(id_key), row.get(\"metric_name\"))\n                        else:\n                            dedup_key = row.get(id_key)\n                        if dedup_key not in seen:\n                            seen.add(dedup_key)\n                            deduped.append(row)\n                    all_data = deduped\n\n            logger.info(\n                f\"Imported {len(all_data)} rows (all columns) from \"\n                f\"{table.schema_name}.{table.name} (handle {handle[:8]}...)\"\n            )\n            return all_data\n\n    except InvalidColumnError:\n        raise\n    except Exception as e:\n        logger.error(f\"Error importing data (all columns): {e}\")\n        raise DatabaseServiceError(f\"Failed to import data: {e}\")\n</code></pre>"},{"location":"api-reference/backend/eval-runner-service/","title":"Eval Runner Service","text":"<p>Batch evaluation execution via the Axion evaluation engine.</p>"},{"location":"api-reference/backend/eval-runner-service/#app.services.eval_runner_service-classes","title":"Classes","text":""},{"location":"api-reference/backend/eval-runner-service/#app.services.eval_runner_service.EvalRunnerError","title":"<code>EvalRunnerError</code>","text":"<p>               Bases: <code>Exception</code></p> <p>Base exception for eval runner errors.</p>"},{"location":"api-reference/backend/eval-runner-service/#app.services.eval_runner_service.MetricEvaluationError","title":"<code>MetricEvaluationError</code>","text":"<p>               Bases: <code>EvalRunnerError</code></p> <p>Error during metric evaluation.</p>"},{"location":"api-reference/backend/eval-runner-service/#app.services.eval_runner_service.AgentConnectionError","title":"<code>AgentConnectionError</code>","text":"<p>               Bases: <code>EvalRunnerError</code></p> <p>Error connecting to agent API.</p>"},{"location":"api-reference/backend/eval-runner-service/#app.services.eval_runner_service-functions","title":"Functions","text":""},{"location":"api-reference/backend/eval-runner-service/#app.services.eval_runner_service.get_available_metrics","title":"<code>get_available_metrics()</code>","text":"<p>Return all available metrics from the registry.</p> Source code in <code>backend/app/services/eval_runner_service.py</code> <pre><code>def get_available_metrics() -&gt; list[MetricInfo]:\n    \"\"\"Return all available metrics from the registry.\"\"\"\n    return METRIC_REGISTRY\n</code></pre>"},{"location":"api-reference/backend/eval-runner-service/#app.services.eval_runner_service.get_metric_by_key","title":"<code>get_metric_by_key(key)</code>","text":"<p>Get a specific metric by its key.</p> Source code in <code>backend/app/services/eval_runner_service.py</code> <pre><code>def get_metric_by_key(key: str) -&gt; MetricInfo | None:\n    \"\"\"Get a specific metric by its key.\"\"\"\n    return METRIC_REGISTRY_MAP.get(key)\n</code></pre>"},{"location":"api-reference/backend/eval-runner-service/#app.services.eval_runner_service.evaluate_llm_metric","title":"<code>evaluate_llm_metric(metric_key, item, model_name, llm_provider)</code>  <code>async</code>","text":"<p>Evaluate a single item using an LLM-based metric.</p> <p>Parameters:</p> Name Type Description Default <code>metric_key</code> <code>str</code> <p>The metric to evaluate</p> required <code>item</code> <code>dict[str, Any]</code> <p>The item data with required fields</p> required <code>model_name</code> <code>str</code> <p>LLM model to use</p> required <code>llm_provider</code> <code>str</code> <p>Provider (openai, anthropic)</p> required <p>Returns:</p> Type Description <code>tuple[float, str]</code> <p>Tuple of (score, reasoning)</p> Source code in <code>backend/app/services/eval_runner_service.py</code> <pre><code>async def evaluate_llm_metric(\n    metric_key: str,\n    item: dict[str, Any],\n    model_name: str,\n    llm_provider: str,\n) -&gt; tuple[float, str]:\n    \"\"\"Evaluate a single item using an LLM-based metric.\n\n    Args:\n        metric_key: The metric to evaluate\n        item: The item data with required fields\n        model_name: LLM model to use\n        llm_provider: Provider (openai, anthropic)\n\n    Returns:\n        Tuple of (score, reasoning)\n    \"\"\"\n    metric = METRIC_REGISTRY_MAP.get(metric_key)\n    if not metric:\n        raise MetricEvaluationError(f\"Unknown metric: {metric_key}\")\n\n    # Build evaluation prompt based on metric type\n    prompt = _build_metric_prompt(metric_key, item)\n\n    try:\n        registry = LLMRegistry(provider=llm_provider)\n        llm = registry.get_llm(model_name)\n\n        messages = [\n            {\n                \"role\": \"system\",\n                \"content\": (\n                    \"You are an expert evaluator. Evaluate the given content \"\n                    \"and respond with a JSON object containing:\\n\"\n                    '- \"score\": a float between 0.0 and 1.0\\n'\n                    '- \"reasoning\": a brief explanation\\n\\n'\n                    \"Respond ONLY with valid JSON, no other text.\"\n                ),\n            },\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n\n        response = await llm.achat(messages)\n\n        # Extract content from response\n        if hasattr(response, \"content\"):\n            content = response.content\n        elif hasattr(response, \"choices\") and response.choices:\n            content = response.choices[0].message.content\n        else:\n            content = str(response)\n\n        # Parse JSON response\n        try:\n            # Find JSON in response (handle markdown code blocks)\n            if \"```json\" in content:\n                content = content.split(\"```json\")[1].split(\"```\")[0]\n            elif \"```\" in content:\n                content = content.split(\"```\")[1].split(\"```\")[0]\n\n            result = json.loads(content.strip())\n            score = float(result.get(\"score\", 0.5))\n            reasoning = result.get(\"reasoning\", \"No reasoning provided\")\n\n            # Clamp score to [0, 1]\n            score = max(0.0, min(1.0, score))\n\n            return score, reasoning\n\n        except (json.JSONDecodeError, KeyError, ValueError) as e:\n            logger.warning(f\"Failed to parse LLM response: {e}\")\n            return 0.5, f\"Failed to parse evaluation response: {content[:100]}\"\n\n    except Exception as e:\n        logger.error(f\"LLM metric evaluation failed: {e}\")\n        raise MetricEvaluationError(f\"Failed to evaluate {metric_key}: {e}\") from e\n</code></pre>"},{"location":"api-reference/backend/eval-runner-service/#app.services.eval_runner_service.evaluate_heuristic_metric","title":"<code>evaluate_heuristic_metric(metric_key, item)</code>","text":"<p>Evaluate a single item using a heuristic (non-LLM) metric.</p> <p>Parameters:</p> Name Type Description Default <code>metric_key</code> <code>str</code> <p>The metric to evaluate</p> required <code>item</code> <code>dict[str, Any]</code> <p>The item data with required fields</p> required <p>Returns:</p> Type Description <code>tuple[float, str]</code> <p>Tuple of (score, reasoning)</p> Source code in <code>backend/app/services/eval_runner_service.py</code> <pre><code>def evaluate_heuristic_metric(\n    metric_key: str,\n    item: dict[str, Any],\n) -&gt; tuple[float, str]:\n    \"\"\"Evaluate a single item using a heuristic (non-LLM) metric.\n\n    Args:\n        metric_key: The metric to evaluate\n        item: The item data with required fields\n\n    Returns:\n        Tuple of (score, reasoning)\n    \"\"\"\n    actual_output = str(item.get(\"actual_output\", \"\"))\n    expected_output = str(item.get(\"expected_output\", \"\"))\n\n    if metric_key == \"exact_string_match\":\n        match = actual_output.strip() == expected_output.strip()\n        return (1.0 if match else 0.0, \"Exact match\" if match else \"No exact match\")\n\n    elif metric_key == \"levenshtein_ratio\":\n        ratio = SequenceMatcher(None, actual_output, expected_output).ratio()\n        return (ratio, f\"Similarity ratio: {ratio:.2%}\")\n\n    elif metric_key == \"sentence_bleu\":\n        score = _calculate_bleu(actual_output, expected_output)\n        return (score, f\"BLEU score: {score:.4f}\")\n\n    elif metric_key == \"contains_match\":\n        expected_subs = item.get(\"expected_substrings\", [expected_output])\n        if isinstance(expected_subs, str):\n            expected_subs = [expected_subs]\n        matches = sum(1 for sub in expected_subs if sub.lower() in actual_output.lower())\n        score = matches / len(expected_subs) if expected_subs else 0.0\n        return (score, f\"Matched {matches}/{len(expected_subs)} substrings\")\n\n    elif metric_key == \"length_constraint\":\n        length = len(actual_output)\n        min_len = item.get(\"min_length\", 1)\n        max_len = item.get(\"max_length\", 10000)\n        if min_len &lt;= length &lt;= max_len:\n            return (1.0, f\"Length {length} within bounds [{min_len}, {max_len}]\")\n        return (0.0, f\"Length {length} outside bounds [{min_len}, {max_len}]\")\n\n    elif metric_key == \"citation_presence\":\n        # Simple heuristic: check for common citation patterns\n        citation_patterns = [\n            \"[1]\",\n            \"[2]\",\n            \"(1)\",\n            \"(2)\",\n            \"http://\",\n            \"https://\",\n            \"source:\",\n            \"reference:\",\n        ]\n        has_citation = any(p in actual_output.lower() for p in citation_patterns)\n        return (\n            1.0 if has_citation else 0.0,\n            \"Citation found\" if has_citation else \"No citation found\",\n        )\n\n    elif metric_key == \"latency\":\n        latency = float(item.get(\"latency\", 0))\n        # Normalize: lower latency is better, cap at threshold for score calculation\n        threshold = 1000.0  # 1 second baseline\n        score = max(0.0, 1.0 - (latency / threshold))\n        return (score, f\"Latency: {latency}ms\")\n\n    elif metric_key in [\"hit_rate_at_k\", \"precision_at_k\", \"recall_at_k\", \"ndcg_at_k\", \"mrr\"]:\n        # Retrieval metrics - simplified implementation\n        retrieved = item.get(\"retrieved_content\", \"\")\n        expected = item.get(\"expected_output\", \"\")\n        # Simple overlap-based approximation\n        if not retrieved or not expected:\n            return (0.0, \"Missing retrieved content or expected output\")\n        overlap = SequenceMatcher(None, retrieved, expected).ratio()\n        return (overlap, f\"Content overlap: {overlap:.2%}\")\n\n    elif metric_key == \"tool_correctness\":\n        tools_called = item.get(\"tools_called\", [])\n        expected_tools = item.get(\"expected_tools\", [])\n        if isinstance(tools_called, str):\n            tools_called = [t.strip() for t in tools_called.split(\",\")]\n        if isinstance(expected_tools, str):\n            expected_tools = [t.strip() for t in expected_tools.split(\",\")]\n\n        if not expected_tools:\n            return (1.0, \"No expected tools specified\")\n\n        correct = sum(1 for t in expected_tools if t in tools_called)\n        score = correct / len(expected_tools)\n        return (score, f\"Correct tools: {correct}/{len(expected_tools)}\")\n\n    return (0.5, f\"Unknown metric: {metric_key}\")\n</code></pre>"},{"location":"api-reference/backend/eval-runner-service/#app.services.eval_runner_service.call_agent_api","title":"<code>call_agent_api(agent_config, query)</code>  <code>async</code>","text":"<p>Call an external agent API to generate output.</p> <p>Parameters:</p> Name Type Description Default <code>agent_config</code> <code>AgentConfig</code> <p>Agent configuration</p> required <code>query</code> <code>str</code> <p>The query to send</p> required <p>Returns:</p> Type Description <code>tuple[str, float]</code> <p>Tuple of (output, latency_ms)</p> Source code in <code>backend/app/services/eval_runner_service.py</code> <pre><code>async def call_agent_api(\n    agent_config: AgentConfig,\n    query: str,\n) -&gt; tuple[str, float]:\n    \"\"\"Call an external agent API to generate output.\n\n    Args:\n        agent_config: Agent configuration\n        query: The query to send\n\n    Returns:\n        Tuple of (output, latency_ms)\n    \"\"\"\n    if agent_config.type == AgentType.NONE:\n        raise AgentConnectionError(\"No agent configured\")\n\n    if agent_config.type == AgentType.API:\n        return await _call_http_agent(agent_config, query)\n\n    if agent_config.type == AgentType.PROMPT:\n        return await _call_prompt_agent(agent_config, query)\n\n    raise AgentConnectionError(f\"Unknown agent type: {agent_config.type}\")\n</code></pre>"},{"location":"api-reference/backend/eval-runner-service/#app.services.eval_runner_service.prepare_evaluation_data","title":"<code>prepare_evaluation_data(dataset_data, column_mapping, metrics)</code>","text":"<p>Validate data, build DatasetItems, and instantiate metrics.</p> <p>Returns:</p> Type Description <code>list[DatasetItem]</code> <p>Tuple of (dataset_items, scoring_metrics, valid_metric_keys, warnings).</p> <code>list[Any]</code> <p>Warnings are human-readable strings for surfacing to the user.</p> Source code in <code>backend/app/services/eval_runner_service.py</code> <pre><code>def prepare_evaluation_data(\n    dataset_data: list[dict[str, Any]],\n    column_mapping: ColumnMapping,\n    metrics: list[str],\n) -&gt; tuple[list[DatasetItem], list[Any], list[str], list[str]]:\n    \"\"\"Validate data, build DatasetItems, and instantiate metrics.\n\n    Returns:\n        Tuple of (dataset_items, scoring_metrics, valid_metric_keys, warnings).\n        Warnings are human-readable strings for surfacing to the user.\n    \"\"\"\n    warnings: list[str] = []\n\n    # Build DatasetItem list from input data\n    dataset_items: list[DatasetItem] = []\n    for i, row in enumerate(dataset_data):\n        item_kwargs: dict[str, Any] = {}\n\n        # Map columns to DatasetItem fields\n        if column_mapping.query:\n            item_kwargs[\"query\"] = str(row.get(column_mapping.query, \"\"))\n        if column_mapping.actual_output:\n            item_kwargs[\"actual_output\"] = str(row.get(column_mapping.actual_output, \"\"))\n        if column_mapping.expected_output:\n            val = row.get(column_mapping.expected_output)\n            if val:\n                item_kwargs[\"expected_output\"] = str(val)\n        if column_mapping.retrieved_content:\n            val = row.get(column_mapping.retrieved_content)\n            if val:\n                # axion expects retrieved_content as a list of strings\n                if isinstance(val, list):\n                    item_kwargs[\"retrieved_content\"] = [str(v) for v in val]\n                else:\n                    item_kwargs[\"retrieved_content\"] = [str(val)]\n        if column_mapping.latency:\n            val = row.get(column_mapping.latency)\n            if val:\n                item_kwargs[\"latency\"] = float(val)\n        if column_mapping.tools_called:\n            val = row.get(column_mapping.tools_called)\n            if val:\n                item_kwargs[\"tools_called\"] = val if isinstance(val, list) else [val]\n        if column_mapping.expected_tools:\n            val = row.get(column_mapping.expected_tools)\n            if val:\n                item_kwargs[\"expected_tools\"] = val if isinstance(val, list) else [val]\n        if column_mapping.acceptance_criteria:\n            val = row.get(column_mapping.acceptance_criteria)\n            if val:\n                item_kwargs[\"acceptance_criteria\"] = str(val)\n\n        # Create DatasetItem\n        try:\n            dataset_items.append(DatasetItem(**item_kwargs))\n        except Exception as e:\n            msg = f\"Row {i}: validation issue \u2014 {e}\"\n            warnings.append(msg)\n            logger.warning(f\"Failed to create DatasetItem for row {i}: {e}\")\n            # Create minimal item\n            dataset_items.append(\n                DatasetItem(\n                    query=item_kwargs.get(\"query\", f\"Item {i}\"),\n                    actual_output=item_kwargs.get(\"actual_output\", \"\"),\n                )\n            )\n\n    # Check which fields are actually populated across the dataset\n    populated_fields: set[str] = set()\n    for item in dataset_items:\n        if item.query:\n            populated_fields.add(\"query\")\n        if item.actual_output:\n            populated_fields.add(\"actual_output\")\n        if item.expected_output:\n            populated_fields.add(\"expected_output\")\n        if item.retrieved_content:\n            populated_fields.add(\"retrieved_content\")\n\n    # Get metric instances from axion's registry\n    scoring_metrics = []\n    valid_metric_keys = []\n    for metric_key in metrics:\n        try:\n            metric_class = axion_metric_registry.get(metric_key)\n            if metric_class:\n                metric_instance = metric_class()\n\n                # Check required fields for this metric\n                metric_info = METRIC_REGISTRY_MAP.get(metric_key)\n                if metric_info:\n                    missing_fields = [\n                        f for f in metric_info.required_fields if f not in populated_fields\n                    ]\n                    if missing_fields:\n                        msg = (\n                            f\"Metric '{metric_info.name}' requires {missing_fields} \"\n                            f\"but data only has {sorted(populated_fields)}\"\n                        )\n                        warnings.append(msg)\n                        logger.warning(msg)\n\n                scoring_metrics.append(metric_instance)\n                valid_metric_keys.append(metric_key)\n            else:\n                msg = f\"Metric '{metric_key}' not found in axion registry\"\n                warnings.append(msg)\n                logger.warning(msg)\n        except Exception as e:\n            msg = f\"Failed to instantiate metric '{metric_key}': {e}\"\n            warnings.append(msg)\n            logger.warning(msg)\n\n    if not scoring_metrics:\n        raise EvalRunnerError(\"No valid metrics could be instantiated\")\n\n    return dataset_items, scoring_metrics, valid_metric_keys, warnings\n</code></pre>"},{"location":"api-reference/backend/eval-runner-service/#app.services.eval_runner_service.run_evaluation_sync","title":"<code>run_evaluation_sync(evaluation_name, dataset_data, column_mapping, metrics, model_name, llm_provider, max_concurrent, thresholds, agent_config)</code>","text":"<p>Run evaluation using axion's evaluation_runner (synchronous).</p> <p>Convenience wrapper that validates data and runs evaluation in one call.</p> Source code in <code>backend/app/services/eval_runner_service.py</code> <pre><code>def run_evaluation_sync(\n    evaluation_name: str,\n    dataset_data: list[dict[str, Any]],\n    column_mapping: ColumnMapping,\n    metrics: list[str],\n    model_name: str,\n    llm_provider: str,\n    max_concurrent: int,\n    thresholds: dict[str, float] | None,\n    agent_config: AgentConfig | None,\n) -&gt; EvaluationSummary:\n    \"\"\"Run evaluation using axion's evaluation_runner (synchronous).\n\n    Convenience wrapper that validates data and runs evaluation in one call.\n    \"\"\"\n    dataset_items, scoring_metrics, valid_metric_keys, _warnings = prepare_evaluation_data(\n        dataset_data, column_mapping, metrics\n    )\n    return _run_evaluation_core(\n        evaluation_name=evaluation_name,\n        dataset_items=dataset_items,\n        scoring_metrics=scoring_metrics,\n        valid_metric_keys=valid_metric_keys,\n        model_name=model_name,\n        llm_provider=llm_provider,\n        max_concurrent=max_concurrent,\n        thresholds=thresholds,\n    )\n</code></pre>"},{"location":"api-reference/backend/eval-runner-service/#app.services.eval_runner_service.run_evaluation","title":"<code>run_evaluation(evaluation_name, dataset_data, column_mapping, metrics, model_name, llm_provider, max_concurrent, thresholds, agent_config, on_progress=None, on_log=None)</code>  <code>async</code>","text":"<p>Run evaluation asynchronously using axion's evaluation_runner.</p> <p>Runs the synchronous evaluation_runner in a thread pool to not block the async event loop while still showing progress in the terminal.</p> Source code in <code>backend/app/services/eval_runner_service.py</code> <pre><code>async def run_evaluation(\n    evaluation_name: str,\n    dataset_data: list[dict[str, Any]],\n    column_mapping: ColumnMapping,\n    metrics: list[str],\n    model_name: str,\n    llm_provider: str,\n    max_concurrent: int,\n    thresholds: dict[str, float] | None,\n    agent_config: AgentConfig | None,\n    on_progress: Any | None = None,\n    on_log: Any | None = None,\n) -&gt; EvaluationSummary:\n    \"\"\"Run evaluation asynchronously using axion's evaluation_runner.\n\n    Runs the synchronous evaluation_runner in a thread pool to not block\n    the async event loop while still showing progress in the terminal.\n    \"\"\"\n    # Generate outputs from agent if configured\n    if agent_config and agent_config.type != AgentType.NONE:\n        logger.info(\"Generating outputs from agent...\")\n        for i, row in enumerate(dataset_data):\n            output_col = column_mapping.actual_output\n            if output_col and not row.get(output_col):\n                try:\n                    query_col = column_mapping.query\n                    query = str(row.get(query_col, \"\")) if query_col else \"\"\n                    output, latency = await call_agent_api(agent_config, query)\n                    row[output_col] = output\n                    if column_mapping.latency:\n                        row[column_mapping.latency] = latency\n                except AgentConnectionError as e:\n                    logger.error(f\"Agent call failed for row {i}: {e}\")\n                    row[output_col] = \"\"\n\n    # Run the synchronous evaluation in a thread pool\n    loop = asyncio.get_event_loop()\n    summary = await loop.run_in_executor(\n        None,\n        run_evaluation_sync,\n        evaluation_name,\n        dataset_data,\n        column_mapping,\n        metrics,\n        model_name,\n        llm_provider,\n        max_concurrent,\n        thresholds,\n        agent_config,\n    )\n\n    return summary\n</code></pre>"},{"location":"api-reference/backend/eval-runner-service/#app.services.eval_runner_service.run_evaluation_stream","title":"<code>run_evaluation_stream(evaluation_name, dataset_data, column_mapping, metrics, model_name, llm_provider, max_concurrent, thresholds, agent_config)</code>  <code>async</code>","text":"<p>Run evaluation with SSE streaming updates.</p> <p>Yields SSE events for progress, logs, and completion. Runs validation in the async context for real progress tracking, then runs axion evaluation in a thread pool.</p> Source code in <code>backend/app/services/eval_runner_service.py</code> <pre><code>async def run_evaluation_stream(\n    evaluation_name: str,\n    dataset_data: list[dict[str, Any]],\n    column_mapping: ColumnMapping,\n    metrics: list[str],\n    model_name: str,\n    llm_provider: str,\n    max_concurrent: int,\n    thresholds: dict[str, float] | None,\n    agent_config: AgentConfig | None,\n) -&gt; AsyncGenerator[dict[str, Any], None]:\n    \"\"\"Run evaluation with SSE streaming updates.\n\n    Yields SSE events for progress, logs, and completion.\n    Runs validation in the async context for real progress tracking,\n    then runs axion evaluation in a thread pool.\n    \"\"\"\n    import concurrent.futures\n\n    total_evaluations = len(dataset_data) * len(metrics)\n    thresholds = thresholds or {}\n\n    def _make_log(level: str, message: str) -&gt; dict[str, Any]:\n        return {\n            \"event\": \"log\",\n            \"data\": {\n                \"timestamp\": datetime.now(UTC).isoformat(),\n                \"level\": level,\n                \"message\": message,\n            },\n        }\n\n    def _make_progress(\n        current: int, total: int, status: str, message: str, phase: str = \"running\"\n    ) -&gt; dict[str, Any]:\n        return {\n            \"event\": \"progress\",\n            \"data\": {\n                \"current\": current,\n                \"total\": total,\n                \"status\": status,\n                \"message\": message,\n                \"phase\": phase,\n            },\n        }\n\n    try:\n        yield _make_log(\"INFO\", f\"Starting evaluation: {evaluation_name}\")\n        yield _make_log(\n            \"INFO\",\n            f\"Processing {len(dataset_data)} items with {len(metrics)} metrics \"\n            f\"({total_evaluations} total evaluations)\",\n        )\n\n        # Phase 1: Validate data and prepare metrics (real progress)\n        yield _make_progress(0, total_evaluations, \"running\", \"Validating data...\", \"validating\")\n\n        # Generate outputs from agent if configured\n        if agent_config and agent_config.type != AgentType.NONE:\n            yield _make_log(\"INFO\", f\"Generating outputs from agent ({agent_config.type.value})...\")\n            for i, row in enumerate(dataset_data):\n                output_col = column_mapping.actual_output\n                if output_col and not row.get(output_col):\n                    try:\n                        query_col = column_mapping.query\n                        query = str(row.get(query_col, \"\")) if query_col else \"\"\n                        output, latency = await call_agent_api(agent_config, query)\n                        row[output_col] = output\n                        if column_mapping.latency:\n                            row[column_mapping.latency] = latency\n                    except AgentConnectionError as e:\n                        yield _make_log(\"WARNING\", f\"Agent call failed for row {i}: {e}\")\n                        row[output_col] = \"\"\n\n        dataset_items, scoring_metrics, valid_metric_keys, warnings = prepare_evaluation_data(\n            dataset_data, column_mapping, metrics\n        )\n\n        yield _make_log(\"INFO\", f\"Validated {len(dataset_items)} items successfully\")\n        yield _make_log(\"INFO\", f\"Instantiated {len(scoring_metrics)} metrics: {valid_metric_keys}\")\n\n        # Surface validation warnings as log events\n        if warnings:\n            yield _make_log(\n                \"WARNING\",\n                f\"{len(warnings)} validation warning(s) detected:\",\n            )\n            for warn_msg in warnings:\n                yield _make_log(\"WARNING\", warn_msg)\n\n        # Phase 2: Run axion evaluation in thread pool\n        yield _make_progress(0, total_evaluations, \"running\", \"Running evaluation...\", \"evaluating\")\n        yield _make_log(\"INFO\", \"Starting metric evaluation with axion...\")\n\n        with concurrent.futures.ThreadPoolExecutor() as executor:\n            future = executor.submit(\n                _run_evaluation_core,\n                evaluation_name,\n                dataset_items,\n                scoring_metrics,\n                valid_metric_keys,\n                model_name,\n                llm_provider,\n                max_concurrent,\n                thresholds,\n            )\n\n            # Poll for completion while sending progress updates\n            elapsed: float = 0\n            poll_interval = 0.5  # Faster polling for better UX\n            while not future.done():\n                await asyncio.sleep(poll_interval)\n                elapsed += poll_interval\n\n                # Estimate progress \u2014 use log curve for more natural feel\n                # Approaches 90% asymptotically, never reaches 100% until done\n                import math\n\n                progress_pct = 1 - math.exp(-elapsed * max_concurrent * 0.3 / total_evaluations)\n                estimated_progress = min(\n                    int(progress_pct * total_evaluations),\n                    total_evaluations - 1,\n                )\n\n                yield _make_progress(\n                    estimated_progress,\n                    total_evaluations,\n                    \"running\",\n                    f\"Evaluating metrics... ({int(elapsed)}s elapsed)\",\n                    \"evaluating\",\n                )\n\n            # Get the result (may raise)\n            summary = future.result()\n\n        # Phase 3: Complete\n        logger.info(\n            f\"Evaluation complete, preparing response with \"\n            f\"{len(summary.dataframe_records)} dataframe records\"\n        )\n\n        yield _make_progress(\n            total_evaluations, total_evaluations, \"complete\", \"Evaluation complete!\", \"complete\"\n        )\n\n        # Check for potential issues in results\n        zero_metrics = [\n            mr.metric_name\n            for mr in summary.metric_results\n            if mr.average_score == 0.0 and mr.pass_rate == 0.0\n        ]\n        if zero_metrics:\n            yield _make_log(\n                \"WARNING\",\n                f\"Metrics with 0% scores: {zero_metrics}. \"\n                \"This may indicate missing required data fields (e.g., expected_output, \"\n                \"retrieved_content) or metric execution failures.\",\n            )\n\n        # Serialize summary carefully to handle any problematic values\n        try:\n            summary_dict = summary.model_dump()\n            if summary_dict.get(\"dataframe_records\"):\n                for record in summary_dict[\"dataframe_records\"]:\n                    for key, val in list(record.items()):\n                        if val is not None and not isinstance(\n                            val, str | int | float | bool | list | dict\n                        ):\n                            record[key] = str(val)\n            logger.info(\n                f\"Serialized summary with {len(summary_dict.get('dataframe_records', []))} records\"\n            )\n        except Exception as e:\n            logger.error(f\"Failed to serialize summary: {e}\")\n            summary_dict = summary.model_dump(exclude={\"dataframe_records\", \"dataframe_columns\"})\n            summary_dict[\"dataframe_records\"] = []\n            summary_dict[\"dataframe_columns\"] = []\n\n        yield {\n            \"event\": \"complete\",\n            \"data\": {\n                \"run_id\": summary.run_id,\n                \"summary\": summary_dict,\n            },\n        }\n\n    except Exception as e:\n        logger.error(f\"Evaluation stream error: {e}\", exc_info=True)\n        yield {\n            \"event\": \"error\",\n            \"data\": {\n                \"message\": str(e),\n                \"details\": None,\n            },\n        }\n</code></pre>"},{"location":"api-reference/backend/graph-service/","title":"Graph Service","text":"<p>FalkorDB knowledge graph operations \u2014 node/edge queries, search, and neighborhood traversal.</p>"},{"location":"api-reference/backend/graph-service/#app.plugins.memory.services.graph_service-classes","title":"Classes","text":""},{"location":"api-reference/backend/graph-service/#app.plugins.memory.services.graph_service-functions","title":"Functions","text":""},{"location":"api-reference/backend/graph-service/#app.plugins.memory.services.graph_service.check_connection","title":"<code>check_connection()</code>","text":"<p>Check if FalkorDB is reachable.</p> Source code in <code>backend/app/plugins/memory/services/graph_service.py</code> <pre><code>def check_connection() -&gt; dict[str, Any]:\n    \"\"\"Check if FalkorDB is reachable.\"\"\"\n    try:\n        graph = _get_graph()\n        # Simple query to verify connectivity\n        graph.query(\"RETURN 1\")\n        return {\n            \"connected\": True,\n            \"graph_name\": settings.graph_db_name,\n            \"message\": \"Connected to FalkorDB\",\n        }\n    except Exception as e:\n        _reset_connection()\n        logger.warning(\"FalkorDB connection check failed: %s\", e)\n        return {\n            \"connected\": False,\n            \"graph_name\": settings.graph_db_name,\n            \"message\": f\"Connection failed: {e}\",\n        }\n</code></pre>"},{"location":"api-reference/backend/graph-service/#app.plugins.memory.services.graph_service.get_summary","title":"<code>get_summary()</code>","text":"<p>Get summary statistics for the knowledge graph.</p> Source code in <code>backend/app/plugins/memory/services/graph_service.py</code> <pre><code>def get_summary() -&gt; dict[str, Any]:\n    \"\"\"Get summary statistics for the knowledge graph.\"\"\"\n    graph = _get_graph()\n\n    # Count nodes by label\n    result = graph.query(\"MATCH (n) RETURN labels(n)[0] AS label, count(n) AS cnt\")\n    nodes_by_type: dict[str, int] = {}\n    total_nodes = 0\n    for row in result.result_set:\n        label = row[0] or \"Unknown\"\n        count = row[1]\n        nodes_by_type[label] = count\n        total_nodes += count\n\n    # Count edges by relation type\n    result = graph.query(\"MATCH ()-[r]-&gt;() RETURN type(r) AS rel, count(r) AS cnt\")\n    edges_by_relation: dict[str, int] = {}\n    total_edges = 0\n    for row in result.result_set:\n        rel = row[0]\n        count = row[1]\n        edges_by_relation[rel] = count\n        total_edges += count\n\n    # Rules by action\n    rules_by_action: dict[str, int] = {}\n    try:\n        result = graph.query(\"MATCH (r:Rule) RETURN r.action AS action, count(r) AS cnt\")\n        for row in result.result_set:\n            if row[0]:\n                rules_by_action[row[0]] = row[1]\n    except Exception:\n        logger.debug(\"No action property on Rule nodes\")\n\n    # Rules by product\n    rules_by_product: dict[str, int] = {}\n    try:\n        result = graph.query(\"MATCH (r:Rule) RETURN r.product_type AS product, count(r) AS cnt\")\n        for row in result.result_set:\n            if row[0]:\n                rules_by_product[row[0]] = row[1]\n    except Exception:\n        logger.debug(\"No product_type property on Rule nodes\")\n\n    return {\n        \"total_nodes\": total_nodes,\n        \"total_edges\": total_edges,\n        \"nodes_by_type\": nodes_by_type,\n        \"edges_by_relation\": edges_by_relation,\n        \"rules_by_action\": rules_by_action,\n        \"rules_by_product\": rules_by_product,\n    }\n</code></pre>"},{"location":"api-reference/backend/graph-service/#app.plugins.memory.services.graph_service.get_full_graph","title":"<code>get_full_graph(limit=500, risk_factor=None, product_type=None, action=None, node_type=None)</code>","text":"<p>Fetch the full graph (or a filtered subset).</p>"},{"location":"api-reference/backend/graph-service/#app.plugins.memory.services.graph_service.get_full_graph--parameters","title":"Parameters","text":"<p>limit : int     Maximum number of relationships to return. risk_factor : str | None     Filter to show only subgraph connected to this risk factor. product_type : str | None     Filter rules by product_type property. action : str | None     Filter rules by action property. node_type : str | None     Filter to only show nodes of this type.</p> Source code in <code>backend/app/plugins/memory/services/graph_service.py</code> <pre><code>def get_full_graph(\n    limit: int = 500,\n    risk_factor: str | None = None,\n    product_type: str | None = None,\n    action: str | None = None,\n    node_type: str | None = None,\n) -&gt; GraphData:\n    \"\"\"Fetch the full graph (or a filtered subset).\n\n    Parameters\n    ----------\n    limit : int\n        Maximum number of relationships to return.\n    risk_factor : str | None\n        Filter to show only subgraph connected to this risk factor.\n    product_type : str | None\n        Filter rules by product_type property.\n    action : str | None\n        Filter rules by action property.\n    node_type : str | None\n        Filter to only show nodes of this type.\n    \"\"\"\n    graph = _get_graph()\n\n    # Build the Cypher query based on filters\n    where_clauses: list[str] = []\n    params: dict[str, Any] = {}\n\n    if risk_factor:\n        # Match subgraph connected to the given risk factor\n        query = \"MATCH (rf:RiskFactor {name: $rf})-[r]-(m) \" \"RETURN rf, r, m LIMIT $limit\"\n        params = {\"rf\": risk_factor, \"limit\": limit}\n    elif action or product_type or node_type:\n        # Filter based on properties\n        match_clause = \"MATCH (n)-[r]-&gt;(m)\"\n\n        if action:\n            where_clauses.append(\n                \"(n:Rule AND n.action = $action) OR (m:Rule AND m.action = $action)\"\n            )\n            params[\"action\"] = action\n        if product_type:\n            where_clauses.append(\n                \"(n:Rule AND n.product_type = $product) OR \"\n                \"(m:Rule AND m.product_type = $product)\"\n            )\n            params[\"product\"] = product_type\n        if node_type:\n            where_clauses.append(f\"(n:{node_type} OR m:{node_type})\")\n\n        where_str = \" AND \".join(f\"({c})\" for c in where_clauses)\n        query = f\"{match_clause} WHERE {where_str} RETURN n, r, m LIMIT $limit\"\n        params[\"limit\"] = limit\n    else:\n        query = \"MATCH (n)-[r]-&gt;(m) RETURN n, r, m LIMIT $limit\"\n        params = {\"limit\": limit}\n\n    result = graph.query(query, params)\n\n    # Deduplicate nodes and edges\n    nodes_map: dict[str, GraphNode] = {}\n    edges_list: list[GraphEdge] = []\n    seen_edges: set[str] = set()\n\n    for row in result.result_set:\n        n_node = row[0]\n        rel = row[1]\n        m_node = row[2]\n\n        n_label = _extract_label(n_node)\n        m_label = _extract_label(m_node)\n\n        n_gn = _node_to_graph_node(n_node, n_label)\n        m_gn = _node_to_graph_node(m_node, m_label)\n\n        nodes_map[n_gn.id] = n_gn\n        nodes_map[m_gn.id] = m_gn\n\n        edge_key = f\"{n_gn.id}-&gt;{m_gn.id}:{rel.relation if hasattr(rel, 'relation') else 'RELATED'}\"\n        if edge_key not in seen_edges:\n            seen_edges.add(edge_key)\n            edges_list.append(_edge_to_graph_edge(rel, n_gn.id, m_gn.id))\n\n    nodes = list(nodes_map.values())\n\n    # Compute counts\n    node_counts: dict[str, int] = {}\n    for node in nodes:\n        node_counts[node.type] = node_counts.get(node.type, 0) + 1\n\n    edge_counts: dict[str, int] = {}\n    for edge in edges_list:\n        edge_counts[edge.type] = edge_counts.get(edge.type, 0) + 1\n\n    return GraphData(\n        nodes=nodes,\n        edges=edges_list,\n        node_counts=node_counts,\n        edge_counts=edge_counts,\n    )\n</code></pre>"},{"location":"api-reference/backend/graph-service/#app.plugins.memory.services.graph_service.search_nodes","title":"<code>search_nodes(query, limit=20)</code>","text":"<p>Search for nodes by name (case-insensitive contains).</p> Source code in <code>backend/app/plugins/memory/services/graph_service.py</code> <pre><code>def search_nodes(query: str, limit: int = 20) -&gt; list[GraphSearchResult]:\n    \"\"\"Search for nodes by name (case-insensitive contains).\"\"\"\n    graph = _get_graph()\n\n    q = query.lower()\n    result = graph.query(\n        \"MATCH (n) \"\n        \"WHERE toLower(n.name) CONTAINS $q \"\n        \"OPTIONAL MATCH (n)-[r]-() \"\n        \"RETURN n, labels(n)[0] AS label, count(r) AS connections \"\n        \"ORDER BY connections DESC \"\n        \"LIMIT $limit\",\n        {\"q\": q, \"limit\": limit},\n    )\n\n    results: list[GraphSearchResult] = []\n    for row in result.result_set:\n        node = row[0]\n        label = row[1] or \"Unknown\"\n        connections = row[2]\n        props = node.properties if hasattr(node, \"properties\") else {}\n        name = props.get(\"name\", \"unknown\")\n\n        # Build a snippet from properties\n        snippet_parts = []\n        for k, v in props.items():\n            if k != \"name\" and v is not None:\n                snippet_parts.append(f\"{k}: {v}\")\n        snippet = \"; \".join(snippet_parts[:3]) if snippet_parts else label\n\n        results.append(\n            GraphSearchResult(\n                node_id=f\"{label}:{_slugify(name)}\",\n                label=name,\n                type=label,\n                connected_nodes=connections,\n                snippet=snippet,\n            )\n        )\n\n    return results\n</code></pre>"},{"location":"api-reference/backend/graph-service/#app.plugins.memory.services.graph_service.get_neighborhood","title":"<code>get_neighborhood(node_id, depth=1)</code>","text":"<p>Get the neighborhood subgraph around a node.</p>"},{"location":"api-reference/backend/graph-service/#app.plugins.memory.services.graph_service.get_neighborhood--parameters","title":"Parameters","text":"<p>node_id : str     Node ID in format \"Label:slug\" (e.g. \"Rule:high_risk_decline\"). depth : int     How many hops from the focal node.</p> Source code in <code>backend/app/plugins/memory/services/graph_service.py</code> <pre><code>def get_neighborhood(node_id: str, depth: int = 1) -&gt; dict[str, Any]:\n    \"\"\"Get the neighborhood subgraph around a node.\n\n    Parameters\n    ----------\n    node_id : str\n        Node ID in format \"Label:slug\" (e.g. \"Rule:high_risk_decline\").\n    depth : int\n        How many hops from the focal node.\n    \"\"\"\n    graph = _get_graph()\n\n    # Parse node_id to get the label and name\n    parts = node_id.split(\":\", 1)\n    if len(parts) != 2:\n        msg = f\"Invalid node_id format: {node_id}. Expected 'Label:slug'.\"\n        raise ValueError(msg)\n\n    node_label = parts[0]\n    node_slug = parts[1]\n\n    # First find the focal node by matching slug against name\n    focal_result = graph.query(\n        f\"MATCH (n:{node_label}) \" \"RETURN n \" \"LIMIT 50\",\n    )\n\n    focal_node: GraphNode | None = None\n    focal_name: str | None = None\n    for row in focal_result.result_set:\n        n = row[0]\n        props = n.properties if hasattr(n, \"properties\") else {}\n        name = props.get(\"name\", \"\")\n        if _slugify(name) == node_slug:\n            focal_node = _node_to_graph_node(n, node_label)\n            focal_name = name\n            break\n\n    if focal_node is None or focal_name is None:\n        msg = f\"Node not found: {node_id}\"\n        raise ValueError(msg)\n\n    # Query the neighborhood\n    depth_param = max(1, min(depth, 3))\n    neighborhood_result = graph.query(\n        f\"MATCH (focal:{node_label} {{name: $name}})-[r*1..{depth_param}]-(neighbor) \"\n        \"UNWIND r AS rel \"\n        \"WITH focal, rel, startNode(rel) AS sn, endNode(rel) AS en \"\n        \"RETURN focal, rel, sn, en\",\n        {\"name\": focal_name},\n    )\n\n    nodes_map: dict[str, GraphNode] = {focal_node.id: focal_node}\n    edges_list: list[GraphEdge] = []\n    seen_edges: set[str] = set()\n\n    for row in neighborhood_result.result_set:\n        rel = row[1]\n        sn = row[2]\n        en = row[3]\n\n        sn_label = _extract_label(sn)\n        en_label = _extract_label(en)\n\n        sn_gn = _node_to_graph_node(sn, sn_label)\n        en_gn = _node_to_graph_node(en, en_label)\n\n        nodes_map[sn_gn.id] = sn_gn\n        nodes_map[en_gn.id] = en_gn\n\n        rel_type = rel.relation if hasattr(rel, \"relation\") else \"RELATED\"\n        edge_key = f\"{sn_gn.id}-&gt;{en_gn.id}:{rel_type}\"\n        if edge_key not in seen_edges:\n            seen_edges.add(edge_key)\n            edges_list.append(_edge_to_graph_edge(rel, sn_gn.id, en_gn.id))\n\n    return {\n        \"focal_node\": focal_node,\n        \"nodes\": list(nodes_map.values()),\n        \"edges\": edges_list,\n        \"depth\": depth_param,\n    }\n</code></pre>"},{"location":"api-reference/backend/human-signals-service/","title":"Human Signals Service","text":"<p>Human signals processing, signal flattening, and metrics aggregation.</p>"},{"location":"api-reference/backend/human-signals-service/#app.services.human_signals_service-functions","title":"Functions","text":""},{"location":"api-reference/backend/human-signals-service/#app.services.human_signals_service.safe_literal_eval","title":"<code>safe_literal_eval(s)</code>","text":"<p>Safely evaluate a Python literal string.</p> Source code in <code>backend/app/services/human_signals_service.py</code> <pre><code>def safe_literal_eval(s: str | None) -&gt; dict[str, Any] | list[Any] | None:\n    \"\"\"Safely evaluate a Python literal string.\"\"\"\n    if not s or (isinstance(s, float) and np.isnan(s)):\n        return None\n    try:\n        result = ast.literal_eval(str(s))\n        if isinstance(result, dict | list):\n            return result\n        return None\n    except Exception:\n        return None\n</code></pre>"},{"location":"api-reference/backend/human-signals-service/#app.services.human_signals_service.safe_json_or_literal","title":"<code>safe_json_or_literal(s)</code>","text":"<p>Try JSON first, fall back to Python literal eval.</p> Source code in <code>backend/app/services/human_signals_service.py</code> <pre><code>def safe_json_or_literal(s: str | None) -&gt; dict[str, Any] | list[Any] | None:\n    \"\"\"Try JSON first, fall back to Python literal eval.\"\"\"\n    if not s or (isinstance(s, float) and np.isnan(s)):\n        return None\n    raw = str(s).strip()\n    # Try JSON\n    try:\n        result = json.loads(raw)\n        if isinstance(result, dict | list):\n            return result\n        return None\n    except (json.JSONDecodeError, ValueError):\n        pass\n    # Fall back to ast.literal_eval\n    return safe_literal_eval(raw)\n</code></pre>"},{"location":"api-reference/backend/human-signals-service/#app.services.human_signals_service.extract_case_label","title":"<code>extract_case_label(content)</code>","text":"<p>Extract a short label from the first conversation message.</p> <p>Looks for a <code>New ... case: &lt;label&gt;</code> pattern first, then falls back to the first non-empty line of text (truncated to 80 chars).</p> Source code in <code>backend/app/services/human_signals_service.py</code> <pre><code>def extract_case_label(content: str | None) -&gt; str:\n    \"\"\"Extract a short label from the first conversation message.\n\n    Looks for a ``New ... case: &lt;label&gt;`` pattern first, then falls back\n    to the first non-empty line of text (truncated to 80 chars).\n    \"\"\"\n    if not content:\n        return \"Unknown\"\n    match = re.search(r\"New\\s+\\w+\\s+case:\\s*(.+?)(?:\\n|$)\", content)\n    if match:\n        return match.group(1).strip()\n    # Fallback: first non-empty line\n    for line in content.splitlines():\n        stripped = line.strip()\n        if stripped:\n            return stripped[:80]\n    return \"Unknown\"\n</code></pre>"},{"location":"api-reference/backend/human-signals-service/#app.services.human_signals_service.detect_signals_format","title":"<code>detect_signals_format(df)</code>","text":"<p>Detect if DataFrame has the required signals format (metric_name, dataset_id, signals).</p> Source code in <code>backend/app/services/human_signals_service.py</code> <pre><code>def detect_signals_format(df: pd.DataFrame) -&gt; bool:\n    \"\"\"Detect if DataFrame has the required signals format (metric_name, dataset_id, signals).\"\"\"\n    normalized = {col.lower().strip().replace(\" \", \"_\") for col in df.columns}\n    return {\"metric_name\", \"dataset_id\", \"signals\"}.issubset(normalized)\n</code></pre>"},{"location":"api-reference/backend/human-signals-service/#app.services.human_signals_service.detect_source_fields","title":"<code>detect_source_fields(df)</code>","text":"<p>Detect if data has source fields (source_name, source_component, environment).</p> Source code in <code>backend/app/services/human_signals_service.py</code> <pre><code>def detect_source_fields(df: pd.DataFrame) -&gt; bool:\n    \"\"\"Detect if data has source fields (source_name, source_component, environment).\"\"\"\n    cols = {col.lower().strip() for col in df.columns}\n    return \"source_name\" in cols\n</code></pre>"},{"location":"api-reference/backend/human-signals-service/#app.services.human_signals_service.build_metric_schema","title":"<code>build_metric_schema(df)</code>","text":"<p>Auto-discover metric schema from data.</p> <p>For each unique metric_name, inspects signals JSON across all rows to discover: - Signal keys and their types (boolean, string, number, array) - Unique values for string signals (for filter options and chart labels) - metric_category (classification vs score)</p> Source code in <code>backend/app/services/human_signals_service.py</code> <pre><code>def build_metric_schema(df: pd.DataFrame) -&gt; dict[str, Any]:\n    \"\"\"Auto-discover metric schema from data.\n\n    For each unique metric_name, inspects signals JSON across all rows to discover:\n    - Signal keys and their types (boolean, string, number, array)\n    - Unique values for string signals (for filter options and chart labels)\n    - metric_category (classification vs score)\n    \"\"\"\n    metrics: dict[str, Any] = {}\n\n    # Determine available source fields\n    source_fields = []\n    for field in [\"source_name\", \"source_component\", \"source_type\", \"environment\"]:\n        if field in df.columns:\n            source_fields.append(field)\n\n    has_timestamp = \"timestamp\" in df.columns\n\n    common_metadata = _detect_common_metadata_keys(df)\n\n    for metric_name, group in df.groupby(\"metric_name\"):\n        metric_name = str(metric_name).strip()\n        if not metric_name:\n            continue\n\n        # Get category from first row\n        category = str(group.iloc[0].get(\"metric_category\", \"classification\")).strip().lower()\n\n        # Collect all signal keys and their values\n        signal_values: dict[str, list[Any]] = {}\n        for _, row in group.iterrows():\n            signals = safe_json_or_literal(row.get(\"signals\"))\n            if not isinstance(signals, dict):\n                continue\n            expanded = _expand_category_signals(signals)\n            for key, val in expanded.items():\n                if key not in signal_values:\n                    signal_values[key] = []\n                signal_values[key].append(val)\n\n        # Strip common metadata keys (they pollute charts/filters)\n        for key in common_metadata:\n            signal_values.pop(key, None)\n\n        # Build signal types and unique values\n        signal_types: dict[str, str] = {}\n        unique_values: dict[str, list[str]] = {}\n\n        for key, vals in signal_values.items():\n            sig_type = _infer_signal_type(vals)\n            signal_types[key] = sig_type\n\n            if sig_type == \"string\":\n                # Collect unique non-empty string values\n                uniques = sorted({str(v) for v in vals if v is not None and str(v).strip() != \"\"})\n                if uniques:\n                    unique_values[key] = uniques\n\n        metrics[metric_name] = {\n            \"category\": category,\n            \"signals\": list(signal_values.keys()),\n            \"signal_types\": signal_types,\n            \"values\": unique_values,\n        }\n\n    # Filter to visible metrics if configured\n    visible = human_signals_db_config.visible_metrics\n    if visible:\n        metrics = {k: v for k, v in metrics.items() if k in visible}\n\n    return {\n        \"metrics\": metrics,\n        \"source_fields\": source_fields,\n        \"has_timestamp\": has_timestamp,\n    }\n</code></pre>"},{"location":"api-reference/backend/human-signals-service/#app.services.human_signals_service.aggregate_cases","title":"<code>aggregate_cases(df)</code>","text":"<p>Generic per-case aggregation.</p> <p>Groups by dataset_id, extracts shared columns (source_name, source_component, environment, timestamp, conversation, message_count), then for each metric row flattens all signals as {metric_name}__{signal_key}.</p> Source code in <code>backend/app/services/human_signals_service.py</code> <pre><code>def aggregate_cases(df: pd.DataFrame) -&gt; list[dict[str, Any]]:\n    \"\"\"Generic per-case aggregation.\n\n    Groups by dataset_id, extracts shared columns (source_name, source_component,\n    environment, timestamp, conversation, message_count), then for each metric row\n    flattens all signals as {metric_name}__{signal_key}.\n    \"\"\"\n    cases: list[dict[str, Any]] = []\n    common_metadata = _detect_common_metadata_keys(df)\n\n    for dataset_id, group in df.groupby(\"dataset_id\"):\n        first_row = group.iloc[0]\n        case: dict[str, Any] = {\"Case_ID\": str(dataset_id)}\n\n        # Extract source fields\n        for field in [\"source_name\", \"source_component\", \"source_type\", \"environment\"]:\n            if field in df.columns:\n                val = first_row.get(field)\n                case[field] = str(val) if pd.notna(val) else None\n\n        # Parse shared columns\n        additional_input = safe_json_or_literal(first_row.get(\"additional_input\"))\n        if isinstance(additional_input, dict):\n            case[\"Slack_URL\"] = additional_input.get(\"message_url\")\n            case[\"Agent_Name\"] = additional_input.get(\"sender\")\n        else:\n            case[\"Slack_URL\"] = None\n            case[\"Agent_Name\"] = case.get(\"source_name\")  # Fallback to source_name\n\n        # Parse conversation\n        conv_dict = safe_json_or_literal(first_row.get(\"conversation\"))\n        messages: list[dict[str, Any]] = []\n        if isinstance(conv_dict, dict):\n            messages = conv_dict.get(\"messages\", [])\n\n        # Extract a label from the first message\n        if messages:\n            case[\"Business\"] = extract_case_label(messages[0].get(\"content\", \"\"))\n        else:\n            case[\"Business\"] = \"Unknown\"\n\n        case[\"Full_Conversation\"] = messages\n\n        # Parse conversation stats\n        conv_stats = safe_json_or_literal(first_row.get(\"conversation_stats\"))\n        if isinstance(conv_stats, dict):\n            case[\"Message_Count\"] = conv_stats.get(\n                \"turn_count\",\n                conv_stats.get(\"user_message_count\", 0) + conv_stats.get(\"ai_message_count\", 0),\n            )\n        else:\n            case[\"Message_Count\"] = 0\n\n        # Timestamp\n        case[\"Timestamp\"] = str(first_row.get(\"timestamp\", \"\"))\n\n        # Extract additional structured metadata columns\n        for col in [\"evaluation_metadata\", \"actual_reference\", \"additional_output\"]:\n            if col in df.columns:\n                raw = first_row.get(col)\n                if pd.notna(raw):\n                    parsed = safe_json_or_literal(str(raw))\n                    if parsed is not None:\n                        case[col] = json.dumps(parsed)\n                    else:\n                        case[col] = str(raw)\n\n        # Store full additional_input as JSON (beyond Slack_URL/Agent_Name already extracted)\n        if additional_input is not None:\n            case[\"additional_input\"] = json.dumps(additional_input)\n\n        # Flatten all metric signals as {metric_name}__{signal_key}\n        visible = human_signals_db_config.visible_metrics\n        for _, row in group.iterrows():\n            metric_name = str(row.get(\"metric_name\", \"\")).strip()\n            if not metric_name:\n                continue\n            if visible and metric_name not in visible:\n                continue\n\n            signals = safe_json_or_literal(row.get(\"signals\"))\n            if not isinstance(signals, dict):\n                continue\n\n            expanded = _expand_category_signals(signals)\n            for signal_key, signal_val in expanded.items():\n                # Promote common metadata to case-level (first occurrence wins)\n                if signal_key in common_metadata:\n                    if signal_key not in case and signal_val is not None:\n                        case[signal_key] = signal_val\n                    continue\n\n                flat_key = f\"{metric_name}__{signal_key}\"\n                # Serialize complex values as JSON strings for clean DuckDB storage\n                if isinstance(signal_val, str):\n                    parsed = safe_json_or_literal(signal_val)\n                    if parsed is not None:\n                        signal_val = json.dumps(parsed)\n                elif isinstance(signal_val, dict | list):\n                    signal_val = json.dumps(signal_val)\n                case[flat_key] = signal_val\n\n        cases.append(case)\n\n    logger.info(f\"Aggregated {len(cases)} cases from {len(df)} metric rows\")\n    return cases\n</code></pre>"},{"location":"api-reference/backend/memory-service/","title":"Memory Service","text":"<p>Decision memory management, rule extraction, hard stops, and batch analysis.</p>"},{"location":"api-reference/backend/memory-service/#app.plugins.memory.services.memory_service-functions","title":"Functions","text":""},{"location":"api-reference/backend/memory-service/#app.plugins.memory.services.memory_service.set_data","title":"<code>set_data(rows)</code>","text":"<p>Replace the in-memory cache (called after CSV upload).</p> Source code in <code>backend/app/plugins/memory/services/memory_service.py</code> <pre><code>def set_data(rows: list[dict[str, Any]]) -&gt; None:\n    \"\"\"Replace the in-memory cache (called after CSV upload).\"\"\"\n    global _cache\n    _cache = rows\n    logger.info(\"Memory cache updated with %d records\", len(rows))\n</code></pre>"},{"location":"api-reference/backend/memory-service/#app.plugins.memory.services.memory_service.get_all_rules","title":"<code>get_all_rules(filters)</code>","text":"<p>Return filtered rules with available filter values.</p> <p>Parameters:</p> Name Type Description Default <code>filters</code> <code>dict[str, str]</code> <p>dict of role_name -&gt; value to filter on.</p> required Source code in <code>backend/app/plugins/memory/services/memory_service.py</code> <pre><code>def get_all_rules(filters: dict[str, str]) -&gt; dict[str, Any]:\n    \"\"\"Return filtered rules with available filter values.\n\n    Args:\n        filters: dict of role_name -&gt; value to filter on.\n    \"\"\"\n    data = _load_data()\n\n    # Build filter values from full dataset for configured filter_roles + batch\n    filter_keys = [*list(memory_config.filter_roles), \"batch\"]\n    filters_available: dict[str, list[str]] = {}\n    for role in filter_keys:\n        filters_available[role] = sorted({str(r.get(role, \"\")) for r in data if r.get(role)})\n\n    # Apply filters\n    filtered = data\n    for role, value in filters.items():\n        if value:\n            filtered = [r for r in filtered if str(r.get(role, \"\")) == value]\n\n    return {\n        \"data\": [_to_rule_record(r) for r in filtered],\n        \"total\": len(filtered),\n        \"filters_available\": filters_available,\n    }\n</code></pre>"},{"location":"api-reference/backend/memory-service/#app.plugins.memory.services.memory_service.get_summary","title":"<code>get_summary()</code>","text":"<p>Aggregate summary statistics.</p> Source code in <code>backend/app/plugins/memory/services/memory_service.py</code> <pre><code>def get_summary() -&gt; dict[str, Any]:\n    \"\"\"Aggregate summary statistics.\"\"\"\n    data = _load_data()\n    return _compute_summary(data)\n</code></pre>"},{"location":"api-reference/backend/memory-service/#app.plugins.memory.services.memory_service.get_decision_quality","title":"<code>get_decision_quality()</code>","text":"<p>Split rules by quality role using configured quality_values.</p> Source code in <code>backend/app/plugins/memory/services/memory_service.py</code> <pre><code>def get_decision_quality() -&gt; dict[str, Any]:\n    \"\"\"Split rules by quality role using configured quality_values.\"\"\"\n    data = _load_data()\n    qv = memory_config.quality_values\n    aligned = [_to_rule_record(r) for r in data if r.get(\"quality\") == qv[\"aligned\"]]\n    divergent = [_to_rule_record(r) for r in data if r.get(\"quality\") == qv[\"divergent\"]]\n    partial = [_to_rule_record(r) for r in data if r.get(\"quality\") == qv[\"partial\"]]\n    return {\"aligned\": aligned, \"divergent\": divergent, \"partial\": partial}\n</code></pre>"},{"location":"api-reference/backend/memory-service/#app.plugins.memory.services.memory_service.get_soft_thresholds","title":"<code>get_soft_thresholds()</code>","text":"<p>Return rules with soft thresholds.</p> Source code in <code>backend/app/plugins/memory/services/memory_service.py</code> <pre><code>def get_soft_thresholds() -&gt; dict[str, Any]:\n    \"\"\"Return rules with soft thresholds.\"\"\"\n    data = _load_data()\n    stv = memory_config.soft_threshold_value\n    soft = [_to_rule_record(r) for r in data if r.get(\"threshold_type\") == stv]\n    return {\"data\": soft}\n</code></pre>"},{"location":"api-reference/backend/memory-service/#app.plugins.memory.services.memory_service.get_hard_stops","title":"<code>get_hard_stops()</code>","text":"<p>Return hard stops based on config: action matches action_value AND mitigants empty.</p> Source code in <code>backend/app/plugins/memory/services/memory_service.py</code> <pre><code>def get_hard_stops() -&gt; dict[str, Any]:\n    \"\"\"Return hard stops based on config: action matches action_value AND mitigants empty.\"\"\"\n    data = _load_data()\n    hs = memory_config.hard_stops\n    action_value = hs.get(\"action_value\", \"decline\")\n    require_empty = hs.get(\"require_empty_mitigants\", True)\n\n    stops = []\n    for r in data:\n        if r.get(\"action\") != action_value:\n            continue\n        if require_empty and r.get(\"mitigants\"):\n            continue\n        stops.append(_to_rule_record(r))\n\n    return {\"data\": stops}\n</code></pre>"},{"location":"api-reference/backend/memory-service/#app.plugins.memory.services.memory_service.get_batches","title":"<code>get_batches()</code>","text":"<p>Group rules by batch role.</p> Source code in <code>backend/app/plugins/memory/services/memory_service.py</code> <pre><code>def get_batches() -&gt; dict[str, Any]:\n    \"\"\"Group rules by batch role.\"\"\"\n    data = _load_data()\n    batches: dict[str, list[dict[str, Any]]] = {}\n    for row in data:\n        bid = row.get(\"batch\", \"unknown\")\n        batches.setdefault(bid, []).append(row)\n\n    result = []\n    for bid, rows in batches.items():\n        status_counter = Counter(r.get(\"status\", \"unknown\") for r in rows)\n        cats = sorted({r.get(\"category\", \"\") for r in rows if r.get(\"category\")})\n        created_dates = [r.get(\"created_at\", \"\") for r in rows if r.get(\"created_at\")]\n        earliest = min(created_dates) if created_dates else \"\"\n        result.append(\n            {\n                \"batch_id\": bid,\n                \"rules_count\": len(rows),\n                \"created_at\": earliest,\n                \"statuses\": dict(status_counter),\n                \"risk_categories\": cats,\n            }\n        )\n\n    return {\"data\": result}\n</code></pre>"},{"location":"api-reference/backend/memory-service/#app.plugins.memory.services.memory_service.get_trace","title":"<code>get_trace(rule_id)</code>","text":"<p>Build a trace path from a single rule's fields.</p> Source code in <code>backend/app/plugins/memory/services/memory_service.py</code> <pre><code>def get_trace(rule_id: str) -&gt; dict[str, Any] | None:\n    \"\"\"Build a trace path from a single rule's fields.\"\"\"\n    data = _load_data()\n    row = next((r for r in data if r.get(\"id\") == rule_id), None)\n    if row is None:\n        return None\n    return {\n        \"group_by\": row.get(\"group_by\", \"\"),\n        \"name\": row.get(\"name\", \"\"),\n        \"action\": row.get(\"action\", \"\"),\n        \"description\": row.get(\"description\", \"\"),\n        \"mitigants\": row.get(\"mitigants\", []),\n        \"threshold_value\": row.get(\"threshold_value\", \"\"),\n        \"threshold_type\": row.get(\"threshold_type\", \"\"),\n    }\n</code></pre>"},{"location":"api-reference/backend/memory-service/#app.plugins.memory.services.memory_service.get_conflicts","title":"<code>get_conflicts()</code>","text":"<p>Find risk factors with contradictory actions.</p> Source code in <code>backend/app/plugins/memory/services/memory_service.py</code> <pre><code>def get_conflicts() -&gt; dict[str, Any]:\n    \"\"\"Find risk factors with contradictory actions.\"\"\"\n    data = _load_data()\n\n    # Group by (group_by, product) roles\n    groups: dict[tuple[str, str], list[dict[str, Any]]] = {}\n    for row in data:\n        rf = row.get(\"group_by\", \"\")\n        pt = row.get(\"product\", \"\")\n        if rf:\n            groups.setdefault((rf, pt), []).append(row)\n\n    conflicts = []\n    contradictory_sets = memory_config.contradictory_frozensets\n    for (rf, _pt), rows in groups.items():\n        actions_in_group = {r.get(\"action\", \"\") for r in rows}\n        if len(actions_in_group) &lt; 2:\n            continue\n\n        # Check if any pair is truly contradictory\n        is_contradictory = False\n        for a1 in actions_in_group:\n            for a2 in actions_in_group:\n                if a1 != a2 and frozenset({a1, a2}) in contradictory_sets:\n                    is_contradictory = True\n                    break\n            if is_contradictory:\n                break\n\n        if is_contradictory:\n            conflicting_rules = [\n                {\"rule_name\": r.get(\"name\", \"\"), \"action\": r.get(\"action\", \"\")} for r in rows\n            ]\n            desc = (\n                f\"Risk factor '{rf}' has contradictory actions: \"\n                f\"{', '.join(sorted(actions_in_group))}\"\n            )\n            conflicts.append(\n                {\n                    \"risk_factor\": rf,\n                    \"conflicting_rules\": conflicting_rules,\n                    \"description\": desc,\n                }\n            )\n\n    return {\"data\": conflicts, \"has_conflicts\": len(conflicts) &gt; 0}\n</code></pre>"},{"location":"api-reference/backend/memory-service/#app.plugins.memory.services.memory_service.get_status_counts","title":"<code>get_status_counts()</code>","text":"<p>Count rules by status role.</p> Source code in <code>backend/app/plugins/memory/services/memory_service.py</code> <pre><code>def get_status_counts() -&gt; dict[str, Any]:\n    \"\"\"Count rules by status role.\"\"\"\n    data = _load_data()\n    counter = Counter(r.get(\"status\", \"unknown\") for r in data)\n    return {\"data\": dict(counter)}\n</code></pre>"},{"location":"api-reference/backend/memory-service/#app.plugins.memory.services.memory_service.process_uploaded_csv","title":"<code>process_uploaded_csv(csv_content)</code>","text":"<p>Process uploaded CSV content into structured role-keyed rule records.</p> <p>Maps CSV column names -&gt; role names using field_roles config at import time.</p> Source code in <code>backend/app/plugins/memory/services/memory_service.py</code> <pre><code>def process_uploaded_csv(csv_content: str) -&gt; dict[str, Any]:\n    \"\"\"Process uploaded CSV content into structured role-keyed rule records.\n\n    Maps CSV column names -&gt; role names using field_roles config at import time.\n    \"\"\"\n    import io\n\n    reader = csv.DictReader(io.StringIO(csv_content))\n    raw_rows: list[dict[str, Any]] = []\n    columns: list[str] = []\n    for i, row in enumerate(reader):\n        if i == 0:\n            columns = list(row.keys())\n        raw_rows.append(dict(row))\n\n    if not raw_rows:\n        return {\n            \"success\": True,\n            \"format\": \"memory\",\n            \"row_count\": 0,\n            \"columns\": columns,\n            \"data\": [],\n            \"filters_available\": {},\n            \"summary\": {\n                \"rules_count\": 0,\n                \"risk_factors_count\": 0,\n                \"mitigants_count\": 0,\n                \"hard_stops_count\": 0,\n                \"rules_by_action\": [],\n                \"rules_by_product\": [],\n            },\n            \"message\": \"CSV was empty\",\n        }\n\n    # Check that required columns exist in CSV\n    roles = memory_config.field_roles\n    csv_columns_set = set(columns)\n    missing_required: list[str] = []\n    for role in memory_config.required_roles:\n        col = roles.column_for(role)\n        if col not in csv_columns_set:\n            missing_required.append(f\"'{col}' (for role '{role}')\")\n    if missing_required:\n        return {\n            \"success\": False,\n            \"format\": \"memory\",\n            \"row_count\": 0,\n            \"columns\": columns,\n            \"data\": [],\n            \"filters_available\": {},\n            \"summary\": {\n                \"rules_count\": 0,\n                \"risk_factors_count\": 0,\n                \"mitigants_count\": 0,\n                \"hard_stops_count\": 0,\n                \"rules_by_action\": [],\n                \"rules_by_product\": [],\n            },\n            \"message\": f\"Missing required columns: {', '.join(missing_required)}\",\n        }\n\n    # Map column names -&gt; role names at import time\n    role_keyed_rows: list[dict[str, Any]] = []\n    roles_dict = roles.to_dict()\n    list_fields_set = set(memory_config.list_fields)\n\n    for raw_row in raw_rows:\n        record: dict[str, Any] = {}\n        for role, col in roles_dict.items():\n            val = raw_row.get(col, \"\")\n            if role in list_fields_set:\n                val = _parse_list_field(str(val) if val else \"\")\n            record[role] = val\n        role_keyed_rows.append(record)\n\n    records = [_to_rule_record(r) for r in role_keyed_rows]\n    set_data(role_keyed_rows)\n    logger.info(\"Processed %d rule extraction records from upload\", len(records))\n\n    return {\n        \"success\": True,\n        \"format\": \"memory\",\n        \"row_count\": len(records),\n        \"columns\": columns,\n        \"data\": records,\n        \"filters_available\": _compute_filters_available(role_keyed_rows),\n        \"summary\": _compute_summary(role_keyed_rows),\n    }\n</code></pre>"},{"location":"api-reference/backend/memory-service/#app.plugins.memory.services.memory_service.create_rule","title":"<code>create_rule(data)</code>","text":"<p>Create a new rule in the in-memory cache (mock \u2014 swap for DB write later).</p> <p>Accepts role-keyed data directly. Validates required roles.</p> Source code in <code>backend/app/plugins/memory/services/memory_service.py</code> <pre><code>def create_rule(data: dict[str, Any]) -&gt; dict[str, Any]:\n    \"\"\"Create a new rule in the in-memory cache (mock \u2014 swap for DB write later).\n\n    Accepts role-keyed data directly. Validates required roles.\n    \"\"\"\n    import uuid\n    from datetime import datetime\n\n    cache = _load_data()\n\n    # Validate required roles\n    missing = memory_config.validate_required_roles(data)\n    # id, batch, and status are auto-generated for new rules\n    auto_generated = {\"id\", \"batch\", \"status\"}\n    real_missing = [r for r in missing if r not in auto_generated]\n    if real_missing:\n        msg = f\"Missing required fields: {', '.join(real_missing)}\"\n        raise ValueError(msg)\n\n    new_id = str(uuid.uuid4())\n    now = datetime.now(UTC).isoformat()\n\n    row: dict[str, Any] = {\n        \"id\": new_id,\n        \"created_at\": now,\n        \"batch\": \"manual\",\n        \"status\": \"pending\",\n    }\n\n    # Copy all provided role-keyed fields\n    for key, value in data.items():\n        if key not in row:\n            row[key] = value\n\n    # Ensure list fields default to empty list\n    for lf in memory_config.list_fields:\n        if lf not in row:\n            row[lf] = []\n\n    cache.insert(0, row)\n    logger.info(\"Created rule %s: %s\", new_id, data.get(\"name\", \"\"))\n    return _to_rule_record(row)\n</code></pre>"},{"location":"api-reference/backend/memory-service/#app.plugins.memory.services.memory_service.delete_rule","title":"<code>delete_rule(rule_id)</code>","text":"<p>Delete a rule from the in-memory cache (mock \u2014 swap for DB delete later).</p> Source code in <code>backend/app/plugins/memory/services/memory_service.py</code> <pre><code>def delete_rule(rule_id: str) -&gt; bool:\n    \"\"\"Delete a rule from the in-memory cache (mock \u2014 swap for DB delete later).\"\"\"\n    cache = _load_data()\n    for i, row in enumerate(cache):\n        if row.get(\"id\") == rule_id:\n            cache.pop(i)\n            logger.info(\"Deleted rule %s\", rule_id)\n            return True\n    return False\n</code></pre>"},{"location":"api-reference/backend/memory-service/#app.plugins.memory.services.memory_service.update_rule","title":"<code>update_rule(rule_id, updates)</code>","text":"<p>Update a rule in the in-memory cache (mock \u2014 swap for DB write later).</p> <p>Accepts role-keyed updates directly.</p> Source code in <code>backend/app/plugins/memory/services/memory_service.py</code> <pre><code>def update_rule(rule_id: str, updates: dict[str, Any]) -&gt; dict[str, Any] | None:\n    \"\"\"Update a rule in the in-memory cache (mock \u2014 swap for DB write later).\n\n    Accepts role-keyed updates directly.\n    \"\"\"\n    data = _load_data()\n    row = next((r for r in data if r.get(\"id\") == rule_id), None)\n    if row is None:\n        return None\n\n    for key, value in updates.items():\n        if value is not None:\n            row[key] = value\n\n    logger.info(\"Updated rule %s: %s\", rule_id, list(updates.keys()))\n    return _to_rule_record(row)\n</code></pre>"},{"location":"api-reference/backend/schemas/","title":"Schemas","text":"<p>Pydantic data models used across the AXIS backend.</p>"},{"location":"api-reference/backend/schemas/#core-schemas","title":"Core Schemas","text":""},{"location":"api-reference/backend/schemas/#app.models.schemas-classes","title":"Classes","text":""},{"location":"api-reference/backend/schemas/#app.models.schemas.DataFormat","title":"<code>DataFormat</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Supported evaluation data formats.</p>"},{"location":"api-reference/backend/schemas/#app.models.schemas.UploadResponse","title":"<code>UploadResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response after uploading evaluation data.</p>"},{"location":"api-reference/backend/schemas/#app.models.schemas.DataFormatResponse","title":"<code>DataFormatResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response for data format detection.</p>"},{"location":"api-reference/backend/schemas/#app.models.schemas.DataPreviewResponse","title":"<code>DataPreviewResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Preview of uploaded data with column info.</p>"},{"location":"api-reference/backend/schemas/#app.models.schemas.MetricSummary","title":"<code>MetricSummary</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Summary statistics for a single metric.</p>"},{"location":"api-reference/backend/schemas/#app.models.schemas.SummaryResponse","title":"<code>SummaryResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Aggregated summary of all metrics.</p>"},{"location":"api-reference/backend/schemas/#app.models.schemas.DistributionStats","title":"<code>DistributionStats</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Descriptive statistics for a metric distribution.</p>"},{"location":"api-reference/backend/schemas/#app.models.schemas.Histogram","title":"<code>Histogram</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Histogram bin counts and edges.</p>"},{"location":"api-reference/backend/schemas/#app.models.schemas.DistributionResponse","title":"<code>DistributionResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Full distribution data for a single metric.</p>"},{"location":"api-reference/backend/schemas/#app.models.schemas.EvaluationRecord","title":"<code>EvaluationRecord</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A single evaluation record with input/output fields.</p>"},{"location":"api-reference/backend/schemas/#app.models.schemas.EvaluationRecord-classes","title":"Classes","text":""},{"location":"api-reference/backend/schemas/#app.models.schemas.EvaluationRecord.Config","title":"<code>Config</code>","text":"<p>Pydantic config allowing extra fields.</p>"},{"location":"api-reference/backend/schemas/#app.models.schemas.TreeMetric","title":"<code>TreeMetric</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A metric in the tree-format evaluation structure.</p>"},{"location":"api-reference/backend/schemas/#app.models.schemas.Annotation","title":"<code>Annotation</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A human annotation on an evaluation record.</p>"},{"location":"api-reference/backend/schemas/#app.models.schemas.Persona","title":"<code>Persona</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A simulation persona with traits.</p>"},{"location":"api-reference/backend/schemas/#app.models.schemas.SimulationConfig","title":"<code>SimulationConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for running a simulation.</p>"},{"location":"api-reference/backend/schemas/#app.models.schemas.SimulationResult","title":"<code>SimulationResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result of a single simulation run.</p>"},{"location":"api-reference/backend/schemas/#app.models.schemas.CalibrationResult","title":"<code>CalibrationResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Inter-annotator agreement calibration results.</p>"},{"location":"api-reference/backend/schemas/#app.models.schemas.ChatMessage","title":"<code>ChatMessage</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A single chat message.</p>"},{"location":"api-reference/backend/schemas/#app.models.schemas.AnalysisInsight","title":"<code>AnalysisInsight</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>An automated insight from data analysis.</p>"},{"location":"api-reference/backend/schemas/#database-schemas","title":"Database Schemas","text":""},{"location":"api-reference/backend/schemas/#app.models.database_schemas-classes","title":"Classes","text":""},{"location":"api-reference/backend/schemas/#app.models.database_schemas.SSLMode","title":"<code>SSLMode</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Database SSL connection modes.</p>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.DatabaseConnectionRequest","title":"<code>DatabaseConnectionRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request to connect to a database.</p>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.DatabaseConnectionRequest-functions","title":"Functions","text":""},{"location":"api-reference/backend/schemas/#app.models.database_schemas.DatabaseConnectionRequest.validate_host","title":"<code>validate_host(v)</code>  <code>classmethod</code>","text":"<p>Validate host is not empty.</p> Source code in <code>backend/app/models/database_schemas.py</code> <pre><code>@field_validator(\"host\")\n@classmethod\ndef validate_host(cls, v: str) -&gt; str:\n    \"\"\"Validate host is not empty.\"\"\"\n    if not v or not v.strip():\n        raise ValueError(\"Host cannot be empty\")\n    return v.strip()\n</code></pre>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.DatabaseConnectionRequest.validate_database","title":"<code>validate_database(v)</code>  <code>classmethod</code>","text":"<p>Validate database name is not empty.</p> Source code in <code>backend/app/models/database_schemas.py</code> <pre><code>@field_validator(\"database\")\n@classmethod\ndef validate_database(cls, v: str) -&gt; str:\n    \"\"\"Validate database name is not empty.\"\"\"\n    if not v or not v.strip():\n        raise ValueError(\"Database name cannot be empty\")\n    return v.strip()\n</code></pre>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.DatabaseConnectionRequest.validate_username","title":"<code>validate_username(v)</code>  <code>classmethod</code>","text":"<p>Validate username is not empty.</p> Source code in <code>backend/app/models/database_schemas.py</code> <pre><code>@field_validator(\"username\")\n@classmethod\ndef validate_username(cls, v: str) -&gt; str:\n    \"\"\"Validate username is not empty.\"\"\"\n    if not v or not v.strip():\n        raise ValueError(\"Username cannot be empty\")\n    return v.strip()\n</code></pre>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.DatabaseConnectionRequest.validate_port","title":"<code>validate_port(v)</code>  <code>classmethod</code>","text":"<p>Validate port is in valid range.</p> Source code in <code>backend/app/models/database_schemas.py</code> <pre><code>@field_validator(\"port\")\n@classmethod\ndef validate_port(cls, v: int) -&gt; int:\n    \"\"\"Validate port is in valid range.\"\"\"\n    if v &lt; 1 or v &gt; 65535:\n        raise ValueError(\"Port must be between 1 and 65535\")\n    return v\n</code></pre>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.ConnectResponse","title":"<code>ConnectResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response from a successful database connection.</p>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.TableIdentifier","title":"<code>TableIdentifier</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Identifier for a database table.</p>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.TableIdentifier-functions","title":"Functions","text":""},{"location":"api-reference/backend/schemas/#app.models.database_schemas.TableIdentifier.validate_name","title":"<code>validate_name(v)</code>  <code>classmethod</code>","text":"<p>Validate table name is not empty.</p> Source code in <code>backend/app/models/database_schemas.py</code> <pre><code>@field_validator(\"name\")\n@classmethod\ndef validate_name(cls, v: str) -&gt; str:\n    \"\"\"Validate table name is not empty.\"\"\"\n    if not v or not v.strip():\n        raise ValueError(\"Table name cannot be empty\")\n    return v.strip()\n</code></pre>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.TableInfo","title":"<code>TableInfo</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Information about a database table.</p>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.TablesListResponse","title":"<code>TablesListResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response containing list of tables.</p>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.ColumnInfo","title":"<code>ColumnInfo</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Information about a table column.</p>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.TableSchemaResponse","title":"<code>TableSchemaResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response containing table schema information.</p>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.ColumnMapping","title":"<code>ColumnMapping</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Mapping from source DB column to target AXIS column.</p> <p>Supported target columns: - dataset_id, query, actual_output, expected_output - retrieved_content, conversation, additional_input, document_text - actual_reference, expected_reference - tools_called, expected_tools, acceptance_criteria - latency, trace_id, observation_id</p>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.FilterCondition","title":"<code>FilterCondition</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Simple equality filter condition.</p>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.DatabaseImportRequest","title":"<code>DatabaseImportRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request to import data from database.</p>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.DatabaseImportRequest-functions","title":"Functions","text":""},{"location":"api-reference/backend/schemas/#app.models.database_schemas.DatabaseImportRequest.validate_limit","title":"<code>validate_limit(v)</code>  <code>classmethod</code>","text":"<p>Validate limit is within bounds.</p> Source code in <code>backend/app/models/database_schemas.py</code> <pre><code>@field_validator(\"limit\")\n@classmethod\ndef validate_limit(cls, v: int) -&gt; int:\n    \"\"\"Validate limit is within bounds.\"\"\"\n    if v &lt; 1:\n        raise ValueError(\"Limit must be at least 1\")\n    if v &gt; 10000:\n        raise ValueError(\"Limit cannot exceed 10000 rows\")\n    return v\n</code></pre>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.PreviewRequest","title":"<code>PreviewRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request to preview data from database.</p>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.PreviewResponse","title":"<code>PreviewResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response containing preview data.</p>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.DistinctValuesRequest","title":"<code>DistinctValuesRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request to get distinct values for a column.</p>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.DistinctValuesResponse","title":"<code>DistinctValuesResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response containing distinct values.</p>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.DatabaseDefaults","title":"<code>DatabaseDefaults</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Default database connection values from config.</p>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.QueryPreviewRequest","title":"<code>QueryPreviewRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request to preview results of a SQL query.</p>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.QueryPreviewRequest-functions","title":"Functions","text":""},{"location":"api-reference/backend/schemas/#app.models.database_schemas.QueryPreviewRequest.validate_query","title":"<code>validate_query(v)</code>  <code>classmethod</code>","text":"<p>Validate query is safe.</p> Source code in <code>backend/app/models/database_schemas.py</code> <pre><code>@field_validator(\"query\")\n@classmethod\ndef validate_query(cls, v: str) -&gt; str:\n    \"\"\"Validate query is safe.\"\"\"\n    return _validate_sql_query(v)\n</code></pre>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.QueryPreviewRequest.validate_limit","title":"<code>validate_limit(v)</code>  <code>classmethod</code>","text":"<p>Validate limit is within bounds.</p> Source code in <code>backend/app/models/database_schemas.py</code> <pre><code>@field_validator(\"limit\")\n@classmethod\ndef validate_limit(cls, v: int) -&gt; int:\n    \"\"\"Validate limit is within bounds.\"\"\"\n    if v &lt; 1:\n        raise ValueError(\"Limit must be at least 1\")\n    if v &gt; 100:\n        raise ValueError(\"Preview limit cannot exceed 100 rows\")\n    return v\n</code></pre>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.QueryImportRequest","title":"<code>QueryImportRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request to import data from a SQL query.</p>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.QueryImportRequest-functions","title":"Functions","text":""},{"location":"api-reference/backend/schemas/#app.models.database_schemas.QueryImportRequest.validate_query","title":"<code>validate_query(v)</code>  <code>classmethod</code>","text":"<p>Validate query is safe.</p> Source code in <code>backend/app/models/database_schemas.py</code> <pre><code>@field_validator(\"query\")\n@classmethod\ndef validate_query(cls, v: str) -&gt; str:\n    \"\"\"Validate query is safe.\"\"\"\n    return _validate_sql_query(v)\n</code></pre>"},{"location":"api-reference/backend/schemas/#app.models.database_schemas.QueryImportRequest.validate_limit","title":"<code>validate_limit(v)</code>  <code>classmethod</code>","text":"<p>Validate limit is within bounds.</p> Source code in <code>backend/app/models/database_schemas.py</code> <pre><code>@field_validator(\"limit\")\n@classmethod\ndef validate_limit(cls, v: int) -&gt; int:\n    \"\"\"Validate limit is within bounds.\"\"\"\n    if v &lt; 1:\n        raise ValueError(\"Limit must be at least 1\")\n    if v &gt; 50000:\n        raise ValueError(\"Import limit cannot exceed 50000 rows\")\n    return v\n</code></pre>"},{"location":"api-reference/backend/schemas/#evaluation-runner-schemas","title":"Evaluation Runner Schemas","text":""},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas-classes","title":"Classes","text":""},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.AgentType","title":"<code>AgentType</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Type of agent connection for generating outputs.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.LLMProvider","title":"<code>LLMProvider</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Supported LLM providers for evaluation metrics.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.MetricInfo","title":"<code>MetricInfo</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Information about an available evaluation metric.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.MetricsResponse","title":"<code>MetricsResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response with available metrics.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.ColumnMapping","title":"<code>ColumnMapping</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Mapping of canonical field names to actual column names in the dataset.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.DatasetInfo","title":"<code>DatasetInfo</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Information about an uploaded dataset.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.UploadResponse","title":"<code>UploadResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response from dataset upload.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.AgentAPIConfig","title":"<code>AgentAPIConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for Agent API connection.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.PromptTemplateConfig","title":"<code>PromptTemplateConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for LLM prompt template.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.AgentConfig","title":"<code>AgentConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for agent connection.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.TestConnectionRequest","title":"<code>TestConnectionRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request to test agent connection.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.TestConnectionResponse","title":"<code>TestConnectionResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response from testing agent connection.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.DatasetConfig","title":"<code>DatasetConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Dataset configuration including column mapping and data.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.EvaluationRunRequest","title":"<code>EvaluationRunRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request to run an evaluation.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.MetricResult","title":"<code>MetricResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result for a single metric across all items.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.ItemResult","title":"<code>ItemResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result for a single evaluation item.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.EvaluationSummary","title":"<code>EvaluationSummary</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Summary of evaluation results.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.EvaluationResultResponse","title":"<code>EvaluationResultResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Full response from completed evaluation.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.ProgressEvent","title":"<code>ProgressEvent</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Progress update during evaluation.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.LogEvent","title":"<code>LogEvent</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Log message during evaluation.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.CompleteEvent","title":"<code>CompleteEvent</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Completion event with results.</p>"},{"location":"api-reference/backend/schemas/#app.models.eval_runner_schemas.ErrorEvent","title":"<code>ErrorEvent</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Error event during evaluation.</p>"},{"location":"api-reference/backend/schemas/#memory-schemas","title":"Memory Schemas","text":""},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.memory_schemas-classes","title":"Classes","text":""},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.memory_schemas.RuleRecord","title":"<code>RuleRecord</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A single extracted rule. Only <code>id</code> is typed; all other role-keyed fields are extras.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.memory_schemas.ActionCount","title":"<code>ActionCount</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Count of rules per action type.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.memory_schemas.ProductCount","title":"<code>ProductCount</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Count of rules per product type.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.memory_schemas.SummaryResponse","title":"<code>SummaryResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Summary statistics for the rule memory.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.memory_schemas.RulesResponse","title":"<code>RulesResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Paginated list of rules with available filters.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.memory_schemas.QualityResponse","title":"<code>QualityResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Decision quality breakdown into aligned, divergent, and partial.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.memory_schemas.SoftThresholdsResponse","title":"<code>SoftThresholdsResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Rules with soft thresholds.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.memory_schemas.HardStopsResponse","title":"<code>HardStopsResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Rules classified as hard stops.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.memory_schemas.BatchInfo","title":"<code>BatchInfo</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Metadata for a single extraction batch.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.memory_schemas.BatchesResponse","title":"<code>BatchesResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>List of extraction batches.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.memory_schemas.TraceResponse","title":"<code>TraceResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Trace detail for a single rule \u2014 all fields are dynamic.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.memory_schemas.ConflictInfo","title":"<code>ConflictInfo</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Information about conflicting rules for a risk factor.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.memory_schemas.ConflictsResponse","title":"<code>ConflictsResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response containing detected rule conflicts.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.memory_schemas.StatusCountsResponse","title":"<code>StatusCountsResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Counts of rules grouped by ingestion status.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.memory_schemas.RuleCreateRequest","title":"<code>RuleCreateRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Create a new rule \u2014 accepts any role-keyed fields.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.memory_schemas.RuleUpdateRequest","title":"<code>RuleUpdateRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Partial update for a rule \u2014 only provided fields are changed.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.memory_schemas.RuleUpdateResponse","title":"<code>RuleUpdateResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response after creating or updating a rule.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.memory_schemas.RuleDeleteResponse","title":"<code>RuleDeleteResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response after deleting a rule.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.memory_schemas.MemoryUploadResponse","title":"<code>MemoryUploadResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response after uploading memory data.</p>"},{"location":"api-reference/backend/schemas/#graph-schemas","title":"Graph Schemas","text":""},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.graph_schemas-classes","title":"Classes","text":""},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.graph_schemas.GraphNode","title":"<code>GraphNode</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A node in the knowledge graph.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.graph_schemas.GraphEdge","title":"<code>GraphEdge</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>An edge in the knowledge graph.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.graph_schemas.GraphData","title":"<code>GraphData</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Full graph payload with nodes and edges.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.graph_schemas.GraphResponse","title":"<code>GraphResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>API response wrapping graph data.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.graph_schemas.GraphSearchResult","title":"<code>GraphSearchResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A single search result from the graph.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.graph_schemas.GraphSearchResponse","title":"<code>GraphSearchResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>API response for graph search.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.graph_schemas.GraphNeighborhoodResponse","title":"<code>GraphNeighborhoodResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>API response for a node's neighborhood subgraph.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.graph_schemas.GraphSummaryResponse","title":"<code>GraphSummaryResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>API response for graph summary statistics.</p>"},{"location":"api-reference/backend/schemas/#app.plugins.memory.models.graph_schemas.GraphStatusResponse","title":"<code>GraphStatusResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>API response for graph connection health check.</p>"},{"location":"api-reference/backend/schemas/#alignment-schemas","title":"Alignment Schemas","text":""},{"location":"api-reference/backend/schemas/#app.models.align_schemas-classes","title":"Classes","text":""},{"location":"api-reference/backend/schemas/#app.models.align_schemas.LLMProvider","title":"<code>LLMProvider</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Supported LLM providers.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.FewShotExample","title":"<code>FewShotExample</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A few-shot example for the judge prompt.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.JudgeConfig","title":"<code>JudgeConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Configuration for the LLM judge.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.AlignmentMetrics","title":"<code>AlignmentMetrics</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Computed alignment metrics between human and LLM scores.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.AlignmentResult","title":"<code>AlignmentResult</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Result for a single evaluated record.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.EvaluationRequest","title":"<code>EvaluationRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request to run LLM evaluation on a dataset.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.EvaluationResponse","title":"<code>EvaluationResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response from running LLM evaluation.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.MetricsRequest","title":"<code>MetricsRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request to calculate alignment metrics.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.MetricsResponse","title":"<code>MetricsResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response with computed alignment metrics.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.MisalignmentPattern","title":"<code>MisalignmentPattern</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A pattern identified in misaligned cases.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.MisalignmentAnalysis","title":"<code>MisalignmentAnalysis</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Analysis of misalignment patterns.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.MisalignmentAnalysisRequest","title":"<code>MisalignmentAnalysisRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request to analyze misalignment patterns.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.MisalignmentAnalysisResponse","title":"<code>MisalignmentAnalysisResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response with misalignment analysis.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.PromptSuggestion","title":"<code>PromptSuggestion</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A suggested improvement to the judge prompt.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.OptimizedPrompt","title":"<code>OptimizedPrompt</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Optimized prompt with suggestions.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.OptimizePromptRequest","title":"<code>OptimizePromptRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request to optimize the judge prompt.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.OptimizePromptResponse","title":"<code>OptimizePromptResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response with optimized prompt.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.ExampleSelectionStrategy","title":"<code>ExampleSelectionStrategy</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Strategy for selecting few-shot examples.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.SuggestExamplesRequest","title":"<code>SuggestExamplesRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request to suggest few-shot examples.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.SuggestExamplesResponse","title":"<code>SuggestExamplesResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response with suggested few-shot examples.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.ModelInfo","title":"<code>ModelInfo</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Information about an available LLM model.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.ModelsResponse","title":"<code>ModelsResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response with available models.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.SavedConfig","title":"<code>SavedConfig</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A saved judge configuration.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.SaveConfigRequest","title":"<code>SaveConfigRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request to save a judge configuration.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.SaveConfigResponse","title":"<code>SaveConfigResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response after saving configuration.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.ConfigsListResponse","title":"<code>ConfigsListResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response with list of saved configurations.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.ClusteringMethod","title":"<code>ClusteringMethod</code>","text":"<p>               Bases: <code>StrEnum</code></p> <p>Method for clustering annotation patterns.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.AnnotationWithNotes","title":"<code>AnnotationWithNotes</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Annotation with optional notes for Truesight pattern discovery.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.ErrorPattern","title":"<code>ErrorPattern</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>AI-clustered error pattern from annotation notes.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.LearningArtifactSchema","title":"<code>LearningArtifactSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A distilled learning artifact from the EvidencePipeline.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.PipelineResultSchema","title":"<code>PipelineResultSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Metadata from the EvidencePipeline run.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.ClusterPatternsRequest","title":"<code>ClusterPatternsRequest</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Request to cluster annotation notes into patterns.</p>"},{"location":"api-reference/backend/schemas/#app.models.align_schemas.ClusterPatternsResponse","title":"<code>ClusterPatternsResponse</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Response with clustered patterns.</p>"},{"location":"api-reference/backend/schemas/#report-schemas","title":"Report Schemas","text":""},{"location":"api-reference/backend/schemas/#app.models.report_schemas-classes","title":"Classes","text":""},{"location":"api-reference/backend/schemas/#app.models.report_schemas.InsightPatternSchema","title":"<code>InsightPatternSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>A cross-metric pattern discovered from evaluation issues.</p>"},{"location":"api-reference/backend/schemas/#app.models.report_schemas.InsightResultSchema","title":"<code>InsightResultSchema</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>Structured insight result from InsightExtractor analysis.</p>"},{"location":"api-reference/frontend/api-client/","title":"API Client","text":"<p>Hand-written reference</p> <p>This page is manually maintained. See <code>frontend/src/lib/api.ts</code> for the definitive source.</p> <p>The API client provides typed functions for all backend endpoints. It is built on the browser <code>fetch</code> API with a centralized <code>fetchApi&lt;T&gt;()</code> helper.</p>"},{"location":"api-reference/frontend/api-client/#base-configuration","title":"Base Configuration","text":"<pre><code>const API_BASE_URL = process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8500';\n</code></pre>"},{"location":"api-reference/frontend/api-client/#core-helper","title":"Core Helper","text":""},{"location":"api-reference/frontend/api-client/#fetchapitendpoint-options","title":"<code>fetchApi&lt;T&gt;(endpoint, options?)</code>","text":"<p>Generic typed fetch wrapper. Prepends <code>API_BASE_URL</code>, sets <code>Content-Type: application/json</code>, and maps error responses to <code>Error</code> objects.</p> <pre><code>async function fetchApi&lt;T&gt;(endpoint: string, options?: RequestInit): Promise&lt;T&gt;\n</code></pre>"},{"location":"api-reference/frontend/api-client/#data-endpoints","title":"Data Endpoints","text":"Function Method Endpoint Description <code>uploadFile(file)</code> POST <code>/api/data/upload</code> Upload a CSV file (multipart/form-data) <code>loadExampleDataset(name)</code> GET <code>/api/data/example/{name}</code> Load a built-in example dataset <code>getEvalDBConfig()</code> GET <code>/api/data/eval-db-config</code> Get eval database configuration <code>autoImportEvalFromDB()</code> POST <code>/api/data/eval-db-import</code> Auto-import from configured eval DB"},{"location":"api-reference/frontend/api-client/#analytics-endpoints","title":"Analytics Endpoints","text":"Function Method Endpoint Description <code>getSummaryStats(data)</code> POST <code>/api/analytics/summary</code> Compute metric summaries <code>getDistribution(data, metric, bins?)</code> POST <code>/api/analytics/distribution</code> Score distribution + histogram <code>getComparison(data, groupBy, metrics?)</code> POST <code>/api/analytics/comparison</code> Group-by comparison <code>getCorrelation(data, metrics?)</code> POST <code>/api/analytics/correlation</code> Correlation matrix <code>getRadarData(data, metrics, groupBy?)</code> POST <code>/api/analytics/radar</code> Radar chart traces <code>getScatterData(data, x, y, colorBy?)</code> POST <code>/api/analytics/scatter</code> Scatter plot data"},{"location":"api-reference/frontend/api-client/#ai-endpoints","title":"AI Endpoints","text":"Function Method Endpoint Description <code>chat(messages, dataContext?)</code> POST <code>/api/ai/chat</code> AI copilot chat <code>analyzeData(data, focus?)</code> POST <code>/api/ai/analyze</code> Automated data analysis <code>getAIStatus()</code> GET <code>/api/ai/status</code> AI service status"},{"location":"api-reference/frontend/api-client/#store-endpoints-duckdb-analytics","title":"Store Endpoints (DuckDB Analytics)","text":"Function Method Endpoint Description <code>syncStore(dataset?)</code> POST <code>/api/store/sync</code> Sync all or single dataset. <code>?full=true</code> forces rebuild <code>syncStoreDataset(dataset)</code> POST <code>/api/store/sync/{dataset}</code> Sync a single dataset <code>resetStoreWatermark(dataset)</code> POST <code>/api/store/sync/{dataset}/reset-watermark</code> Clear watermarks for next full rebuild <code>getStoreStatus()</code> GET <code>/api/store/status</code> Per-table sync status, watermarks, refresh intervals <code>getStoreMetadata(dataset)</code> GET <code>/api/store/metadata/{dataset}</code> Columns, time range, filter values, summary stats <code>getStoreData(dataset, params?)</code> GET <code>/api/store/data/{dataset}</code> Paginated data with filters, sorting, search"},{"location":"api-reference/frontend/api-client/#monitoring-endpoints","title":"Monitoring Endpoints","text":"Function Method Endpoint Description <code>uploadMonitoringFile(file)</code> POST <code>/api/monitoring/upload</code> Upload monitoring CSV <code>loadMonitoringExampleDataset(name)</code> GET <code>/api/monitoring/example/{name}</code> Load example monitoring data <code>getMonitoringDBConfig()</code> GET <code>/api/monitoring/db-config</code> Get monitoring DB config <code>autoImportMonitoringFromDB()</code> POST <code>/api/monitoring/db-import</code> Auto-import from monitoring DB"},{"location":"api-reference/frontend/api-client/#monitoring-analytics-endpoints","title":"Monitoring Analytics Endpoints","text":"Function Method Endpoint Description <code>getMonitoringSummary(filters?)</code> GET <code>/api/monitoring/analytics/summary</code> Lightweight KPIs (total, avg score, pass rate, latency) <code>getMonitoringTrends(filters?, metrics?, granularity?)</code> GET <code>/api/monitoring/analytics/trends</code> Time-series trends <code>getMonitoringLatencyDist(filters?, bins?, groupBy?)</code> GET <code>/api/monitoring/analytics/latency-distribution</code> Latency histogram <code>getMonitoringClassDist(filters?, metric?, groupBy?)</code> GET <code>/api/monitoring/analytics/class-distribution</code> Class-level distributions <code>getMonitoringMetricBreakdown(filters?, metrics?, groupBy?, threshold?)</code> GET <code>/api/monitoring/analytics/metric-breakdown</code> Pass/fail breakdown <code>getMonitoringCorrelation(filters?, metrics?)</code> GET <code>/api/monitoring/analytics/correlation</code> Metric correlation matrix <code>getClassificationBreakdown(filters?, metric?, groupBy?)</code> GET <code>/api/monitoring/analytics/classification-breakdown</code> Classification counts <code>getClassificationTrends(filters?, metric?, granularity?)</code> GET <code>/api/monitoring/analytics/classification-trends</code> Classification over time <code>getAnalysisInsights(filters?, page?, pageSize?)</code> GET <code>/api/monitoring/analytics/analysis-insights</code> Paginated ANALYSIS metric records"},{"location":"api-reference/frontend/api-client/#human-signals-endpoints","title":"Human Signals Endpoints","text":"Function Method Endpoint Description <code>uploadHumanSignalsFile(file)</code> POST <code>/api/human-signals/upload</code> Upload human signals CSV <code>loadHumanSignalsExampleDataset(name)</code> GET <code>/api/human-signals/example/{name}</code> Load example human signals data <code>getHumanSignalsDBConfig()</code> GET <code>/api/human-signals/db-config</code> Get human signals DB config <code>autoImportHumanSignalsFromDB()</code> POST <code>/api/human-signals/db-import</code> Auto-import from human signals DB"},{"location":"api-reference/frontend/api-client/#memory-endpoints","title":"Memory Endpoints","text":"Function Method Endpoint Description <code>uploadMemoryFile(file)</code> POST <code>/api/memory/upload</code> Upload memory rules CSV <code>updateMemoryRule(id, updates)</code> PUT <code>/api/memory/rules/{id}</code> Update a memory rule <code>createMemoryRule(data)</code> POST <code>/api/memory/rules</code> Create a new rule <code>deleteMemoryRule(id)</code> DELETE <code>/api/memory/rules/{id}</code> Delete a rule"},{"location":"api-reference/frontend/api-client/#knowledge-graph-endpoints","title":"Knowledge Graph Endpoints","text":"Function Method Endpoint Description <code>getMemoryGraph(filters?)</code> GET <code>/api/memory/graph</code> Get graph nodes and edges <code>getMemoryGraphSummary()</code> GET <code>/api/memory/graph/summary</code> Graph statistics <code>searchMemoryGraph(query)</code> GET <code>/api/memory/graph/search</code> Search graph nodes <code>getMemoryGraphNeighborhood(nodeId, depth?)</code> GET <code>/api/memory/graph/neighborhood</code> Node neighborhood"},{"location":"api-reference/frontend/api-client/#database-endpoints","title":"Database Endpoints","text":"Function Method Endpoint Description <code>databaseGetDefaults()</code> GET <code>/api/database/defaults</code> Get server-side DB defaults <code>databaseConnect(conn)</code> POST <code>/api/database/connect</code> Connect and get handle <code>databaseListTables(handle)</code> GET <code>/api/database/{handle}/tables</code> List tables <code>databaseGetSchema(handle, table)</code> GET <code>/api/database/{handle}/schema</code> Get table schema <code>databaseGetDistinctValues(handle, table, column)</code> POST <code>/api/database/{handle}/distinct-values</code> Distinct column values <code>databasePreview(handle, table, mappings, filters?)</code> POST <code>/api/database/{handle}/preview</code> Preview mapped data <code>databaseImport(request)</code> POST <code>/api/database/{handle}/import</code> Import data"},{"location":"api-reference/frontend/api-client/#eval-runner-endpoints","title":"Eval Runner Endpoints","text":"Function Method Endpoint Description <code>evalRunnerGetMetrics()</code> GET <code>/api/eval-runner/metrics</code> Available evaluation metrics <code>evalRunnerUploadDataset(file)</code> POST <code>/api/eval-runner/upload</code> Upload dataset for evaluation <code>evalRunnerTestConnection(config, query?)</code> POST <code>/api/eval-runner/test-connection</code> Test agent connection <code>evalRunnerRun(...)</code> POST <code>/api/eval-runner/run</code> Run evaluation (sync) <code>evalRunnerRunStream(...)</code> POST <code>/api/eval-runner/run/stream</code> Run evaluation (SSE stream)"},{"location":"api-reference/frontend/api-client/#align-endpoints","title":"Align Endpoints","text":"Function Method Endpoint Description <code>alignEvaluate(records, annotations, config, cols?)</code> POST <code>/api/align/evaluate</code> Run alignment evaluation <code>alignAnalyzeMisalignment(results, config)</code> POST <code>/api/align/analyze-misalignment</code> Analyze misalignment <code>alignOptimizePrompt(results, config)</code> POST <code>/api/align/optimize-prompt</code> Optimize judge prompt <code>alignSuggestExamples(records, annotations, strategy?, count?)</code> POST <code>/api/align/suggest-examples</code> Suggest calibration examples <code>alignGetModels()</code> GET <code>/api/align/models</code> Available LLM models <code>alignSaveConfig(name, config, metrics?)</code> POST <code>/api/align/save-config</code> Save judge config <code>alignGetConfigs()</code> GET <code>/api/align/configs</code> List saved configs <code>alignDeleteConfig(id)</code> DELETE <code>/api/align/configs/{id}</code> Delete a config <code>alignGetDefaults()</code> GET <code>/api/align/defaults</code> Default judge settings <code>alignGetStatus()</code> GET <code>/api/align/status</code> Alignment service status <code>alignClusterPatterns(annotations, config?, method?, domainContext?)</code> POST <code>/api/align/cluster-patterns</code> Discover error patterns and learning insights via EvidencePipeline. Optional <code>domainContext</code> string provides domain-aware analysis"},{"location":"api-reference/frontend/api-client/#report-endpoints","title":"Report Endpoints","text":"Function Method Endpoint Description <code>generateReport(request)</code> POST <code>/api/reports/generate</code> Generate evaluation report (non-streaming). Response includes optional <code>insights</code> field <code>createReportStream(request, handlers)</code> POST <code>/api/reports/generate/stream</code> Stream report generation via SSE. Handlers: <code>onThought</code>, <code>onInsights</code>, <code>onResponse</code>, <code>onError</code>, <code>onDone</code> <code>extractIssuesPreview(request)</code> POST <code>/api/reports/extract-issues</code> Preview extracted issues <code>getReportStatus()</code> GET <code>/api/reports/status</code> Report service status <p>The <code>createReportStream</code> function returns an <code>AbortController</code> for cancellation. The <code>onInsights</code> handler receives an <code>InsightResult</code> object with structured cross-metric patterns and learning artifacts.</p>"},{"location":"api-reference/frontend/hooks/","title":"React Query Hooks","text":"<p>Hand-written reference</p> <p>This page is manually maintained. See <code>frontend/src/lib/hooks.ts</code> and <code>frontend/src/lib/hooks/</code> for the definitive source.</p> <p>AXIS uses TanStack React Query for server state management. Hooks wrap the API client functions, providing automatic caching, refetching, and loading/error states.</p>"},{"location":"api-reference/frontend/hooks/#pattern","title":"Pattern","text":"<p>All hooks follow the same pattern:</p> <pre><code>// Query hook \u2014 auto-fetches when dependencies are available\nexport function useSummaryStats(data: EvaluationRecord[] | null) {\n  return useQuery({\n    queryKey: ['summaryStats', data?.length],\n    queryFn: () =&gt; getSummaryStats(data!),\n    enabled: !!data &amp;&amp; data.length &gt; 0,\n  });\n}\n\n// Mutation hook \u2014 triggered explicitly\nexport function useUploadFile() {\n  return useMutation({\n    mutationFn: (file: File) =&gt; uploadFile(file),\n    onSuccess: (response) =&gt; {\n      useDataStore.getState().setData(response.data, response.format);\n    },\n  });\n}\n</code></pre>"},{"location":"api-reference/frontend/hooks/#data-hooks","title":"Data Hooks","text":"Hook Type Wraps Description <code>useUploadFile()</code> Mutation <code>uploadFile</code> Upload CSV and store results <code>useLoadExampleDataset()</code> Mutation <code>loadExampleDataset</code> Load example data <code>useSummaryStats(data)</code> Query <code>getSummaryStats</code> Compute summary statistics"},{"location":"api-reference/frontend/hooks/#analytics-hooks","title":"Analytics Hooks","text":"Hook Type Wraps Description <code>useDistribution(data, metric, bins)</code> Query <code>getDistribution</code> Score distribution <code>useComparison(data, groupBy, metrics)</code> Query <code>getComparison</code> Group comparison <code>useCorrelation(data, metrics)</code> Query <code>getCorrelation</code> Correlation matrix <code>useRadarData(data, metrics, groupBy)</code> Query <code>getRadarData</code> Radar chart <code>useScatterData(data, x, y, colorBy)</code> Query <code>getScatterData</code> Scatter plot"},{"location":"api-reference/frontend/hooks/#monitoring-hooks","title":"Monitoring Hooks","text":"Hook Type Wraps Description <code>useUploadMonitoringFile()</code> Mutation <code>uploadMonitoringFile</code> Upload monitoring CSV <code>useMonitoringTrends(data, metrics, gran)</code> Query <code>getMonitoringTrends</code> Time-series trends <code>useMonitoringLatencyDist(data, bins, groupBy)</code> Query <code>getMonitoringLatencyDist</code> Latency histogram <code>useMonitoringMetricBreakdown(data, metrics, groupBy)</code> Query <code>getMonitoringMetricBreakdown</code> Pass/fail breakdown <code>useMonitoringCorrelation(data, metrics)</code> Query <code>getMonitoringCorrelation</code> Metric correlations"},{"location":"api-reference/frontend/hooks/#human-signals-hooks","title":"Human Signals Hooks","text":"Hook Type Wraps Description <code>useUploadHumanSignalsFile()</code> Mutation <code>uploadHumanSignalsFile</code> Upload human signals CSV <code>useLoadHumanSignalsExample()</code> Mutation <code>loadHumanSignalsExampleDataset</code> Load example human signals data"},{"location":"api-reference/frontend/hooks/#memory-hooks","title":"Memory Hooks","text":"Hook Type Wraps Description <code>useUploadMemoryFile()</code> Mutation <code>uploadMemoryFile</code> Upload memory rules CSV <code>useUpdateMemoryRule()</code> Mutation <code>updateMemoryRule</code> Update a rule <code>useCreateMemoryRule()</code> Mutation <code>createMemoryRule</code> Create a new rule <code>useDeleteMemoryRule()</code> Mutation <code>deleteMemoryRule</code> Delete a rule"},{"location":"api-reference/frontend/hooks/#calibration-align-hooks","title":"Calibration (Align) Hooks","text":"Hook Type Wraps Description <code>useAlignEvaluate()</code> Mutation <code>alignEvaluate</code> Run alignment evaluation <code>useAlignAnalyzeMisalignment()</code> Mutation <code>alignAnalyzeMisalignment</code> Analyze misalignment patterns <code>useAlignOptimizePrompt()</code> Mutation <code>alignOptimizePrompt</code> Generate optimized judge prompt <code>useAlignSuggestExamples()</code> Mutation <code>alignSuggestExamples</code> Suggest few-shot calibration examples <code>useClusterPatterns()</code> Mutation <code>alignClusterPatterns</code> Discover error patterns and learning insights via EvidencePipeline. Returns <code>patterns</code>, <code>learnings</code>, and <code>pipeline_metadata</code> <code>useAlignGetModels()</code> Query <code>alignGetModels</code> List available LLM models <code>useAlignGetConfigs()</code> Query <code>alignGetConfigs</code> List saved judge configurations <code>useAlignGetDefaults()</code> Query <code>alignGetDefaults</code> Get default judge settings <code>useAlignGetStatus()</code> Query <code>alignGetStatus</code> Alignment service status"},{"location":"api-reference/frontend/hooks/#report-hooks","title":"Report Hooks","text":"Hook Type Description <code>useReportStream()</code> Custom Manages SSE-based report generation. Returns <code>{ report, thoughts, insights, isGenerating, error, generate, cancel }</code>. The <code>insights</code> field (<code>InsightResult \\| null</code>) contains structured patterns discovered during generation <code>useReportStatus()</code> Query Check report service status"},{"location":"api-reference/frontend/hooks/#usage","title":"Usage","text":""},{"location":"api-reference/frontend/hooks/#in-components","title":"In Components","text":"<pre><code>'use client';\n\nimport { useDistribution } from '@/lib/hooks';\nimport { useDataStore } from '@/stores';\n\nexport function DistributionChart({ metric }: { metric: string }) {\n  const { data } = useDataStore();\n  const { data: dist, isLoading, error } = useDistribution(data, metric);\n\n  if (isLoading) return &lt;Spinner /&gt;;\n  if (error) return &lt;ErrorMessage error={error} /&gt;;\n  if (!dist) return null;\n\n  return &lt;PlotlyChart data={[{ type: 'violin', y: dist.values }]} /&gt;;\n}\n</code></pre>"},{"location":"api-reference/frontend/hooks/#query-keys","title":"Query Keys","text":"<p>Query hooks use structured keys for cache invalidation:</p> <pre><code>['summaryStats', dataLength]\n['distribution', metric, bins, dataLength]\n['comparison', groupBy, metrics, dataLength]\n['monitoringTrends', metrics, granularity, dataLength]\n</code></pre>"},{"location":"api-reference/frontend/hooks/#enabled-conditions","title":"Enabled Conditions","text":"<p>All query hooks include <code>enabled</code> guards to prevent fetching with <code>null</code> or empty data:</p> <pre><code>enabled: !!data &amp;&amp; data.length &gt; 0\n</code></pre>"},{"location":"api-reference/frontend/stores/","title":"Zustand Stores","text":"<p>Hand-written reference</p> <p>This page is manually maintained. See <code>frontend/src/stores/</code> for the definitive source.</p> <p>All stores are barrel-exported from <code>@/stores</code>:</p> <pre><code>import { useUIStore, useDataStore, useMonitoringStore } from '@/stores';\n</code></pre>"},{"location":"api-reference/frontend/stores/#store-list","title":"Store List","text":"Store File Description <code>useUIStore</code> <code>ui-store.ts</code> UI preferences, filters, modal state <code>useDataStore</code> <code>data-store.ts</code> Evaluation data from uploads <code>useMonitoringStore</code> <code>monitoring-store.ts</code> Monitoring/observability data <code>useMemoryStore</code> <code>memory-store.ts</code> Decision memory rules and batches <code>useHumanSignalsStore</code> <code>human-signals-store.ts</code> Human signals data <code>useAnnotationStore</code> <code>annotation-store.ts</code> Human annotation state <code>useCalibrationStore</code> <code>calibration-store.ts</code> LLM judge calibration, pattern discovery, learning insights <code>useCopilotStore</code> <code>copilot-store.ts</code> AI copilot chat state <code>useDatabaseStore</code> <code>database-store.ts</code> DB connection wizard state <code>useEvalRunnerStore</code> <code>eval-runner-store.ts</code> Evaluation runner workflow <code>useThemeStore</code> <code>theme-store.ts</code> Theme/branding configuration"},{"location":"api-reference/frontend/stores/#useuistore","title":"useUIStore","text":"<p>Manages global UI preferences. Uses <code>persist</code> middleware for localStorage persistence.</p> <p>Key State:</p> Field Type Description <code>sidebarCollapsed</code> <code>boolean</code> Sidebar open/closed <code>copilotOpen</code> <code>boolean</code> AI copilot panel visibility <code>selectedExperiment</code> <code>string \\| null</code> Active experiment filter <code>selectedExperiments</code> <code>string[]</code> Experiments for comparison <code>selectedMetrics</code> <code>string[]</code> Active metric filters <code>currentPage</code> <code>number</code> Current pagination page <code>itemsPerPage</code> <code>number</code> Items per page <code>viewMode</code> <code>'list' \\| 'grid'</code> Data view mode <code>visualizeSubTab</code> <code>string</code> Active visualize sub-tab"},{"location":"api-reference/frontend/stores/#usedatastore","title":"useDataStore","text":"<p>Manages evaluation data loaded from CSV uploads or DB imports.</p> <p>Key State:</p> Field Type Description <code>data</code> <code>EvaluationRecord[]</code> Raw evaluation records <code>format</code> <code>DataFormat \\| null</code> Detected data format <code>columns</code> <code>string[]</code> Column names <code>metricColumns</code> <code>string[]</code> Metric column names <code>summary</code> <code>MetricSummary[]</code> Computed metric summaries <code>isLoading</code> <code>boolean</code> Loading state <code>error</code> <code>string \\| null</code> Error message <p>Key Actions:</p> <ul> <li><code>setData(data, format)</code> \u2014 Store uploaded data</li> <li><code>clearData()</code> \u2014 Reset to empty state</li> </ul>"},{"location":"api-reference/frontend/stores/#usemonitoringstore","title":"useMonitoringStore","text":"<p>Manages production monitoring data with time-series filtering and source metadata.</p> <p>Key State:</p> Field Type Description <code>data</code> <code>MonitoringRecord[]</code> Raw monitoring records <code>metricColumns</code> <code>string[]</code> Detected metric columns <code>timeRange</code> <code>MonitoringTimeRange</code> Active time filter <code>selectedEnvironment</code> <code>string \\| null</code> Environment filter <code>selectedSourceName</code> <code>string \\| null</code> Source name filter <code>selectedSourceComponent</code> <code>string \\| null</code> Component filter <code>selectedSourceType</code> <code>string \\| null</code> Source type filter <code>availableEnvironments</code> <code>string[]</code> Unique environments in data <code>availableSourceNames</code> <code>string[]</code> Unique source names"},{"location":"api-reference/frontend/stores/#usememorystore","title":"useMemoryStore","text":"<p>Manages decision memory rules, hard stops, batches, and decision quality data.</p> <p>Key State:</p> Field Type Description <code>rules</code> <code>MemoryRuleRecord[]</code> All memory rules <code>activeTab</code> <code>string</code> Active tab (rules, hardstops, batches, quality, graph) <code>searchQuery</code> <code>string</code> Rule search filter <code>selectedCategory</code> <code>string \\| null</code> Category filter"},{"location":"api-reference/frontend/stores/#usehumansignalsstore","title":"useHumanSignalsStore","text":"<p>Manages Human Signals data with source and metric filtering.</p> <p>Key State:</p> Field Type Description <code>data</code> <code>Record&lt;string, unknown&gt;[]</code> Flattened signal records <code>metricSchema</code> <code>SignalsMetricSchema \\| null</code> Schema describing available metrics <code>displayConfig</code> <code>SignalsDisplayConfig \\| null</code> Display overrides from YAML <code>selectedSource</code> <code>string \\| null</code> Source filter <code>selectedMetric</code> <code>string \\| null</code> Metric filter <code>timeRange</code> <code>SignalsTimeRange</code> Time range filter"},{"location":"api-reference/frontend/stores/#usecalibrationstore","title":"useCalibrationStore","text":"<p>Manages LLM judge calibration state including evaluation results, pattern discovery, and learning insights from the EvidencePipeline.</p> <p>Key State:</p> Field Type Description <code>step</code> <code>number</code> Current workflow step (0-2) <code>evaluationResults</code> <code>AlignEvaluationResult[] \\| null</code> Judge evaluation results <code>clusterPatterns</code> <code>ClusterPattern[] \\| null</code> Discovered error patterns <code>learningArtifacts</code> <code>LearningArtifact[] \\| null</code> Actionable learning insights from EvidencePipeline <code>pipelineMetadata</code> <code>PipelineMetadata \\| null</code> Metadata about the clustering pipeline run <code>domainContext</code> <code>string</code> Optional domain context for pattern discovery <code>selectedProvider</code> <code>string</code> Active LLM provider <code>selectedModel</code> <code>string</code> Active LLM model"},{"location":"api-reference/frontend/stores/#pattern","title":"Pattern","text":"<p>All stores follow the Zustand <code>create&lt;State&gt;()((set) =&gt; ({...}))</code> pattern:</p> <pre><code>import { create } from 'zustand';\n\ninterface ExampleState {\n  count: number;\n  increment: () =&gt; void;\n  reset: () =&gt; void;\n}\n\nexport const useExampleStore = create&lt;ExampleState&gt;()((set) =&gt; ({\n  count: 0,\n  increment: () =&gt; set((state) =&gt; ({ count: state.count + 1 })),\n  reset: () =&gt; set({ count: 0 }),\n}));\n</code></pre> <p>For persisted stores (e.g., <code>useUIStore</code>):</p> <pre><code>import { create } from 'zustand';\nimport { persist } from 'zustand/middleware';\n\nexport const useUIStore = create&lt;UIState&gt;()(\n  persist(\n    (set) =&gt; ({\n      // ...state and actions\n    }),\n    {\n      name: 'axis-ui-store',\n      partialize: (state) =&gt; ({\n        sidebarCollapsed: state.sidebarCollapsed,\n        // only persist selected fields\n      }),\n    }\n  )\n);\n</code></pre>"},{"location":"api-reference/frontend/types/","title":"TypeScript Types","text":"<p>Hand-written reference</p> <p>This page is manually maintained. See <code>frontend/src/types/index.ts</code> for the definitive source.</p> <p>All types are defined in a single file and imported via <code>@/types</code>.</p>"},{"location":"api-reference/frontend/types/#constants","title":"Constants","text":""},{"location":"api-reference/frontend/types/#columns","title":"Columns","text":"<p>Column name constants shared with the Python backend:</p> <pre><code>export const Columns = {\n  ID: 'id',\n  EXPERIMENT_NAME: 'evaluation_name',\n  QUERY: 'query',\n  ACTUAL_OUTPUT: 'actual_output',\n  EXPECTED_OUTPUT: 'expected_output',\n  METRIC_NAME: 'metric_name',\n  METRIC_SCORE: 'metric_score',\n  WEIGHT: 'weight',\n  METRIC_TYPE: 'metric_type',\n  PARENT: 'parent',\n} as const;\n</code></pre>"},{"location":"api-reference/frontend/types/#thresholds","title":"Thresholds","text":"<p>Score thresholds for pass/fail and color coding:</p> <pre><code>export const Thresholds = {\n  PASSING_RATE: 0.5,\n  GREEN_THRESHOLD: 0.7,\n  RED_THRESHOLD: 0.3,\n} as const;\n</code></pre>"},{"location":"api-reference/frontend/types/#uiconfig","title":"UIConfig","text":"<pre><code>export const UIConfig = {\n  ITEMS_PER_PAGE: 3,\n  CONTENT_TRUNC_LENGTH: 200,\n} as const;\n</code></pre>"},{"location":"api-reference/frontend/types/#chartcolors","title":"ChartColors","text":"<p>Color palette for multi-series charts:</p> <pre><code>export const ChartColors = [\n  '#8B9F4F', '#A4B86C', '#6B7A3A', '#B8C78A',\n  '#D4AF37', '#B8C5D3', '#D4E0B8', '#1f77b4',\n  '#ff7f0e', '#2ca02c',\n];\n</code></pre>"},{"location":"api-reference/frontend/types/#evaluation-types","title":"Evaluation Types","text":""},{"location":"api-reference/frontend/types/#dataformat","title":"DataFormat","text":"<pre><code>type DataFormat =\n  | 'tree_format'\n  | 'flat_format'\n  | 'simple_judgment'\n  | 'fresh_annotation'\n  | 'unknown';\n</code></pre>"},{"location":"api-reference/frontend/types/#evaluationrecord","title":"EvaluationRecord","text":"<p>Core record type for evaluation data. Varies by format but always has ID, query, and output:</p> <pre><code>interface EvaluationRecord {\n  [Columns.ID]: string;\n  [Columns.QUERY]: string;\n  [Columns.ACTUAL_OUTPUT]: string;\n  [key: string]: unknown;\n}\n</code></pre>"},{"location":"api-reference/frontend/types/#metricsummary","title":"MetricSummary","text":"<pre><code>interface MetricSummary {\n  metric: string;\n  count: number;\n  mean: number;\n  std: number;\n  min: number;\n  max: number;\n  median: number;\n  pass_rate: number;\n}\n</code></pre>"},{"location":"api-reference/frontend/types/#comparisonrow","title":"ComparisonRow","text":"<p>Used in the Compare view for side-by-side model comparison:</p> <pre><code>interface ComparisonRow {\n  id: string;\n  query: string;\n  actualOutput: string;\n  experimentName?: string;\n  metrics: Record&lt;string, number&gt;;\n  overallScore: number;\n  metadata?: Record&lt;string, unknown&gt;;\n}\n</code></pre>"},{"location":"api-reference/frontend/types/#monitoring-types","title":"Monitoring Types","text":""},{"location":"api-reference/frontend/types/#monitoringrecord","title":"MonitoringRecord","text":"<p>Supports both long format (metric_name + metric_score) and wide format (dynamic <code>*_score</code> columns):</p> <pre><code>interface MonitoringRecord {\n  dataset_id: string;\n  timestamp: string;\n  query?: string;\n  actual_output?: string;\n\n  // Long format\n  metric_name?: string;\n  metric_score?: number;\n  metric_type?: string;\n  metric_category?: MetricCategory;\n\n  // Source metadata\n  environment?: string;\n  source_name?: string;\n  source_component?: string;\n  source_type?: string;\n\n  // Observability\n  trace_id?: string;\n  latency?: number;\n\n  // Wide format: dynamic columns\n  [metricName: string]: unknown;\n}\n</code></pre>"},{"location":"api-reference/frontend/types/#metriccategory","title":"MetricCategory","text":"<pre><code>type MetricCategory = 'SCORE' | 'ANALYSIS' | 'CLASSIFICATION';\n</code></pre> Category Description Example <code>SCORE</code> Numeric value (0-1) for charts and thresholds <code>0.85</code> <code>ANALYSIS</code> Structured insights/reasoning (JSON) <code>{\"issues\": [...]}</code> <code>CLASSIFICATION</code> Categorical label for breakdowns <code>\"POSITIVE\"</code>"},{"location":"api-reference/frontend/types/#monitoringgroupby","title":"MonitoringGroupBy","text":"<pre><code>type MonitoringGroupBy =\n  | 'environment'\n  | 'source_name'\n  | 'source_component'\n  | 'source_type'\n  | 'evaluation_name'\n  | null;\n</code></pre>"},{"location":"api-reference/frontend/types/#signals-types","title":"Signals Types","text":""},{"location":"api-reference/frontend/types/#signalsmetricschema","title":"SignalsMetricSchema","text":"<p>Describes the metrics available in a signals dataset (V2 format):</p> <pre><code>interface SignalsMetricSchema {\n  [metricName: string]: {\n    signals: string[];\n    signal_types: Record&lt;string, string&gt;;\n  };\n}\n</code></pre>"},{"location":"api-reference/frontend/types/#signalsdisplayconfig","title":"SignalsDisplayConfig","text":"<p>Display overrides from <code>custom/config/signals_metrics.yaml</code>:</p> <pre><code>interface SignalsDisplayConfig {\n  [metricName: string]: {\n    label?: string;\n    description?: string;\n    chart_type?: string;\n    signals?: Record&lt;string, { label?: string; format?: string }&gt;;\n  };\n}\n</code></pre>"},{"location":"api-reference/frontend/types/#memory-types","title":"Memory Types","text":""},{"location":"api-reference/frontend/types/#memoryrulerecord","title":"MemoryRuleRecord","text":"<pre><code>interface MemoryRuleRecord {\n  rule_id: string;\n  rule_text: string;\n  category: string;\n  severity: string;\n  batch_id: string;\n  is_hard_stop: boolean;\n  confidence: number;\n  source_context?: string;\n  created_at?: string;\n}\n</code></pre>"},{"location":"api-reference/frontend/types/#graph-types","title":"Graph Types","text":""},{"location":"api-reference/frontend/types/#graphnode-graphedge-graphdata","title":"GraphNode / GraphEdge / GraphData","text":"<pre><code>interface GraphNode {\n  id: string;\n  label: string;\n  type: string;\n  properties: Record&lt;string, unknown&gt;;\n}\n\ninterface GraphEdge {\n  source: string;\n  target: string;\n  relation: string;\n  properties: Record&lt;string, unknown&gt;;\n}\n\ninterface GraphData {\n  nodes: GraphNode[];\n  edges: GraphEdge[];\n}\n</code></pre>"},{"location":"api-reference/frontend/types/#calibration-align-types","title":"Calibration (Align) Types","text":""},{"location":"api-reference/frontend/types/#learningartifact","title":"LearningArtifact","text":"<p>Actionable learning insight produced by the EvidencePipeline during pattern clustering:</p> <pre><code>interface LearningArtifact {\n  insight: string;\n  recommended_action: string;\n  supporting_evidence: string[];\n  counterexamples: string[];\n  confidence: number;\n  scope: string;\n  metadata: Record&lt;string, unknown&gt;;\n}\n</code></pre>"},{"location":"api-reference/frontend/types/#pipelinemetadata","title":"PipelineMetadata","text":"<p>Metadata about the pattern discovery pipeline execution:</p> <pre><code>interface PipelineMetadata {\n  clustering_method: string;\n  num_clusters: number;\n  total_annotations: number;\n  silhouette_score: number | null;\n  processing_time_seconds: number | null;\n}\n</code></pre>"},{"location":"api-reference/frontend/types/#report-insight-types","title":"Report Insight Types","text":""},{"location":"api-reference/frontend/types/#insightpattern","title":"InsightPattern","text":"<p>A structured cross-metric pattern discovered by the InsightExtractor:</p> <pre><code>interface InsightPattern {\n  category: string;\n  description: string;\n  count: number;\n  issue_ids: string[];\n  metrics_involved: string[];\n  is_cross_metric: boolean;\n  distinct_test_cases: number;\n  examples: string[];\n  confidence: number | null;\n}\n</code></pre> Field Description <code>category</code> Pattern category name (e.g., \"Hallucination\", \"Context Gaps\") <code>is_cross_metric</code> Whether this pattern spans multiple metrics <code>confidence</code> Confidence score (0-1), or <code>null</code> if not computed <code>distinct_test_cases</code> Number of unique test cases exhibiting this pattern <code>metrics_involved</code> Which evaluation metrics this pattern affects"},{"location":"api-reference/frontend/types/#insightresult","title":"InsightResult","text":"<p>Container for all insights from a report generation run:</p> <pre><code>interface InsightResult {\n  patterns: InsightPattern[];\n  learnings: LearningArtifact[];\n  total_issues_analyzed: number;\n  pipeline_metadata: PipelineMetadata | null;\n}\n</code></pre>"},{"location":"api-reference/frontend/types/#reportresponse","title":"ReportResponse","text":"<p>Response from the report generation endpoint:</p> <pre><code>interface ReportResponse {\n  success: boolean;\n  report_text: string;\n  issues_analyzed: number;\n  metrics_covered: string[];\n  insights?: InsightResult | null;\n}\n</code></pre>"},{"location":"api-reference/frontend/types/#sseeventtype","title":"SSEEventType","text":"<p>Event types used in Server-Sent Event streams:</p> <pre><code>type SSEEventType = 'thought' | 'response' | 'insights' | 'error' | 'done' | 'ping';\n</code></pre>"},{"location":"api-reference/frontend/types/#theme-types","title":"Theme Types","text":""},{"location":"api-reference/frontend/types/#themeconfigresponse","title":"ThemeConfigResponse","text":"<pre><code>interface ThemeConfigResponse {\n  active: string;\n  palettes: Record&lt;string, ThemePalette&gt;;\n  hero: ThemeHero;\n  branding: ThemeBranding;\n}\n</code></pre>"},{"location":"architecture/","title":"Architecture Overview","text":"<p>AXIS uses a split architecture with a Next.js 14 frontend and a FastAPI backend communicating over HTTP REST APIs. Both services run independently and can be deployed together or separately.</p>"},{"location":"architecture/#system-diagram","title":"System Diagram","text":"<pre><code>graph TB\n    subgraph Frontend [\"Frontend (Next.js 14 -- port 3500)\"]\n        A[App Router Pages] --&gt; B[React Components]\n        B --&gt; C[Zustand Stores]\n        B --&gt; D[React Query Hooks]\n        D --&gt; E[\"fetchApi&amp;lt;T&amp;gt; Client\"]\n    end\n\n    subgraph Backend [\"Backend (FastAPI -- port 8500)\"]\n        F[API Routers] --&gt; G[Services]\n        G --&gt; H[Data Processor]\n        G --&gt; I[Database Service]\n        G --&gt; J[AI / Copilot]\n        G --&gt; SE[Sync Engine]\n        SE --&gt; DUCK[(DuckDB&lt;br/&gt;Analytics Store)]\n    end\n\n    subgraph DataSources [\"Data Sources\"]\n        K[(PostgreSQL)]\n        L[(FalkorDB)]\n        M[CSV Files]\n        N[LLM APIs]\n    end\n\n    E -- \"HTTP REST /api/*\" --&gt; F\n    I --&gt; K\n    K -- \"Split sync&lt;br/&gt;(dataset + results)\" --&gt; SE\n    G --&gt; L\n    H --&gt; M\n    J --&gt; N</code></pre>"},{"location":"architecture/#tech-stack","title":"Tech Stack","text":""},{"location":"architecture/#frontend","title":"Frontend","text":"Category Technology Version Framework Next.js (App Router) 14.2 Language TypeScript 5.6 Styling Tailwind CSS 3.4 State Management Zustand 5.0 Data Fetching TanStack React Query 5.60 Charts Plotly.js / react-plotly 2.35 Graph Viz D3.js 7.9 Icons Lucide React 0.460"},{"location":"architecture/#backend","title":"Backend","text":"Category Technology Version Framework FastAPI 0.115+ Language Python 3.12+ Data Processing Pandas / NumPy Latest Schemas Pydantic / pydantic-settings 2.0+ Database SQLAlchemy + asyncpg 2.0+ Analytics Store DuckDB 1.1+ Graph DB FalkorDB (Redis protocol) Latest Linting Ruff Latest"},{"location":"architecture/#port-assignments","title":"Port Assignments","text":"Service Default Port Environment Variable Frontend 3500 (next.config.js) Backend API 8500 <code>PORT</code> in <code>.env</code> PostgreSQL 5432 <code>*_db_port</code> in <code>.env</code> FalkorDB 6379 <code>graph_db_port</code> in <code>.env</code>"},{"location":"architecture/#directory-structure","title":"Directory Structure","text":"<pre><code>axis/\n\u251c\u2500\u2500 backend/\n\u2502   \u251c\u2500\u2500 app/\n\u2502   \u2502   \u251c\u2500\u2500 main.py              # FastAPI entry point\n\u2502   \u2502   \u251c\u2500\u2500 config.py            # Settings, Columns, Thresholds, Colors\n\u2502   \u2502   \u251c\u2500\u2500 routers/             # 14 API routers\n\u2502   \u2502   \u251c\u2500\u2500 services/            # Business logic layer\n\u2502   \u2502   \u251c\u2500\u2500 models/              # Pydantic schemas\n\u2502   \u2502   \u2514\u2500\u2500 copilot/             # AI copilot agent + skills\n\u2502   \u251c\u2500\u2500 config/                  # YAML config files (.example templates tracked)\n\u2502   \u2502   \u251c\u2500\u2500 human_signals_db.yaml # Human Signals DB: split queries, incremental sync\n\u2502   \u2502   \u251c\u2500\u2500 monitoring_db.yaml   # Monitoring DB: split queries, incremental sync\n\u2502   \u2502   \u251c\u2500\u2500 eval_db.yaml         # Eval DB: split queries\n\u2502   \u2502   \u251c\u2500\u2500 duckdb.yaml          # DuckDB store: sync mode, workers, concurrency\n\u2502   \u2502   \u251c\u2500\u2500 theme.yaml           # Color palettes and branding\n\u2502   \u2502   \u251c\u2500\u2500 agents.yaml          # Agent registry\n\u2502   \u2502   \u2514\u2500\u2500 signals_metrics.yaml # Signals dashboard display overrides\n\u2502   \u251c\u2500\u2500 data/                    # DuckDB database file\n\u2502   \u2502   \u2514\u2500\u2500 local_store.duckdb\n\u2502   \u2514\u2500\u2500 .env                     # Environment variables\n\u2502\n\u251c\u2500\u2500 frontend/\n\u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u251c\u2500\u2500 app/                 # Next.js App Router pages\n\u2502   \u2502   \u251c\u2500\u2500 components/          # React components (by feature)\n\u2502   \u2502   \u251c\u2500\u2500 stores/              # Zustand state stores\n\u2502   \u2502   \u251c\u2500\u2500 lib/                 # API client, hooks, utilities\n\u2502   \u2502   \u2514\u2500\u2500 types/               # TypeScript type definitions\n\u2502   \u251c\u2500\u2500 public/                  # Static assets\n\u2502   \u2514\u2500\u2500 .env.local               # Frontend environment variables\n\u2502\n\u2514\u2500\u2500 docs/                        # MkDocs documentation site\n</code></pre>"},{"location":"architecture/#request-flow","title":"Request Flow","text":"<p>A typical request flows through these layers:</p> <pre><code>sequenceDiagram\n    participant U as User Browser\n    participant F as Next.js Frontend\n    participant S as Zustand Store\n    participant RQ as React Query\n    participant API as fetchApi Client\n    participant B as FastAPI Router\n    participant SVC as Service Layer\n    participant DB as Database/File\n\n    U-&gt;&gt;F: User action (click, upload)\n    F-&gt;&gt;S: Update UI state\n    F-&gt;&gt;RQ: Trigger query/mutation\n    RQ-&gt;&gt;API: fetchApi&lt;T&gt;(endpoint)\n    API-&gt;&gt;B: HTTP request to /api/*\n    B-&gt;&gt;SVC: Call service function\n    SVC-&gt;&gt;DB: Read/write data\n    DB--&gt;&gt;SVC: Return result\n    SVC--&gt;&gt;B: Return processed data\n    B--&gt;&gt;API: JSON response\n    API--&gt;&gt;RQ: Typed response &lt;T&gt;\n    RQ--&gt;&gt;F: Update component\n    F-&gt;&gt;S: Store server data\n    F--&gt;&gt;U: Re-render UI</code></pre>"},{"location":"architecture/#communication-protocol","title":"Communication Protocol","text":"<ul> <li>Transport: HTTP/1.1 REST over JSON</li> <li>Streaming: Server-Sent Events (SSE) for AI copilot and eval runner progress</li> <li>CORS: Frontend origin explicitly allowed in backend middleware</li> <li>Authentication: None (designed for internal/local deployment)</li> <li>Error format: <code>{ \"detail\": \"error message\" }</code> with appropriate HTTP status codes</li> </ul>"},{"location":"architecture/#next-steps","title":"Next Steps","text":"<ul> <li>Backend Architecture -- routers, services, and configuration</li> <li>DuckDB Analytics Store -- embedded analytics engine and sync pipeline</li> <li>Frontend Architecture -- pages, components, and patterns</li> <li>Data Formats -- evaluation and monitoring data specs</li> <li>State Management -- Zustand stores and React Query</li> </ul>"},{"location":"architecture/backend/","title":"Backend Architecture","text":"<p>The AXIS backend is a FastAPI application following a router / service / model layered architecture. It handles data ingestion, analytics computation, database integration, AI copilot features, and report generation.</p>"},{"location":"architecture/backend/#application-entry-point","title":"Application Entry Point","text":"<p>The FastAPI app is created in <code>backend/app/main.py</code> with:</p> <ul> <li>A <code>lifespan</code> async context manager for startup/shutdown events (DuckDB init, metadata loading, human signals rebuild, periodic sync scheduler)</li> <li>CORS middleware allowing the frontend origin</li> <li>All 14 routers mounted under <code>/api/</code> prefixes</li> <li>Health check endpoints at <code>/</code> and <code>/health</code></li> <li>Background task management with graceful cancellation on shutdown</li> </ul> <pre><code># backend/app/main.py (simplified)\napp = FastAPI(title=\"AXIS API\", version=\"0.1.0\", lifespan=lifespan)\n\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"http://localhost:3500\", settings.FRONTEND_URL],\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\napp.include_router(config.router,  prefix=\"/api/config\",  tags=[\"config\"])\napp.include_router(data.router,    prefix=\"/api/data\",    tags=[\"data\"])\n# ... 12 more routers\n</code></pre>"},{"location":"architecture/backend/#router-service-model-pattern","title":"Router / Service / Model Pattern","text":"<pre><code>graph LR\n    R[Router&lt;br/&gt;API endpoints] --&gt; S[Service&lt;br/&gt;Business logic]\n    S --&gt; M[Model&lt;br/&gt;Pydantic schemas]\n    R --&gt; M</code></pre> Layer Location Responsibility Router <code>app/routers/*.py</code> HTTP endpoint definitions, request validation, error mapping Service <code>app/services/*.py</code> Business logic, data transformations, external integrations Model <code>app/models/*.py</code> Pydantic request/response schemas <p>Thin routers</p> <p>Routers should contain minimal logic. They validate input, call service functions, and map service exceptions to HTTP status codes.</p>"},{"location":"architecture/backend/#routers","title":"Routers","text":"<p>AXIS registers 14 routers in <code>main.py</code>. Each handles a distinct domain:</p> Router Prefix Purpose <code>config</code> <code>/api/config</code> Theme configuration, app settings <code>data</code> <code>/api/data</code> CSV upload, example datasets, eval DB import <code>analytics</code> <code>/api/analytics</code> Summary stats, distribution, correlation, radar, scatter <code>ai</code> <code>/api/ai</code> AI copilot chat, data analysis, status <code>align</code> <code>/api/align</code> LLM judge alignment, prompt optimization <code>reports</code> <code>/api/reports</code> Report generation, issue extraction <code>database</code> <code>/api/database</code> PostgreSQL connection, schema browsing, import <code>human-signals</code> <code>/api/human-signals</code> Human signals upload, DB import, signals processing <code>monitoring</code> <code>/api/monitoring</code> Monitoring data upload, DB config, DB import <code>monitoring_analytics</code> <code>/api/monitoring/analytics</code> Trends, latency distribution, metric breakdown, classification <code>eval_runner</code> <code>/api/eval-runner</code> Run evaluations, SSE streaming progress <code>memory</code> <code>/api/memory</code> Memory rule CRUD, upload, example data <code>graph</code> <code>/api/memory/graph</code> Knowledge graph queries, search, neighborhood <code>store</code> <code>/api/store</code> DuckDB sync triggers, status, metadata, paginated data"},{"location":"architecture/backend/#services","title":"Services","text":"Service File Purpose <code>data_processor</code> <code>data_processor.py</code> Format detection, column normalization, data transformation <code>database_service</code> <code>database_service.py</code> PostgreSQL operations (connect, query, import) <code>connection_store</code> <code>connection_store.py</code> Ephemeral connection handle management (15-min TTL) <code>issue_extractor_service</code> <code>issue_extractor_service.py</code> Extract issues from evaluation data, bridge to axion InsightExtractor for structured pattern discovery <code>human_signals_service</code> <code>human_signals_service.py</code> Human signals data processing <code>signals_display_config</code> <code>signals_display_config.py</code> YAML-driven display configuration for human signals dashboard <code>memory_service</code> <code>memory_service.py</code> Memory rule management (CSV cache, CRUD) <code>graph_service</code> <code>graph_service.py</code> FalkorDB graph queries and traversal <code>eval_runner_service</code> <code>eval_runner_service.py</code> Evaluation execution with Axion metrics <code>align_service</code> <code>align_service.py</code> LLM judge evaluation, prompt optimization, and EvidencePipeline-based pattern discovery with learning insights <code>axion_adapter</code> <code>axion_adapter.py</code> Adapter for internal Axion AI toolkit <code>duckdb_store</code> <code>duckdb_store.py</code> DuckDB connection manager, staging+swap, incremental append, watermarks, metadata persistence <code>sync_engine</code> <code>sync_engine.py</code> Postgres -&gt; DuckDB split sync (dataset+results), parallel COPY, incremental, periodic scheduler"},{"location":"architecture/backend/#configuration","title":"Configuration","text":""},{"location":"architecture/backend/#settings-class","title":"Settings Class","text":"<p>The <code>Settings</code> class in <code>app/config.py</code> uses <code>pydantic-settings</code> to load configuration from environment variables and <code>.env</code> files:</p> <pre><code>class Settings(BaseSettings):\n    HOST: str = \"127.0.0.1\"\n    PORT: int = 8500\n    DEBUG: bool = True\n    FRONTEND_URL: str = \"http://localhost:3500\"\n\n    # AI Configuration\n    openai_api_key: str | None = None\n    anthropic_api_key: str | None = None\n    llm_model_name: str = \"gpt-4\"\n\n    # Database configurations (human_signals, monitoring, eval)\n    human_signals_db_host: str | None = None\n    monitoring_db_host: str | None = None\n    eval_db_host: str | None = None\n\n    # Graph database (FalkorDB)\n    graph_db_host: str = \"localhost\"\n    graph_db_port: int = 6379\n\n    # Theme\n    axis_theme_active: str | None = None\n\n    model_config = SettingsConfigDict(env_file=\".env\", case_sensitive=False)\n</code></pre>"},{"location":"architecture/backend/#yaml-config-files","title":"YAML Config Files","text":"<p>Database and theme settings can also be loaded from YAML files in <code>custom/config/</code> (resolved via <code>AXIS_CUSTOM_DIR</code>). Template files live in <code>backend/config/*.yaml.example</code>; <code>make setup</code> copies them into <code>custom/config/</code>. YAML takes precedence over environment variables when present.</p> File Purpose <code>human_signals_db.yaml</code> Human signals database connection + query config <code>monitoring_db.yaml</code> Monitoring database connection config <code>eval_db.yaml</code> Evaluation database auto-import config <code>duckdb.yaml</code> DuckDB analytics store settings (sync, concurrency, workers) <code>theme.yaml</code> Color palette and branding overrides <code>signals_metrics.yaml</code> Display overrides for human signals dashboard"},{"location":"architecture/backend/#shared-constants","title":"Shared Constants","text":"<p>The <code>config.py</code> module exports three constant classes used across the backend and mirrored in the frontend:</p> ColumnsThresholdsColors <pre><code>class Columns:\n    DATASET_ID = \"dataset_id\"\n    QUERY = \"query\"\n    ACTUAL_OUTPUT = \"actual_output\"\n    METRIC_NAME = \"metric_name\"\n    METRIC_SCORE = \"metric_score\"\n    METRIC_CATEGORY = \"metric_category\"\n    TIMESTAMP = \"timestamp\"\n    # ... 40+ column name constants\n</code></pre> <pre><code>@dataclass(frozen=True)\nclass Thresholds:\n    PASSING_RATE: float = 0.5\n    GREEN_THRESHOLD: float = 0.7\n    RED_THRESHOLD: float = 0.3\n</code></pre> <pre><code>@dataclass(frozen=True)\nclass Colors:\n    PALETTE: ClassVar[dict[str, str]] = {\n        \"primary\": \"#8B9F4F\",\n        \"success\": \"#27AE60\",\n        \"warning\": \"#F39C12\",\n        \"error\": \"#E74C3C\",\n        # ...\n    }\n    CHART_COLORS: ClassVar[list[str]] = [\n        \"#8B9F4F\", \"#A4B86C\", \"#6B7A3A\", ...\n    ]\n</code></pre>"},{"location":"architecture/backend/#duckdb-analytics-store","title":"DuckDB Analytics Store","text":"<p>AXIS uses an embedded DuckDB database as a local analytics engine. Data is synced from PostgreSQL into DuckDB via a split sync pattern (dataset + results tables joined as views), and all monitoring/eval/human-signals analytics queries run against DuckDB with parameterized SQL.</p> <p>Key benefits:</p> <ul> <li>No large data transfers: Frontend sends filter params, not raw data arrays</li> <li>Sub-second queries: DuckDB handles analytical aggregations on millions of rows</li> <li>Split sync: Each dataset syncs as two concurrent reads (dataset + results), joined as a DuckDB view</li> <li>Incremental sync: Watermark-based append mode avoids full rebuilds when <code>incremental_column</code> is configured</li> <li>Parallel reads: Tiered strategy (parallel COPY export \u2192 single COPY \u2192 chunked cursor) for fastest possible sync</li> <li>Atomic updates: Staging + swap pattern ensures readers never see partial data during full rebuilds</li> <li>Non-blocking: All DuckDB I/O runs in threads via <code>anyio.to_thread.run_sync()</code> with a configurable concurrency limiter</li> <li>Periodic scheduler: Built-in background scheduler for datasets with <code>refresh_interval_minutes &gt; 0</code></li> </ul> <p>For a detailed technical deep-dive, see the DuckDB Architecture page.</p>"},{"location":"architecture/backend/#error-handling","title":"Error Handling","text":"<p>The backend uses a layered error handling pattern:</p>"},{"location":"architecture/backend/#service-exceptions","title":"Service Exceptions","text":"<p>Each service defines its own exception hierarchy:</p> <pre><code># In a service module\nclass ServiceError(Exception):\n    \"\"\"Base exception for this service.\"\"\"\n\nclass ConnectionExpiredError(ServiceError):\n    \"\"\"Connection handle has expired.\"\"\"\n\nclass TableNotFoundError(ServiceError):\n    \"\"\"Requested table does not exist.\"\"\"\n</code></pre>"},{"location":"architecture/backend/#router-error-mapping","title":"Router Error Mapping","text":"<p>Routers catch service exceptions and map them to HTTP status codes:</p> <pre><code>@router.post(\"/endpoint\")\nasync def endpoint(request: Request):\n    try:\n        result = await some_service.process(request)\n        return {\"success\": True, \"data\": result}\n    except ConnectionExpiredError as e:\n        raise HTTPException(status_code=401, detail=str(e))\n    except TableNotFoundError as e:\n        raise HTTPException(status_code=404, detail=str(e))\n    except ServiceError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception:\n        logger.exception(\"Unexpected error\")\n        raise HTTPException(status_code=500, detail=\"An unexpected error occurred\")\n</code></pre>"},{"location":"architecture/backend/#response-format","title":"Response Format","text":"<p>All successful responses follow a consistent shape:</p> <pre><code>{\n  \"success\": true,\n  \"data\": { ... },\n  \"message\": \"Optional status message\"\n}\n</code></pre> <p>Error responses use FastAPI's built-in format:</p> <pre><code>{\n  \"detail\": \"Description of what went wrong\"\n}\n</code></pre>"},{"location":"architecture/backend/#async-patterns","title":"Async Patterns","text":"<ul> <li>All router endpoints are <code>async def</code></li> <li>Database operations use async SQLAlchemy + asyncpg</li> <li>File I/O uses FastAPI's <code>UploadFile</code> with async reads</li> <li>SSE streaming (for copilot and eval runner) uses <code>sse_starlette.EventSourceResponse</code></li> </ul> <p>CPU-bound work</p> <p>Data processing with Pandas runs synchronously. For large datasets, the processing happens in the request thread. Consider offloading to a background task for datasets exceeding 50,000 rows.</p>"},{"location":"architecture/backend/#database-connection-handles","title":"Database Connection Handles","text":"<p>The database integration module uses ephemeral connection handles with a 15-minute TTL to avoid resending credentials on every request:</p> <pre><code>sequenceDiagram\n    participant C as Client\n    participant R as Database Router\n    participant CS as Connection Store\n\n    C-&gt;&gt;R: POST /api/database/connect {host, port, ...}\n    R-&gt;&gt;CS: Store connection, return UUID handle\n    CS--&gt;&gt;R: handle = \"abc-123\"\n    R--&gt;&gt;C: {\"handle\": \"abc-123\"}\n\n    C-&gt;&gt;R: GET /api/database/abc-123/tables\n    R-&gt;&gt;CS: Lookup handle, get connection\n    CS--&gt;&gt;R: Connection object\n    R--&gt;&gt;C: {\"tables\": [...]}\n\n    Note over CS: Handle expires after 15 minutes</code></pre>"},{"location":"architecture/backend/#adding-a-new-router","title":"Adding a New Router","text":"<ol> <li>Create the router file in <code>app/routers/new_feature.py</code></li> <li>Define Pydantic models in <code>app/models/new_feature_schemas.py</code></li> <li>Implement business logic in <code>app/services/new_feature_service.py</code></li> <li>Register the router in <code>app/main.py</code>:</li> </ol> <pre><code>from app.routers import new_feature\napp.include_router(\n    new_feature.router,\n    prefix=\"/api/new-feature\",\n    tags=[\"new-feature\"],\n)\n</code></pre>"},{"location":"architecture/backend/#lint-and-format","title":"Lint and Format","text":"<p>Always run before committing:</p> <pre><code>ruff check app --fix &amp;&amp; ruff format app\n</code></pre>"},{"location":"architecture/data-formats/","title":"Data Formats","text":"<p>AXIS supports multiple data formats for evaluation results and production monitoring. The backend automatically detects the format on upload and normalizes column names to a standard schema.</p>"},{"location":"architecture/data-formats/#evaluation-formats","title":"Evaluation Formats","text":"<p>Evaluation data represents the results of running LLM evaluations. AXIS detects five formats, checked in priority order:</p> Format Key Columns Use Case <code>eval_runner</code> <code>run_id</code>, <code>dataset_id</code>, <code>passed</code> Output from AXIS evaluation runner <code>tree_format</code> <code>metric_name</code>, <code>parent</code>, <code>metric_type</code>, <code>metric_score</code> Hierarchical metrics with parent relationships <code>flat_format</code> <code>metric_name</code>, <code>metric_score</code> Simple metric scores in long format <code>simple_judgment</code> <code>judgment</code> Binary pass/fail judgments <code>fresh_annotation</code> <code>dataset_id</code>, <code>evaluation_name</code>, <code>query</code>, <code>actual_output</code> Raw outputs ready for human annotation"},{"location":"architecture/data-formats/#format-detection-flow","title":"Format Detection Flow","text":"<p>The backend's <code>detect_data_format()</code> function checks for formats in a strict priority order. The first match wins:</p> <pre><code>flowchart TD\n    START([Upload CSV]) --&gt; A{Has run_id +&lt;br/&gt;dataset_id + passed?}\n    A -- Yes --&gt; R[eval_runner]\n    A -- No --&gt; B{Has metric_name +&lt;br/&gt;parent + metric_type +&lt;br/&gt;metric_score?}\n    B -- Yes --&gt; T[tree_format]\n    B -- No --&gt; C{Has metric_name +&lt;br/&gt;metric_score?}\n    C -- Yes --&gt; F[flat_format]\n    C -- No --&gt; D{Has judgment&lt;br/&gt;column?}\n    D -- Yes --&gt; J[simple_judgment]\n    D -- No --&gt; E{Has dataset_id +&lt;br/&gt;evaluation_name +&lt;br/&gt;query + actual_output?}\n    E -- Yes --&gt; A2[fresh_annotation]\n    E -- No --&gt; U[unknown]</code></pre>"},{"location":"architecture/data-formats/#tree-format-example","title":"Tree Format Example","text":"<p>Hierarchical metrics where each row is a single metric observation with parent-child relationships:</p> <pre><code>dataset_id,query,actual_output,metric_name,metric_score,metric_type,parent,weight,explanation\nREC-001,What is AI?,AI is...,Overall Quality,0.82,metric,,1.0,\nREC-001,What is AI?,AI is...,Faithfulness,0.90,component,Overall Quality,0.5,Accurate statements\nREC-001,What is AI?,AI is...,Relevance,0.74,component,Overall Quality,0.5,Mostly relevant\n</code></pre>"},{"location":"architecture/data-formats/#flat-format-example","title":"Flat Format Example","text":"<p>Simple long-format scores without hierarchy:</p> <pre><code>dataset_id,query,actual_output,metric_name,metric_score,explanation\nREC-001,What is AI?,AI is...,Faithfulness,0.90,Accurate statements\nREC-001,What is AI?,AI is...,Relevance,0.74,Mostly relevant\nREC-002,Explain ML,ML is...,Faithfulness,0.85,Good accuracy\n</code></pre>"},{"location":"architecture/data-formats/#simple-judgment-example","title":"Simple Judgment Example","text":"<p>Binary pass/fail evaluations:</p> <pre><code>dataset_id,query,actual_output,judgment\nREC-001,What is AI?,AI is...,pass\nREC-002,Explain ML,ML is...,fail\n</code></pre>"},{"location":"architecture/data-formats/#monitoring-formats","title":"Monitoring Formats","text":"<p>Monitoring data represents time-series observations from production systems. Two formats are supported:</p>"},{"location":"architecture/data-formats/#long-format-recommended","title":"Long Format (Recommended)","text":"<p>Each row represents a single metric observation. Detected when data has both <code>metric_name</code> and <code>metric_score</code> columns.</p> <pre><code>dataset_id,query,actual_output,metric_name,metric_score,metric_category,timestamp,environment,source_name\n01KFX,What is...,The answer,Faithfulness,0.85,SCORE,2024-01-15T10:30:00,production,my_agent\n01KFX,What is...,The answer,Relevance,0.92,SCORE,2024-01-15T10:30:00,production,my_agent\n01KFX,What is...,The answer,Topic,RELEVANT,CLASSIFICATION,2024-01-15T10:30:00,production,my_agent\n</code></pre> <p>When to use long format</p> <p>Long format is the recommended format for production monitoring. It maps naturally to normalized database schemas and supports mixed metric categories per record.</p>"},{"location":"architecture/data-formats/#wide-format","title":"Wide Format","text":"<p>Each row contains all metrics as separate columns. Columns ending in <code>_score</code> are auto-detected as metrics.</p> <pre><code>dataset_id,query,actual_output,faithfulness_score,relevance_score,timestamp\n01KFX,What is...,The answer,0.85,0.92,2024-01-15T10:30:00\n</code></pre>"},{"location":"architecture/data-formats/#metric-detection-logic","title":"Metric Detection Logic","text":"<pre><code>def detect_metric_columns(df):\n    # Long format: metric_name + metric_score columns present\n    if \"metric_name\" in df.columns and \"metric_score\" in df.columns:\n        return [\"metric_score\"]\n\n    # Wide format: columns ending with _score\n    return [col for col in df.columns if col.endswith(\"_score\")]\n</code></pre>"},{"location":"architecture/data-formats/#column-normalization","title":"Column Normalization","text":"<p>The monitoring upload automatically normalizes common column name variations. The normalization is case-insensitive and replaces spaces/hyphens with underscores before lookup.</p>"},{"location":"architecture/data-formats/#normalization-map","title":"Normalization Map","text":"IdentifiersTimestampsInput / OutputModel / AgentEnvironmentPerformance Input Alias Normalized To <code>id</code> <code>dataset_id</code> <code>record_id</code> <code>dataset_id</code> <code>dataset_id</code> <code>dataset_id</code> Input Alias Normalized To <code>time</code> <code>timestamp</code> <code>created_at</code> <code>timestamp</code> <code>dataset_created_at</code> <code>timestamp</code> Input Alias Normalized To <code>input</code> <code>query</code> <code>prompt</code> <code>query</code> <code>user_input</code> <code>query</code> <code>output</code> <code>actual_output</code> <code>response</code> <code>actual_output</code> <code>model_output</code> <code>actual_output</code> <code>completion</code> <code>actual_output</code> Input Alias Normalized To <code>model</code> <code>model_name</code> <code>agent</code> <code>model_name</code> <code>agent_name</code> <code>model_name</code> Input Alias Normalized To <code>env</code> <code>environment</code> <code>stage</code> <code>environment</code> Input Alias Normalized To <code>latency_ms</code> <code>latency</code> <code>response_time</code> <code>latency</code> <code>error</code> <code>has_errors</code> <p>Custom column mappings</p> <p>When loading from a database via YAML config, you can specify a <code>columns</code> map that takes precedence over the default normalization. This allows mapping arbitrary column names to the standard schema.</p>"},{"location":"architecture/data-formats/#metric-categories","title":"Metric Categories","text":"<p>Each metric in the monitoring long format can have a <code>metric_category</code> that determines how the metric output is interpreted and displayed:</p> Category Value Type Display Example Output <code>SCORE</code> Numeric (0-1) Charts, thresholds, pass/fail, trend lines <code>0.85</code>, <code>0.92</code> <code>CLASSIFICATION</code> String Category breakdowns, distribution bar charts <code>\"RELEVANT\"</code>, <code>\"POSITIVE\"</code> <code>ANALYSIS</code> JSON / Text Structured detail views, signal inspectors <code>{\"issues\": [...], \"summary\": \"...\"}</code> <pre><code>graph LR\n    M[metric_category] --&gt; S[SCORE]\n    M --&gt; C[CLASSIFICATION]\n    M --&gt; A[ANALYSIS]\n\n    S --&gt; S1[Trend charts]\n    S --&gt; S2[Pass/fail rates]\n    S --&gt; S3[Thresholds]\n\n    C --&gt; C1[Category bar charts]\n    C --&gt; C2[Distribution breakdowns]\n    C --&gt; C3[Trend stacked areas]\n\n    A --&gt; A1[Signal inspector]\n    A --&gt; A2[Detail view cards]\n    A --&gt; A3[Paginated records]</code></pre> <p>If <code>metric_category</code> is not provided, the metric defaults to <code>SCORE</code>.</p>"},{"location":"architecture/data-formats/#shared-constants","title":"Shared Constants","text":"<p>Column names, thresholds, and colors are defined in both the Python backend and the TypeScript frontend to keep them in sync.</p> Python (backend/app/config.py)TypeScript (frontend/src/types/index.ts) <pre><code>class Columns:\n    DATASET_ID = \"dataset_id\"\n    QUERY = \"query\"\n    ACTUAL_OUTPUT = \"actual_output\"\n    METRIC_NAME = \"metric_name\"\n    METRIC_SCORE = \"metric_score\"\n    METRIC_CATEGORY = \"metric_category\"\n    TIMESTAMP = \"timestamp\"\n    # ... 40+ constants\n\n@dataclass(frozen=True)\nclass Thresholds:\n    PASSING_RATE: float = 0.5\n    GREEN_THRESHOLD: float = 0.7\n    RED_THRESHOLD: float = 0.3\n\n@dataclass(frozen=True)\nclass Colors:\n    PALETTE = {\n        \"primary\": \"#8B9F4F\",\n        \"success\": \"#27AE60\",\n        \"warning\": \"#F39C12\",\n        \"error\": \"#E74C3C\",\n    }\n</code></pre> <pre><code>export const Columns = {\n  DATASET_ID: 'dataset_id',\n  QUERY: 'query',\n  ACTUAL_OUTPUT: 'actual_output',\n  METRIC_NAME: 'metric_name',\n  METRIC_SCORE: 'metric_score',\n  METRIC_CATEGORY: 'metric_category',\n  TIMESTAMP: 'timestamp',\n  // ... 40+ constants\n} as const;\n\nexport const Thresholds = {\n  PASSING_RATE: 0.5,\n  GREEN_THRESHOLD: 0.7,\n  RED_THRESHOLD: 0.3,\n} as const;\n\nexport const DefaultColors = {\n  primary: '#8B9F4F',\n  success: '#27AE60',\n  warning: '#F39C12',\n  error: '#E74C3C',\n} as const;\n</code></pre> <p>Keep in sync</p> <p>When adding or renaming a column constant, update both <code>backend/app/config.py</code> and <code>frontend/src/types/index.ts</code>. There is no code generation step -- these are maintained manually.</p>"},{"location":"architecture/data-formats/#monitoring-column-reference","title":"Monitoring Column Reference","text":"<p>Complete reference of standard monitoring columns:</p> Column Required Type Description <code>dataset_id</code> Yes string Unique identifier for the record <code>timestamp</code> No* datetime ISO datetime; auto-generated if missing <code>query</code> No string Input/prompt text <code>actual_output</code> No string LLM response text <code>expected_output</code> No string Ground truth for comparison <code>metric_name</code> No string Metric name (long format) <code>metric_score</code> No number Metric value (long format) <code>metric_type</code> No string Type of metric (<code>component</code>, <code>aggregate</code>) <code>metric_category</code> No string Output type: <code>SCORE</code>, <code>CLASSIFICATION</code>, <code>ANALYSIS</code> <code>environment</code> No string Deployment environment (e.g., <code>production</code>) <code>source_name</code> No string Agent or source system name (e.g., <code>alpha_bot</code>) <code>source_component</code> No string Component within source (e.g., <code>retrieval</code>) <code>source_type</code> No string Source type (e.g., <code>langfuse</code>, <code>custom</code>) <code>evaluation_name</code> No string Name of the evaluation/experiment <code>model_name</code> No string Model used for generation <code>trace_id</code> No string Observability trace ID <code>latency</code> No number Response time in milliseconds <code>passed</code> No boolean Whether the metric passed its threshold <code>threshold</code> No number Pass/fail threshold value <code>explanation</code> No string Metric explanation text <code>signals</code> No JSON Structured evaluation signals <p>*Timestamp is auto-generated with the current time if not present in the uploaded data.</p>"},{"location":"architecture/data-formats/#human-signals-formats","title":"Human Signals Formats","text":"<p>The Human Signals (HITL) dashboard supports two data versions:</p>"},{"location":"architecture/data-formats/#v1-format","title":"V1 Format","text":"<p>Case-level records with fixed columns like <code>Case_ID</code>, <code>Business</code>, <code>Has_Intervention</code>, <code>Intervention_Type</code>, <code>Sentiment</code>, <code>Final_Outcome</code>, etc. This is a hardcoded schema.</p>"},{"location":"architecture/data-formats/#v2-format-data-driven","title":"V2 Format (Data-Driven)","text":"<p>Generic signal records where metrics are flattened as <code>{metric_name}__{signal_key}</code> columns. The backend auto-discovers the schema and returns:</p> <ul> <li><code>metric_schema</code>: Describes discovered metrics, their categories, and signal types</li> <li><code>display_config</code>: YAML-driven layout for KPIs, charts, filters, and table columns</li> </ul> <p>The frontend auto-detects V1 vs V2 based on the presence of <code>metric_schema</code> in the upload response.</p>"},{"location":"architecture/duckdb-store/","title":"DuckDB Analytics Store","text":"<p>AXIS uses an embedded DuckDB database as a local analytics engine. Data is synced from external PostgreSQL sources into DuckDB, where all analytics queries run. This architecture eliminates large data transfers between frontend and backend and enables sub-second aggregation queries on millions of rows.</p>"},{"location":"architecture/duckdb-store/#architecture","title":"Architecture","text":"<pre><code>graph TB\n    subgraph Sources [\"External PostgreSQL\"]\n        PG_MON[(monitoring DB)]\n        PG_FB[(human signals DB)]\n        PG_EVAL[(eval DB)]\n    end\n\n    subgraph SyncEngine [\"Sync Engine\"]\n        SPLIT[\"Split read&lt;br/&gt;(dataset + results)\"]\n        COPY[\"Parallel COPY export&lt;br/&gt;(or chunked fallback)\"]\n        NORM[\"Column normalization&lt;br/&gt;(per-dataset)\"]\n        STAGE[\"Staging table write\"]\n        SWAP[\"Atomic swap / Append&lt;br/&gt;(full or incremental)\"]\n    end\n\n    subgraph DuckDB [\"DuckDB (data/local_store.duckdb)\"]\n        T_MON_D[monitoring_dataset]\n        T_MON_R[monitoring_results]\n        T_MON[monitoring_data&lt;br/&gt;JOIN view]\n        T_FB_D[human_signals_dataset]\n        T_FB_R[human_signals_results]\n        T_FB_RAW[human_signals_raw&lt;br/&gt;JOIN view]\n        T_FB_CASES[human_signals_cases&lt;br/&gt;derived]\n        T_EVAL_D[eval_dataset]\n        T_EVAL_R[eval_results]\n        T_EVAL[eval_data&lt;br/&gt;JOIN view]\n        T_META[_store_metadata&lt;br/&gt;metadata + KV + watermarks]\n    end\n\n    subgraph API [\"Analytics Endpoints\"]\n        EP_SUMMARY[\"/monitoring/analytics/summary\"]\n        EP_TRENDS[\"/monitoring/analytics/trends\"]\n        EP_BREAKDOWN[\"/monitoring/analytics/metric-breakdown\"]\n        EP_CLASS[\"/monitoring/analytics/classification-*\"]\n        EP_ANALYSIS[\"/monitoring/analytics/analysis-insights\"]\n        EP_STORE[\"/store/status, /data, /metadata\"]\n    end\n\n    PG_MON --&gt; SPLIT\n    PG_FB --&gt; SPLIT\n    PG_EVAL --&gt; SPLIT\n    SPLIT --&gt; COPY --&gt; NORM --&gt; STAGE --&gt; SWAP\n    SWAP --&gt; T_MON_D\n    SWAP --&gt; T_MON_R\n    SWAP --&gt; T_FB_D\n    SWAP --&gt; T_FB_R\n    SWAP --&gt; T_EVAL_D\n    SWAP --&gt; T_EVAL_R\n    T_MON_D -.-&gt;|\"JOIN view\"| T_MON\n    T_MON_R -.-&gt;|\"JOIN view\"| T_MON\n    T_FB_D -.-&gt;|\"JOIN view\"| T_FB_RAW\n    T_FB_R -.-&gt;|\"JOIN view\"| T_FB_RAW\n    T_EVAL_D -.-&gt;|\"JOIN view\"| T_EVAL\n    T_EVAL_R -.-&gt;|\"JOIN view\"| T_EVAL\n    T_FB_RAW -.-&gt;|\"derived at sync time\"| T_FB_CASES\n    T_FB_RAW -.-&gt; T_META\n\n    T_MON --&gt; EP_SUMMARY\n    T_MON --&gt; EP_TRENDS\n    T_MON --&gt; EP_BREAKDOWN\n    T_MON --&gt; EP_CLASS\n    T_MON --&gt; EP_ANALYSIS\n    T_MON --&gt; EP_STORE\n    T_EVAL --&gt; EP_STORE\n    T_FB_CASES --&gt; EP_STORE</code></pre>"},{"location":"architecture/duckdb-store/#key-design-decisions","title":"Key Design Decisions","text":""},{"location":"architecture/duckdb-store/#split-sync-dataset-results","title":"Split Sync (Dataset + Results)","text":"<p>All datasets use a two-table split sync pattern. Each source database is expected to provide two queries:</p> <ul> <li><code>dataset_query</code> \u2014 fetches the \"records\" side (dataset_id, query, actual_output, metadata)</li> <li><code>results_query</code> \u2014 fetches the \"metrics\" side (dataset_id, metric_name, metric_score, ...)</li> </ul> <p>The two tables sync concurrently via <code>asyncio.gather</code>, then a DuckDB JOIN view is created:</p> <pre><code>CREATE VIEW monitoring_data AS\n  SELECT r.*, d.query, d.actual_output, ...\n  FROM monitoring_results r\n  JOIN monitoring_dataset d ON r.dataset_id = d.dataset_id\n</code></pre> <p>Benefits:</p> <ul> <li>Concurrent reads: Both halves of the data load in parallel from Postgres</li> <li>Reduced redundancy: Dataset columns (query text, outputs) are stored once, not repeated per metric row</li> <li>Incremental-friendly: Each sub-table has its own watermark \u2014 only new rows are appended</li> </ul>"},{"location":"architecture/duckdb-store/#incremental-sync","title":"Incremental Sync","text":"<p>When an <code>incremental_column</code> is configured (e.g., <code>created_at</code>), the sync engine can operate in incremental mode:</p> <ol> <li>Check if both sub-tables exist and have stored watermarks</li> <li>Wrap each query with <code>WHERE {column} &gt; '{watermark}'</code></li> <li>Append new rows to existing tables (INSERT INTO, no staging swap)</li> <li>Update watermarks to the new MAX value</li> <li>Recompute metadata</li> </ol> <p>If incremental sync fails, watermarks are automatically cleared and the next sync falls back to a full rebuild.</p> <p>Force full rebuild</p> <p>Pass <code>?full=true</code> to any sync endpoint to skip incremental mode and force a staging + swap rebuild.</p>"},{"location":"architecture/duckdb-store/#full-rebuild-fallback","title":"Full Rebuild (Fallback)","text":"<p>When incremental is not available (first sync, no watermarks, no <code>incremental_column</code> configured, or <code>?full=true</code>), the engine does a complete staging + atomic swap:</p> <pre><code>BEGIN TRANSACTION;\nDROP TABLE IF EXISTS monitoring_results;\nALTER TABLE monitoring_results_staging RENAME TO monitoring_results;\nCOMMIT;\n</code></pre> <p>Readers always see either the previous complete table or the new complete table -- never partial data.</p>"},{"location":"architecture/duckdb-store/#read-strategies-tiered-fallback","title":"Read Strategies (Tiered Fallback)","text":"<p>The sync engine tries three read strategies in order:</p> <ol> <li>Parallel COPY export \u2014 <code>sync_workers</code> concurrent Postgres <code>COPY TO</code> commands, each handling a partition range. Writes CSV files to a temp directory, then loads into DuckDB via <code>read_csv_auto</code>. Fastest for large tables.</li> <li>Single COPY export \u2014 One <code>COPY TO</code> command for the whole query. Used when <code>partition_column</code> is not configured or <code>sync_workers = 1</code>.</li> <li>Sequential chunked read \u2014 asyncpg cursor reading <code>sync_chunk_size</code> rows per fetch. Fallback when the database backend does not support COPY.</li> </ol>"},{"location":"architecture/duckdb-store/#non-blocking-io","title":"Non-blocking I/O","text":"<p>All DuckDB operations are synchronous (DuckDB does not have an async API). To avoid blocking the FastAPI event loop:</p> <ul> <li>Analytics endpoints are <code>async def</code> and dispatch DuckDB reads via <code>await anyio.to_thread.run_sync(query_fn, limiter=query_limiter)</code></li> <li>A shared <code>anyio.CapacityLimiter</code> (default 8 concurrent) bounds the number of simultaneous DuckDB read threads</li> <li>Sync writes also use <code>anyio.to_thread.run_sync()</code> per chunk</li> <li>Postgres reads happen outside the DuckDB write lock; the lock is held only for the brief staging/append phase</li> </ul>"},{"location":"architecture/duckdb-store/#leader-only-sync","title":"Leader-Only Sync","text":"<p>For multi-worker deployments (multiple uvicorn workers sharing the same DuckDB file), an OS-level file lock (<code>fcntl.flock</code>) ensures only one worker runs the sync at a time. The lock is non-blocking: workers that fail to acquire it skip the sync silently.</p> <p>Multi-host deployments</p> <p>OS file locks only coordinate processes on the same host. For multi-host deployments, the DuckDB file must live on shared storage (e.g., a shared Docker volume), or use a single-writer deployment pattern.</p>"},{"location":"architecture/duckdb-store/#periodic-sync-scheduler","title":"Periodic Sync Scheduler","text":"<p>The backend includes a built-in periodic sync scheduler that runs as a background task. For each dataset with <code>refresh_interval_minutes &gt; 0</code>, the scheduler:</p> <ol> <li>Waits for the startup sync to complete (if <code>sync_mode: \"startup\"</code>)</li> <li>Sleeps until the next dataset is due</li> <li>Syncs all due datasets concurrently</li> <li>Uses incremental mode when watermarks are available</li> </ol> <p>The scheduler runs until the application shuts down (cancelled via lifespan cleanup).</p>"},{"location":"architecture/duckdb-store/#data-flow","title":"Data Flow","text":""},{"location":"architecture/duckdb-store/#sync-lifecycle","title":"Sync Lifecycle","text":"<ol> <li>Startup: <code>lifespan</code> handler in <code>main.py</code> initializes the DuckDB store, loads cached metadata from disk, rebuilds <code>human_signals_cases</code> if needed, and fires a background <code>sync_with_lock()</code> task (if <code>sync_mode: \"startup\"</code>)</li> <li>Periodic scheduler starts: Waits for startup sync to finish, then enters the periodic loop</li> <li>Split read: For each dataset, <code>dataset_query</code> and <code>results_query</code> are read concurrently from Postgres</li> <li>Read strategy selection: Parallel COPY \u2192 single COPY \u2192 sequential chunked (tiered fallback)</li> <li>Column normalization: Per-dataset column normalization (rename, type coercion) runs on each chunk</li> <li>DuckDB write: Full rebuild (staging + swap) or incremental (INSERT INTO) based on watermark state</li> <li>JOIN view creation: On full sync, a DuckDB view is created joining the two sub-tables</li> <li>Metadata compute: Row count, column info, filter values, time range, and summary stats are computed and persisted to <code>_store_metadata</code></li> <li>Watermark update: MAX value of the <code>incremental_column</code> is stored per sub-table</li> <li>Derived tables (human signals only): <code>human_signals_cases</code> and <code>human_signals_metric_schema</code> are rebuilt from <code>human_signals_raw</code></li> </ol>"},{"location":"architecture/duckdb-store/#duckdb-tables","title":"DuckDB Tables","text":"Table Type Source Description <code>monitoring_dataset</code> Internal table <code>monitoring_db.yaml</code> <code>dataset_query</code> Dataset records (query, output, metadata) <code>monitoring_results</code> Internal table <code>monitoring_db.yaml</code> <code>results_query</code> Metric results (scores, categories) <code>monitoring_data</code> JOIN view Auto-generated <code>monitoring_results JOIN monitoring_dataset</code> <code>human_signals_dataset</code> Internal table <code>human_signals_db.yaml</code> <code>dataset_query</code> Human signals dataset records <code>human_signals_results</code> Internal table <code>human_signals_db.yaml</code> <code>results_query</code> Human signals metric results <code>human_signals_raw</code> JOIN view Auto-generated <code>human_signals_results JOIN human_signals_dataset</code> <code>human_signals_cases</code> Derived table Built from <code>human_signals_raw</code> Aggregated cases with flattened signals <code>eval_dataset</code> Internal table <code>eval_db.yaml</code> <code>dataset_query</code> Evaluation dataset records <code>eval_results</code> Internal table <code>eval_db.yaml</code> <code>results_query</code> Evaluation metric results <code>eval_data</code> JOIN view Auto-generated <code>eval_results JOIN eval_dataset</code> <code>_store_metadata</code> Internal table Sync engine Persisted metadata, KV pairs, watermarks, sync IDs <p>Staging tables are invisible</p> <p>Tables like <code>monitoring_results_staging</code> exist only during sync. The <code>ALLOWED_TABLES</code> set in <code>duckdb_store.py</code> ensures only the API-visible tables are exposed via endpoints.</p>"},{"location":"architecture/duckdb-store/#human-signals-derived-tables","title":"Human Signals Derived Tables","text":"<p>Human signals data goes through a two-stage sync:</p> <ol> <li>Stage 1: Raw rows are normalized and stored via the <code>human_signals_dataset</code> + <code>human_signals_results</code> split, joined as <code>human_signals_raw</code></li> <li>Stage 2: <code>human_signals_service.py</code> functions (<code>build_metric_schema()</code>, <code>aggregate_cases()</code>) run against <code>human_signals_raw</code> to produce:<ul> <li><code>human_signals_cases</code> table (pre-aggregated, flattened signals)</li> <li><code>human_signals_metric_schema</code> JSON blob in <code>_store_metadata</code></li> </ul> </li> </ol> <p>A <code>sync_id</code> (UUID) tags both tables. On startup, if the IDs don't match (crash between Stage 1 and Stage 2), the derived tables are automatically rebuilt.</p>"},{"location":"architecture/duckdb-store/#services","title":"Services","text":""},{"location":"architecture/duckdb-store/#duckdb_storepy-duckdbstore","title":"<code>duckdb_store.py</code> -- DuckDBStore","text":"<p>The core connection manager and query executor:</p> Method Purpose <code>query_df(sql, params)</code> Read-only query returning a DataFrame (cursor per call for thread safety) <code>query_list(sql, params)</code> Read-only query returning <code>list[dict]</code> <code>query_value(sql, params)</code> Read-only query returning a single scalar <code>has_table(table_name)</code> Check if a non-staging table exists (allowlist-validated) <code>get_metadata(table_name)</code> Return cached metadata (hot cache first, DuckDB fallback) <code>ensure_ready(table_name)</code> Raise 503/404 if table is not ready for queries <code>get_sync_status(table_name)</code> Return per-table sync status <code>get_kv(key)</code> / <code>set_kv(key, value)</code> Key-value storage in <code>_store_metadata</code> <code>get_watermark(table)</code> / <code>set_watermark(table, val)</code> Incremental sync watermark management <code>clear_watermark(table)</code> Clear watermark \u2014 forces full rebuild on next sync <p>Staging and write methods are synchronous and designed to be called via <code>anyio.to_thread.run_sync()</code>:</p> Method Purpose <code>_init_staging(table)</code> Drop existing staging table <code>_write_chunk(table, df, is_first)</code> Write DataFrame to staging <code>_write_csv_to_staging(table, path)</code> Create staging from CSV via <code>read_csv_auto</code> <code>_swap_staging(table)</code> Atomic DROP + RENAME in transaction <code>_append_chunk(table, df)</code> INSERT INTO existing table (incremental) <code>_append_csv(table, path)</code> INSERT INTO from CSV file (incremental) <code>_write_derived_table(table, df)</code> CREATE OR REPLACE for derived tables <code>_create_view(name, sql)</code> Create or replace a DuckDB view"},{"location":"architecture/duckdb-store/#sync_enginepy-sync-orchestration","title":"<code>sync_engine.py</code> -- Sync Orchestration","text":"Function Purpose <code>sync_dataset(config, table, store)</code> Sync one dataset via split path: two internal tables \u2192 JOIN view <code>sync_all(store)</code> Sync all configured datasets concurrently <code>sync_single(dataset, store)</code> Sync a named dataset by key <code>sync_with_lock(store, reason, force_full)</code> Acquire OS file lock, then <code>sync_all()</code> <code>periodic_sync_loop(store)</code> Background loop: sleep until next due dataset, sync, repeat <code>_sync_split(config, table, store, force_full)</code> Orchestrate split sync with incremental/full decision <code>_sync_internal_table(config, table, store, append_mode)</code> Sync one sub-table (full or incremental) <code>_build_join_view(store, view, dataset_tbl, results_tbl)</code> Create DuckDB JOIN view from two sub-tables <code>_build_human_signals_derived_tables(store, sync_id)</code> Build <code>human_signals_cases</code> + metric schema from <code>human_signals_raw</code> <code>_parallel_copy_read(...)</code> N parallel COPY reads partitioned by column range <code>_chunked_read(...)</code> Async generator yielding DataFrame chunks from cursor"},{"location":"architecture/duckdb-store/#storepy-store-router","title":"<code>store.py</code> -- Store Router","text":"Endpoint Method Purpose <code>/api/store/sync</code> POST Trigger sync for all datasets. <code>?full=true</code> forces full rebuild <code>/api/store/sync/{dataset}</code> POST Sync single dataset (monitoring, human_signals, eval). <code>?full=true</code> forces full rebuild <code>/api/store/sync/{dataset}/reset-watermark</code> POST Clear watermarks \u2014 next sync does full rebuild <code>/api/store/status</code> GET Per-table sync status: state, rows, last sync, watermarks, refresh interval <code>/api/store/metadata/{dataset}</code> GET Columns, time range, pre-computed filter values, summary stats <code>/api/store/data/{dataset}</code> GET Paginated data with filters, sorting, column projection, search"},{"location":"architecture/duckdb-store/#monitoring_analyticspy-analytics-router","title":"<code>monitoring_analytics.py</code> -- Analytics Router","text":"Endpoint Method Purpose <code>/api/monitoring/analytics/summary</code> GET Lightweight KPIs (total, avg score, pass rate, latency percentiles). Uses metadata cache fast path when unfiltered <code>/api/monitoring/analytics/trends</code> GET Time-series trends bucketed by granularity (hourly/daily/weekly) <code>/api/monitoring/analytics/metric-breakdown</code> GET Pass rate and average per metric, with optional group-by <code>/api/monitoring/analytics/latency-distribution</code> GET Latency histogram with percentiles and optional group-by <code>/api/monitoring/analytics/class-distribution</code> GET Score distributions grouped by model/environment/evaluation <code>/api/monitoring/analytics/correlation</code> GET Correlation matrix between metrics <code>/api/monitoring/analytics/classification-breakdown</code> GET Category value counts for CLASSIFICATION metrics <code>/api/monitoring/analytics/classification-trends</code> GET Time-series for CLASSIFICATION metric categories <code>/api/monitoring/analytics/analysis-insights</code> GET Paginated ANALYSIS metric records with signals"},{"location":"architecture/duckdb-store/#metadata-persistence","title":"Metadata Persistence","text":"<p>Metadata is computed at sync time and persisted in a <code>_store_metadata</code> DuckDB table. An in-memory hot cache serves reads without hitting disk:</p> <ul> <li>Startup: <code>load_metadata_from_db()</code> populates the hot cache from DuckDB</li> <li>After sync: <code>_compute_and_persist_metadata()</code> refreshes both DuckDB and the hot cache</li> <li>Multi-worker: Any worker can read metadata from DuckDB, even if it didn't run the sync</li> </ul> <p>Cached metadata per table includes:</p> Field Description <code>row_count</code> Total rows in the table <code>columns</code> Column names and DuckDB types <code>filter_values</code> Distinct values for low-cardinality fields (max 200 per field) <code>time_range</code> <code>{min, max}</code> of the <code>timestamp</code> column <code>summary_stats</code> Pre-aggregated KPIs: total_records, avg_score, pass_rate, p50/p95/p99 latency (monitoring_data only) <p>The <code>summary_stats</code> field enables the <code>/summary</code> endpoint to return instant responses without querying the table when no filters are applied.</p>"},{"location":"architecture/duckdb-store/#watermark-management","title":"Watermark Management","text":"<p>Watermarks are stored in the <code>_store_metadata</code> KV table with keys like <code>_watermark_monitoring_dataset</code>. Each sub-table has its own watermark.</p> Operation Endpoint / Action View watermarks <code>GET /api/store/status</code> \u2014 includes watermarks per sub-table Reset watermarks <code>POST /api/store/sync/{dataset}/reset-watermark</code> \u2014 clears both sub-table watermarks Force full rebuild <code>POST /api/store/sync/{dataset}?full=true</code> \u2014 ignores watermarks for this sync Auto-clear on failure If incremental sync fails, watermarks are automatically cleared"},{"location":"architecture/duckdb-store/#configuration","title":"Configuration","text":"<p>See DuckDB Configuration for the full YAML reference.</p> custom/config/duckdb.yaml<pre><code>duckdb:\n  enabled: true\n  path: \"data/local_store.duckdb\"\n  sync_mode: \"startup\"\n  sync_chunk_size: 10000\n  max_sync_rows: 2000000\n  query_concurrency: 8\n  sync_workers: 4\n</code></pre> custom/config/monitoring_db.yaml (split queries + incremental)<pre><code>monitoring_db:\n  enabled: true\n  auto_load: true\n  url: \"postgresql://user:pass@host:5432/db\"\n  dataset_query: |\n    SELECT id AS dataset_id, input AS query, output AS actual_output, ...\n    FROM traces\n  results_query: |\n    SELECT trace_id AS dataset_id, metric_name, score AS metric_score, ...\n    FROM metric_results\n  partition_column: \"id\"\n  incremental_column: \"created_at\"\n  refresh_interval_minutes: 15\n</code></pre>"},{"location":"architecture/duckdb-store/#sync-status-states","title":"Sync Status States","text":"State Meaning <code>not_synced</code> No sync has been attempted for this table <code>syncing</code> Sync is currently in progress <code>ready</code> Data is available for queries <code>error</code> Last sync failed (error message available) <p>Additional status fields:</p> Field Description <code>sync_type</code> <code>\"full\"</code> or <code>\"incremental\"</code> \u2014 which mode the last sync used <code>last_incremental</code> Timestamp of last incremental sync (if applicable) <code>incremental_rows</code> Number of new rows added in the last incremental sync <code>truncated</code> <code>true</code> if the sync hit <code>max_sync_rows</code> \u2014 analytics run on partial data <code>watermarks</code> Per-sub-table watermark values (shown in <code>/api/store/status</code>) <code>refresh_interval_minutes</code> Configured periodic refresh interval <code>incremental_column</code> Column used for watermark-based incremental sync"},{"location":"architecture/frontend/","title":"Frontend Architecture","text":"<p>The AXIS frontend is a Next.js 14 application using the App Router, TypeScript, Tailwind CSS, Zustand for state management, and React Query for server data. Charts are rendered with Plotly.js and D3.js.</p>"},{"location":"architecture/frontend/#app-router-pages","title":"App Router Pages","text":"<p>Each route in <code>src/app/</code> maps to a page in the application. All pages are client-rendered (<code>'use client'</code>) since they depend on interactive state.</p> <pre><code>src/app/\n\u251c\u2500\u2500 page.tsx                # Home / landing page\n\u251c\u2500\u2500 layout.tsx              # Root layout (Providers + Sidebar)\n\u251c\u2500\u2500 globals.css             # Global styles and CSS animations\n\u251c\u2500\u2500 evaluate/page.tsx       # Evaluation workflow (upload, visualize, compare)\n\u251c\u2500\u2500 comparison/page.tsx     # Multi-experiment comparison\n\u251c\u2500\u2500 annotation-studio/page.tsx  # Human annotation interface\n\u251c\u2500\u2500 caliber-hq/page.tsx     # LLM judge calibration\n\u251c\u2500\u2500 monitoring/page.tsx     # Real-time performance monitoring\n\u251c\u2500\u2500 production/page.tsx     # Production overview with KPIs\n\u251c\u2500\u2500 human-signals/page.tsx  # Human-in-the-loop signals dashboard\n\u251c\u2500\u2500 memory/page.tsx         # Memory rules and knowledge graph\n\u251c\u2500\u2500 simulation/page.tsx     # Persona-based simulation\n\u251c\u2500\u2500 synthetic/page.tsx      # Synthetic data generation\n\u251c\u2500\u2500 learn/page.tsx          # Learning resources and walkthroughs\n\u251c\u2500\u2500 settings/page.tsx       # Application settings\n\u2514\u2500\u2500 (runner)/               # Evaluation runner (route group)\n    \u2514\u2500\u2500 run-eval/page.tsx\n</code></pre>"},{"location":"architecture/frontend/#root-layout","title":"Root Layout","text":"<p><code>layout.tsx</code> wraps the application with:</p> <ul> <li>Providers: React Query client, theme provider</li> <li>Sidebar: Navigation component</li> <li>Data initializers: Components that auto-load data from configured databases on mount</li> </ul> <pre><code>// Simplified layout.tsx\nexport default function RootLayout({ children }) {\n  return (\n    &lt;html&gt;\n      &lt;body&gt;\n        &lt;Providers&gt;\n          &lt;Sidebar /&gt;\n          &lt;main&gt;{children}&lt;/main&gt;\n          &lt;EvalDataInitializer /&gt;\n          &lt;HumanSignalsDataInitializer /&gt;\n          &lt;MonitoringDataInitializer /&gt;\n        &lt;/Providers&gt;\n      &lt;/body&gt;\n    &lt;/html&gt;\n  );\n}\n</code></pre>"},{"location":"architecture/frontend/#component-organization","title":"Component Organization","text":"<p>Components are organized by feature under <code>src/components/</code>:</p> <pre><code>src/components/\n\u251c\u2500\u2500 align/                  # LLM judge alignment components\n\u2502   \u251c\u2500\u2500 analyze/            #   Analysis panels (LearningInsightsPanel)\n\u251c\u2500\u2500 annotation/             # Annotation studio interface\n\u251c\u2500\u2500 charts/                 # Plotly chart wrappers\n\u2502   \u251c\u2500\u2500 plotly-chart.tsx    #   Base PlotlyChart component\n\u2502   \u251c\u2500\u2500 violin-chart.tsx\n\u2502   \u251c\u2500\u2500 radar-chart.tsx\n\u2502   \u2514\u2500\u2500 ...\n\u251c\u2500\u2500 copilot/                # AI copilot sidebar\n\u251c\u2500\u2500 database/               # Database connection wizard\n\u251c\u2500\u2500 eval-runner/            # Evaluation runner workflow\n\u251c\u2500\u2500 evaluate/               # Evaluation page components\n\u2502   \u251c\u2500\u2500 compare/            #   Comparison charts and tables\n\u2502   \u2514\u2500\u2500 visualize/          #   Visualization tabs\n\u2502       \u2514\u2500\u2500 scorecard/      #     Report modal, InsightPatternsPanel\n\u251c\u2500\u2500 human-signals/          # Human signals data-driven dashboard\n\u251c\u2500\u2500 learn/                  # Learning resources\n\u251c\u2500\u2500 memory/                 # Memory dashboard\n\u2502   \u2514\u2500\u2500 graph/              #   D3 knowledge graph\n\u251c\u2500\u2500 monitoring/             # Monitoring dashboard\n\u2502   \u2514\u2500\u2500 executive-summary/  #   Executive summary scorecard\n\u251c\u2500\u2500 production/             # Production overview components\n\u251c\u2500\u2500 shared/                 # Shared utilities\n\u251c\u2500\u2500 tree/                   # D3 tree visualization\n\u2514\u2500\u2500 ui/                     # Reusable UI primitives\n</code></pre>"},{"location":"architecture/frontend/#naming-conventions","title":"Naming Conventions","text":""},{"location":"architecture/frontend/#files","title":"Files","text":"Type Convention Example Components PascalCase <code>KPICard.tsx</code>, <code>DynamicFilters.tsx</code> Pages <code>page.tsx</code> <code>app/monitoring/page.tsx</code> Stores kebab-case <code>monitoring-store.ts</code> Utilities camelCase <code>signals-utils.ts</code>, <code>hooks.ts</code> Types <code>index.ts</code> <code>types/index.ts</code>"},{"location":"architecture/frontend/#exports","title":"Exports","text":"<p>Components use named exports (not default exports):</p> <pre><code>// Correct\nexport function KPICard({ label, value }: KPICardProps) { ... }\n\n// Avoid\nexport default function KPICard({ label, value }: KPICardProps) { ... }\n</code></pre> <p>Feature folders use barrel exports via <code>index.ts</code>:</p> <pre><code>// components/memory/index.ts\nexport { MemorySummaryStrip } from './MemorySummaryStrip';\nexport { RulesTab } from './RulesTab';\nexport { HardStopsTab } from './HardStopsTab';\n</code></pre>"},{"location":"architecture/frontend/#client-directive","title":"Client Directive","text":"<p>All interactive components must start with the <code>'use client'</code> directive:</p> <pre><code>'use client';\n\nimport { useState } from 'react';\n// ...\n</code></pre>"},{"location":"architecture/frontend/#import-patterns","title":"Import Patterns","text":"<p>AXIS uses the <code>@/</code> alias that maps to <code>src/</code>:</p> <pre><code>// External packages first\nimport { useState, useMemo } from 'react';\nimport { Activity, TrendingUp } from 'lucide-react';\n\n// Internal imports with @/ alias\nimport { useMonitoringStore, useUIStore } from '@/stores';\nimport { cn } from '@/lib/utils';\nimport { Columns, Thresholds, ChartColors } from '@/types';\n\n// Type-only imports\nimport type { MonitoringRecord, MetricCategory } from '@/types';\n\n// Relative imports last\nimport { SubComponent } from './SubComponent';\n</code></pre> <p>ESLint import order</p> <p>The project enforces <code>import/order</code> (external, then <code>@/</code>, then relative) and <code>import/no-duplicates</code> to prevent importing from the same module twice.</p>"},{"location":"architecture/frontend/#component-structure-pattern","title":"Component Structure Pattern","text":"<p>Components follow a consistent internal structure:</p> <pre><code>'use client';\n\nimport { useState, useMemo } from 'react';\nimport { useUIStore, useDataStore } from '@/stores';\nimport { cn } from '@/lib/utils';\n\ninterface ComponentNameProps {\n  prop1: string;\n  prop2?: number;\n  className?: string;\n}\n\nexport function ComponentName({ prop1, prop2 = 0, className }: ComponentNameProps) {\n  // 1. Store hooks\n  const { someState, someAction } = useUIStore();\n\n  // 2. Local state\n  const [localState, setLocalState] = useState(false);\n\n  // 3. Derived/memoized data\n  const computedValue = useMemo(() =&gt; {\n    return expensiveComputation(someState);\n  }, [someState]);\n\n  // 4. Event handlers\n  const handleClick = () =&gt; {\n    someAction();\n  };\n\n  // 5. Render\n  return (\n    &lt;div className={cn('base-classes', className)}&gt;\n      {/* JSX */}\n    &lt;/div&gt;\n  );\n}\n</code></pre>"},{"location":"architecture/frontend/#lib-utilities","title":"Lib Utilities","text":"<p>The <code>src/lib/</code> directory contains shared logic:</p> File Purpose <code>api.ts</code> Centralized <code>fetchApi&lt;T&gt;()</code> client and all API functions <code>hooks.ts</code> React Query hooks (mutations and queries) <code>utils.ts</code> <code>cn()</code> class merge, formatting helpers <code>sse.ts</code> Server-Sent Events streaming utilities <code>stats.ts</code> Statistical computation helpers <code>theme.ts</code> Theme color resolution <code>executive-summary-utils.ts</code> Monitoring hierarchy and health computation <code>scorecard-utils.ts</code> Production scorecard computations <code>signals-utils.ts</code> Human signals KPI and chart data computation <code>annotation-utils.ts</code> Annotation data helpers"},{"location":"architecture/frontend/#hooks-directory","title":"Hooks Directory","text":"<p>Custom hooks in <code>src/lib/hooks/</code>:</p> Hook Purpose <code>useHumanSignalsUpload.ts</code> Human signals file upload with store updates <code>useProductionOverview.ts</code> Aggregates data for production dashboard"},{"location":"architecture/frontend/#design-system-highlights","title":"Design System Highlights","text":""},{"location":"architecture/frontend/#color-palette","title":"Color Palette","text":"<p>The sage green palette is used throughout, with semantic status colors:</p> Token Hex Usage <code>primary</code> <code>#8B9F4F</code> Brand, active states <code>primary-light</code> <code>#A4B86C</code> Hover, secondary emphasis <code>primary-dark</code> <code>#6B7A3A</code> Pressed states <code>accent-gold</code> <code>#D4AF37</code> Warnings, highlights <code>accent-silver</code> <code>#B8C5D3</code> Neutral accents <code>success</code> <code>#27AE60</code> Pass, healthy <code>warning</code> <code>#F39C12</code> Caution, at-risk <code>error</code> <code>#E74C3C</code> Fail, critical"},{"location":"architecture/frontend/#key-ui-patterns","title":"Key UI Patterns","text":"<ul> <li>KPI strips: Compact inline cards with icon + value + label (not oversized stat cards)</li> <li>Chart containers: Bordered <code>div</code> with header bar (<code>border-b px-4 py-2</code>)</li> <li>Pagination: Inline pill-button controls, reset to page 1 on filter change</li> <li>Severity cards: White background with colored left border accent</li> <li>Scrollable columns: <code>max-h-[500px] overflow-y-auto</code> inside bordered containers</li> </ul>"},{"location":"architecture/frontend/#lint-and-format","title":"Lint and Format","text":"<p>Always run before committing:</p> <pre><code>npm run format &amp;&amp; npm run lint &amp;&amp; npx tsc --noEmit\n</code></pre>"},{"location":"architecture/plugin-system/","title":"Plugin System","text":"<p>AXIS uses a lightweight plugin system to organize feature modules as self-contained packages. Each plugin owns its routers, services, models, and config \u2014 the framework discovers and registers them automatically at startup. Removing a plugin is as simple as deleting its directory.</p>"},{"location":"architecture/plugin-system/#architecture","title":"Architecture","text":"<pre><code>graph TB\n    subgraph Core [\"Core (app/)\"]\n        MAIN[\"main.py\"]\n        CONFIG[\"config.py&lt;br/&gt;(Settings)\"]\n        LOADER[\"plugins/__init__.py&lt;br/&gt;(discover + register)\"]\n        TYPES[\"plugins/types.py&lt;br/&gt;(PluginMeta)\"]\n        CONFIG_ROUTER[\"routers/config.py&lt;br/&gt;GET /api/config/plugins\"]\n    end\n\n    subgraph PluginDir [\"plugins/memory/\"]\n        ENTRY[\"__init__.py&lt;br/&gt;PLUGIN_META + register()\"]\n        P_CONFIG[\"config.py&lt;br/&gt;(MemoryConfig)\"]\n        P_ROUTERS[\"routers/&lt;br/&gt;memory.py, graph.py\"]\n        P_SERVICES[\"services/&lt;br/&gt;memory_service.py, graph_service.py\"]\n        P_MODELS[\"models/&lt;br/&gt;memory_schemas.py, graph_schemas.py\"]\n    end\n\n    subgraph Frontend [\"Frontend\"]\n        SIDEBAR[\"sidebar.tsx&lt;br/&gt;(dynamic nav)\"]\n        HOOK[\"usePluginNav.ts&lt;br/&gt;GET /api/config/plugins\"]\n        PAGES[\"app/memory/page.tsx\"]\n        COMPONENTS[\"components/memory/\"]\n    end\n\n    MAIN --&gt;|\"startup\"| LOADER\n    LOADER --&gt;|\"pkgutil scan\"| ENTRY\n    LOADER --&gt;|\"validates\"| TYPES\n    ENTRY --&gt;|\"register(app)\"| P_ROUTERS\n    P_ROUTERS --&gt; P_SERVICES --&gt; P_MODELS\n    P_ROUTERS --&gt; P_CONFIG\n    P_CONFIG --&gt;|\"imports settings\"| CONFIG\n    CONFIG_ROUTER --&gt;|\"calls\"| LOADER\n\n    HOOK --&gt;|\"fetches\"| CONFIG_ROUTER\n    SIDEBAR --&gt;|\"reads\"| HOOK\n    PAGES --&gt; COMPONENTS</code></pre>"},{"location":"architecture/plugin-system/#plugin-contract","title":"Plugin Contract","text":"<p>Every plugin is a Python package inside <code>backend/app/plugins/</code>. The loader expects two things in the package's <code>__init__.py</code>:</p> Export Type Purpose <code>PLUGIN_META</code> <code>PluginMeta</code> Static metadata: name, version, nav items, OpenAPI tags <code>register(app)</code> <code>Callable[[FastAPI], None]</code> Registers routers on the FastAPI app instance <p>The module body should contain only these two items. All other imports happen inside <code>register()</code> to keep discovery cheap and side-effect-free.</p> plugins/memory/__init__.py<pre><code>from fastapi import FastAPI\n\nfrom app.plugins.types import PluginMeta, PluginNavItem, PluginTagMeta\n\nPLUGIN_META = PluginMeta(\n    name=\"memory\",\n    version=\"0.1.0\",\n    description=\"Decision memory rules, hard stops, and batch analysis\",\n    nav=[\n        PluginNavItem(name=\"Memory\", href=\"/memory\", icon=\"Brain\", section=\"main\", order=50),\n    ],\n    tags_metadata=[\n        PluginTagMeta(name=\"memory\", description=\"Decision memory rules and batch analysis\"),\n        PluginTagMeta(name=\"graph\", description=\"Knowledge graph queries (FalkorDB)\"),\n    ],\n)\n\ndef register(app: FastAPI) -&gt; None:\n    from .routers.graph import router as graph_router\n    from .routers.memory import router as memory_router\n\n    app.include_router(memory_router, prefix=\"/api/memory\", tags=[\"memory\"])\n    app.include_router(graph_router, prefix=\"/api/memory/graph\", tags=[\"graph\"])\n</code></pre>"},{"location":"architecture/plugin-system/#agent-replay-plugin","title":"Agent Replay Plugin","text":"<p>The Agent Replay plugin shows a more complex pattern \u2014 it integrates with an external service (Langfuse) and an optional search database:</p> plugins/agent_replay/__init__.py<pre><code>from fastapi import FastAPI\n\nfrom app.plugins.types import PluginMeta, PluginNavItem, PluginTagMeta\n\nPLUGIN_META = PluginMeta(\n    name=\"agent_replay\",\n    version=\"0.1.0\",\n    description=\"Step through AI agent workflows from Langfuse\",\n    nav=[\n        PluginNavItem(\n            name=\"Agent Replay\",\n            href=\"/agent-replay\",\n            icon=\"PlayCircle\",\n            section=\"main\",\n            order=45,\n        ),\n    ],\n    tags_metadata=[\n        PluginTagMeta(\n            name=\"agent-replay\",\n            description=\"Agent workflow replay from Langfuse traces\",\n        ),\n    ],\n)\n\ndef register(app: FastAPI) -&gt; None:\n    from .routers.replay import router as replay_router\n\n    app.include_router(replay_router, prefix=\"/api/agent-replay\", tags=[\"agent-replay\"])\n</code></pre> <pre><code>backend/app/plugins/\n\u2514\u2500\u2500 agent_replay/\n    \u251c\u2500\u2500 __init__.py              # PLUGIN_META + register()\n    \u251c\u2500\u2500 config.py                # ReplayConfig, ReplayDBConfig, LangfuseAgentCreds\n    \u251c\u2500\u2500 routers/\n    \u2502   \u2514\u2500\u2500 replay.py            # /api/agent-replay/* endpoints\n    \u251c\u2500\u2500 services/\n    \u2502   \u251c\u2500\u2500 replay_service.py    # Langfuse trace fetching, tree building\n    \u2502   \u2514\u2500\u2500 search_db.py         # PostgreSQL business-field \u2192 trace-ID lookup\n    \u2514\u2500\u2500 models/\n        \u2514\u2500\u2500 replay_schemas.py    # Pydantic request/response models\n</code></pre> <p>Key differences from the Memory plugin:</p> <ul> <li>External service dependency \u2014 Langfuse credentials are discovered from <code>LANGFUSE_*</code> env vars at config load time, not from YAML</li> <li>Optional database \u2014 The search DB (<code>agent_replay_db.yaml</code>) is optional; trace ID search works without it</li> <li>Per-agent overrides \u2014 Both Langfuse credentials and DB table/column mappings can vary per agent</li> </ul>"},{"location":"architecture/plugin-system/#metadata-models","title":"Metadata Models","text":"<p>Plugin metadata is defined as typed Pydantic models in <code>plugins/types.py</code>:</p> <pre><code>class PluginNavItem(BaseModel):\n    name: str           # Display name in sidebar\n    href: str           # Next.js route path\n    icon: str           # Lucide icon name (e.g. \"Brain\")\n    section: str        # \"main\" or \"tools\"\n    order: int = 50     # Sort key (lower = higher in list)\n\nclass PluginTagMeta(BaseModel):\n    name: str           # OpenAPI tag name\n    description: str = \"\"\n\nclass PluginMeta(BaseModel):\n    name: str\n    api_version: int = 1\n    version: str = \"0.1.0\"\n    description: str = \"\"\n    nav: list[PluginNavItem] = Field(default_factory=list)\n    tags_metadata: list[PluginTagMeta] = Field(default_factory=list)\n</code></pre> <p><code>api_version</code> allows the contract to evolve without silent breakage. <code>nav</code> and <code>tags_metadata</code> use <code>Field(default_factory=list)</code> to avoid the mutable default footgun.</p>"},{"location":"architecture/plugin-system/#discovery-and-registration","title":"Discovery and Registration","text":"<p>The plugin loader in <code>plugins/__init__.py</code> uses <code>pkgutil.iter_modules</code> to scan subdirectories. Discovery is deterministic \u2014 module names are sorted alphabetically before importing.</p> <pre><code>sequenceDiagram\n    participant Main as main.py\n    participant Loader as plugins/__init__\n    participant Plugin as plugins/memory\n\n    Main-&gt;&gt;Loader: register_all(app)\n    Loader-&gt;&gt;Loader: discover_plugins() [cached]\n    loop Each subdirectory (sorted)\n        Loader-&gt;&gt;Plugin: importlib.import_module()\n        Plugin--&gt;&gt;Loader: PLUGIN_META + register\n        Loader-&gt;&gt;Loader: Validate PluginMeta, check callable(register)\n    end\n    loop Each enabled plugin\n        Loader-&gt;&gt;Plugin: register(app)\n        Plugin-&gt;&gt;Plugin: include_router(...)\n    end\n    Loader-&gt;&gt;Loader: Cache result (atomic assign)</code></pre>"},{"location":"architecture/plugin-system/#failure-isolation","title":"Failure Isolation","text":"<p>Each plugin's discovery and <code>register()</code> call is individually wrapped in <code>try/except</code>. A broken plugin logs <code>logger.error(...)</code> and is skipped \u2014 the app still starts. The error surfaces in the <code>/api/config/plugins</code> endpoint.</p>"},{"location":"architecture/plugin-system/#conflict-policy","title":"Conflict Policy","text":"<ul> <li>OpenAPI tags: Deduplicated by <code>name</code>, first wins (core tags before plugin tags, plugins in alphabetical order). Sorted by name for stable output.</li> <li>Nav items: Deduplicated by <code>href</code>, first wins. Sorted by <code>(order, name)</code>.</li> </ul>"},{"location":"architecture/plugin-system/#enable-disable","title":"Enable / Disable","text":"<p>The <code>AXIS_PLUGINS_ENABLED</code> setting in <code>app/config.py</code> controls which plugins are active:</p> Value Effect <code>\"*\"</code> (default) All discovered plugins are enabled <code>\"memory,other\"</code> Only named plugins are enabled <code>\"\"</code> (empty) All plugins disabled <p>Disabled plugins are still listed in <code>/api/config/plugins</code> with <code>enabled: false</code> but their <code>register()</code> is never called.</p> <p>Set it via environment variable or in the Settings class:</p> <pre><code>AXIS_PLUGINS_ENABLED=\"memory\" uvicorn app.main:app\n</code></pre>"},{"location":"architecture/plugin-system/#plugin-directory-structure","title":"Plugin Directory Structure","text":"<pre><code>backend/app/plugins/\n\u251c\u2500\u2500 __init__.py                  # Plugin loader (discover, register, tags, nav)\n\u251c\u2500\u2500 types.py                     # PluginMeta, PluginNavItem, PluginTagMeta\n\u2514\u2500\u2500 memory/\n    \u251c\u2500\u2500 __init__.py              # PLUGIN_META + register()\n    \u251c\u2500\u2500 config.py                # MemoryConfig, MemoryFieldRoles, load_memory_config()\n    \u251c\u2500\u2500 routers/\n    \u2502   \u251c\u2500\u2500 __init__.py\n    \u2502   \u251c\u2500\u2500 memory.py            # /api/memory/* endpoints\n    \u2502   \u2514\u2500\u2500 graph.py             # /api/memory/graph/* endpoints\n    \u251c\u2500\u2500 services/\n    \u2502   \u251c\u2500\u2500 __init__.py\n    \u2502   \u251c\u2500\u2500 memory_service.py    # Rule parsing, CSV loading, CRUD\n    \u2502   \u2514\u2500\u2500 graph_service.py     # FalkorDB graph queries\n    \u2514\u2500\u2500 models/\n        \u251c\u2500\u2500 __init__.py\n        \u251c\u2500\u2500 memory_schemas.py    # Memory Pydantic schemas\n        \u2514\u2500\u2500 graph_schemas.py     # Graph Pydantic schemas\n</code></pre>"},{"location":"architecture/plugin-system/#api-endpoint","title":"API Endpoint","text":"<p><code>GET /api/config/plugins</code> returns all discovered plugins (including disabled ones):</p> <pre><code>{\n  \"plugins\": [\n    {\n      \"name\": \"memory\",\n      \"version\": \"0.1.0\",\n      \"api_version\": 1,\n      \"description\": \"Decision memory rules, hard stops, and batch analysis\",\n      \"nav\": [\n        {\n          \"name\": \"Memory\",\n          \"href\": \"/memory\",\n          \"icon\": \"Brain\",\n          \"section\": \"main\",\n          \"order\": 50\n        }\n      ],\n      \"enabled\": true,\n      \"error\": null\n    }\n  ]\n}\n</code></pre> <p>The <code>error</code> field is <code>null</code> for healthy plugins or a string describing the failure (e.g., <code>\"no PLUGIN_META\"</code>, <code>\"register failed\"</code>).</p>"},{"location":"architecture/plugin-system/#frontend-integration","title":"Frontend Integration","text":""},{"location":"architecture/plugin-system/#dynamic-sidebar","title":"Dynamic Sidebar","text":"<p>The sidebar fetches plugin data via the <code>usePluginNav</code> hook and merges plugin nav items into the navigation:</p> <pre><code>const { data: pluginData } = usePluginNav();\n\nconst pluginMainNav = (pluginData?.plugins ?? [])\n  .filter((p) =&gt; p.enabled)\n  .flatMap((p) =&gt; p.nav)\n  .filter((n) =&gt; n.section === 'main')\n  .map((n) =&gt; ({ name: n.name, href: n.href, icon: resolveIcon(n.icon) }));\n\nconst mainNav = [...coreMainNav, ...pluginMainNav];\n</code></pre>"},{"location":"architecture/plugin-system/#icon-resolution","title":"Icon Resolution","text":"<p>A <code>Record&lt;string, LucideIcon&gt;</code> maps icon names from the plugin API to Lucide components. Unknown names fall back to <code>LayoutGrid</code> and log a warning in development:</p> <pre><code>const iconMap: Record&lt;string, LucideIcon&gt; = { Brain };\n\nconst resolveIcon = (name: string): LucideIcon =&gt; {\n  const icon = iconMap[name];\n  if (!icon &amp;&amp; process.env.NODE_ENV === 'development') {\n    console.warn(`[plugins] Unknown icon \"${name}\", using fallback`);\n  }\n  return icon ?? LayoutGrid;\n};\n</code></pre> <p>Add new icon mappings to <code>iconMap</code> as plugins are created.</p>"},{"location":"architecture/plugin-system/#hydration-safety","title":"Hydration Safety","text":"<p>The plugin query is prefetched on <code>QueryClient</code> creation in <code>providers.tsx</code> with <code>staleTime: Infinity</code>. This means the sidebar usually has plugin data on first render. If the API is slow, core nav renders immediately and plugin items appear when ready.</p>"},{"location":"architecture/plugin-system/#creating-a-new-plugin","title":"Creating a New Plugin","text":"<ol> <li> <p>Create a package directory under <code>backend/app/plugins/</code>:</p> <pre><code>plugins/my_feature/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 routers/\n\u2502   \u2514\u2500\u2500 __init__.py\n\u251c\u2500\u2500 services/\n\u2502   \u2514\u2500\u2500 __init__.py\n\u2514\u2500\u2500 models/\n    \u2514\u2500\u2500 __init__.py\n</code></pre> </li> <li> <p>Define <code>PLUGIN_META</code> and <code>register()</code> in <code>__init__.py</code>:</p> <pre><code>from fastapi import FastAPI\nfrom app.plugins.types import PluginMeta, PluginNavItem, PluginTagMeta\n\nPLUGIN_META = PluginMeta(\n    name=\"my_feature\",\n    version=\"0.1.0\",\n    description=\"What this plugin does\",\n    nav=[PluginNavItem(name=\"My Feature\", href=\"/my-feature\", icon=\"Sparkles\", section=\"tools\", order=60)],\n    tags_metadata=[PluginTagMeta(name=\"my-feature\", description=\"My feature endpoints\")],\n)\n\ndef register(app: FastAPI) -&gt; None:\n    from .routers.my_router import router\n    app.include_router(router, prefix=\"/api/my-feature\", tags=[\"my-feature\"])\n</code></pre> </li> <li> <p>Add the icon name to <code>iconMap</code> in <code>sidebar.tsx</code>:</p> <pre><code>import { Brain, Sparkles } from 'lucide-react';\nconst iconMap: Record&lt;string, LucideIcon&gt; = { Brain, Sparkles };\n</code></pre> </li> <li> <p>Create the Next.js page at <code>frontend/src/app/my-feature/page.tsx</code>.</p> </li> <li> <p>Restart the backend \u2014 the plugin is automatically discovered and registered.</p> </li> </ol>"},{"location":"architecture/plugin-system/#key-design-decisions","title":"Key Design Decisions","text":""},{"location":"architecture/plugin-system/#why-not-entry-points-setuptools","title":"Why Not Entry Points / setuptools?","text":"<p>Entry points (<code>pkg_resources</code> / <code>importlib.metadata</code>) are designed for installed third-party packages. AXIS plugins are first-party code in the same repo \u2014 <code>pkgutil.iter_modules</code> is simpler, faster, and requires no packaging machinery.</p>"},{"location":"architecture/plugin-system/#why-module-level-cache","title":"Why Module-Level Cache?","text":"<p><code>discover_plugins()</code> caches its result after first call. Plugin discovery involves importing every plugin module and validating metadata, which should only happen once. The cache is assigned atomically (single <code>=</code> statement) to avoid partial population under concurrency.</p>"},{"location":"architecture/plugin-system/#why-deprecation-proxy-instead-of-redirect","title":"Why Deprecation Proxy Instead of Redirect?","text":"<p>When the <code>/api/config/memory</code> endpoint moved to <code>/api/memory/config</code>, a deprecation proxy was added instead of a 307 redirect. Some HTTP clients and scripts don't follow redirects by default. The proxy returns the same JSON payload plus deprecation headers (<code>Deprecation: true</code>, <code>Sunset</code>, <code>Link</code>) and an extra <code>_deprecated</code> field in the body.</p>"},{"location":"architecture/state-management/","title":"State Management","text":"<p>The AXIS frontend uses Zustand for client-side state and React Query (TanStack Query) for server-side data fetching. These two layers serve different purposes and interact through a predictable pattern.</p>"},{"location":"architecture/state-management/#architecture-overview","title":"Architecture Overview","text":"<pre><code>graph TB\n    subgraph \"Server State (React Query)\"\n        RQ[useQuery / useMutation]\n        CACHE[(Query Cache)]\n        RQ --&gt; CACHE\n    end\n\n    subgraph \"Client State (Zustand)\"\n        UI[useUIStore]\n        DATA[useDataStore]\n        MON[useMonitoringStore]\n        MEM[useMemoryStore]\n        SIG[useHumanSignalsStore]\n        OTHER[\"useAnnotationStore&lt;br/&gt;useCalibrationStore&lt;br/&gt;useCopilotStore&lt;br/&gt;useDatabaseStore&lt;br/&gt;useEvalRunnerStore&lt;br/&gt;useThemeStore\"]\n    end\n\n    subgraph \"API Layer\"\n        API[\"fetchApi&amp;lt;T&amp;gt;()\"]\n    end\n\n    RQ -- \"onSuccess callback\" --&gt; DATA\n    RQ -- \"onSuccess callback\" --&gt; MON\n    RQ -- \"onSuccess callback\" --&gt; SIG\n    API --&gt; RQ\n    UI --&gt; |\"filters, selections\"| RQ</code></pre>"},{"location":"architecture/state-management/#zustand-stores","title":"Zustand Stores","text":"<p>All stores are barrel-exported from <code>src/stores/index.ts</code>:</p> <pre><code>export { useDataStore } from './data-store';\nexport { useUIStore } from './ui-store';\nexport { useAnnotationStore } from './annotation-store';\nexport { useCalibrationStore } from './calibration-store';\nexport { useCopilotStore } from './copilot-store';\nexport { useDatabaseStore } from './database-store';\nexport { useMonitoringStore } from './monitoring-store';\nexport { useEvalRunnerStore } from './eval-runner-store';\nexport { useThemeStore } from './theme-store';\nexport { useMemoryStore } from './memory-store';\nexport { useHumanSignalsStore } from './human-signals-store';\n</code></pre>"},{"location":"architecture/state-management/#store-creation-pattern","title":"Store Creation Pattern","text":"<p>All stores follow the same Zustand pattern:</p> <pre><code>import { create } from 'zustand';\nimport { persist } from 'zustand/middleware';  // optional\n\ninterface SomeState {\n  // State fields\n  data: SomeRecord[];\n  isLoading: boolean;\n  error: string | null;\n\n  // Actions\n  setData: (data: SomeRecord[]) =&gt; void;\n  setLoading: (loading: boolean) =&gt; void;\n  clearData: () =&gt; void;\n}\n\nexport const useSomeStore = create&lt;SomeState&gt;()((set) =&gt; ({\n  data: [],\n  isLoading: false,\n  error: null,\n\n  setData: (data) =&gt; set({ data, isLoading: false, error: null }),\n  setLoading: (isLoading) =&gt; set({ isLoading }),\n  clearData: () =&gt; set({ data: [], isLoading: false, error: null }),\n}));\n</code></pre> <p>Persist middleware</p> <p>Stores that hold UI preferences (like <code>ui-store</code> and <code>monitoring-store</code>) use Zustand's <code>persist</code> middleware to save state to <code>localStorage</code>. Data stores typically do not persist.</p>"},{"location":"architecture/state-management/#store-reference","title":"Store Reference","text":""},{"location":"architecture/state-management/#ui-store","title":"ui-store","text":"<p>The largest store, managing all UI preferences, filter selections, and modal state. Uses <code>persist</code> middleware.</p> State Group Key Fields Layout <code>sidebarCollapsed</code>, <code>copilotOpen</code>, <code>theme</code> Evaluation filters <code>selectedExperiment</code>, <code>selectedExperiments</code>, <code>selectedMetrics</code> Pagination <code>currentPage</code>, <code>itemsPerPage</code>, <code>viewMode</code> Tab state <code>visualizeSubTab</code>, <code>learnMainTab</code>, <code>compareChartType</code> Modals <code>testCaseDetailModalOpen</code>, <code>selectedCompareTestCaseId</code> Report config <code>reportMode</code>, <code>reportType</code>, <code>reportContextFields</code> Annotation config <code>annotationScoreMode</code>, <code>annotationFilter</code>, <code>customTags</code>"},{"location":"architecture/state-management/#data-store","title":"data-store","text":"<p>Manages evaluation data loaded from CSV uploads or database imports. Uses <code>persist</code>.</p> Field Type Description <code>data</code> <code>EvaluationRecord[]</code> Raw evaluation records <code>format</code> <code>DataFormat</code> Detected format type <code>columns</code> <code>string[]</code> All column names <code>metricColumns</code> <code>string[]</code> Columns containing numeric metrics <code>componentColumns</code> <code>string[]</code> Component-level metric columns <code>summary</code> <code>MetricSummary[]</code> Computed metric statistics <code>isLoading</code> <code>boolean</code> Upload in progress <code>error</code> <code>string \\| null</code> Error message"},{"location":"architecture/state-management/#monitoring-store","title":"monitoring-store","text":"<p>Manages monitoring/observability data with time-series filtering. Uses <code>persist</code>.</p> Field Type Description <code>data</code> <code>MonitoringRecord[]</code> Raw monitoring records <code>format</code> <code>'monitoring' \\| null</code> Always <code>'monitoring'</code> when loaded <code>metricColumns</code> <code>string[]</code> <code>['metric_score']</code> for long format <code>timeRange</code> <code>MonitoringTimeRange</code> Active time range with presets <code>selectedEnvironment</code> <code>string</code> Filter by environment <code>selectedSourceName</code> <code>string</code> Filter by source system <code>selectedSourceComponent</code> <code>string</code> Filter by component <code>selectedSourceType</code> <code>string</code> Filter by source type <code>activeMetricTab</code> <code>MetricCategoryTab</code> Active tab (score, classification, analysis) <code>chartGranularity</code> <code>MonitoringChartGranularity</code> Hourly, daily, or weekly <p>Time range presets: <code>1h</code>, <code>6h</code>, <code>24h</code>, <code>7d</code>, <code>30d</code>, <code>custom</code>.</p>"},{"location":"architecture/state-management/#memory-store","title":"memory-store","text":"<p>Manages memory rule data for the Memory dashboard. Does not persist.</p> Field Type Description <code>data</code> <code>MemoryRuleRecord[]</code> Loaded memory rules <code>summary</code> <code>MemorySummary</code> Aggregate counts <code>filtersAvailable</code> <code>MemoryFiltersAvailable</code> Unique filter values <code>activeTab</code> <code>MemoryTab</code> Active tab (rules, quality, hard-stops, batches, knowledge-graph) <code>filters</code> <code>MemoryFilters</code> Active filter selections <code>graphSearchQuery</code> <code>string</code> Knowledge graph search input <code>selectedNodeId</code> <code>string \\| null</code> Selected graph node"},{"location":"architecture/state-management/#human-signals-store","title":"human-signals-store","text":"<p>Manages Human Signals (HITL) data. Uses <code>persist</code>.</p> Field Type Description <code>cases</code> <code>SignalsCaseRecord[]</code> Case records <code>format</code> <code>SignalsDataFormat</code> <code>'hitl_feedback_v2'</code> <code>metricSchema</code> <code>SignalsMetricSchema</code> Auto-discovered metric schema <code>displayConfig</code> <code>SignalsDisplayConfig</code> YAML-driven display layout <code>selectedSourceName</code> <code>string</code> Source filter <code>selectedMetricFilters</code> <code>Record&lt;string, string&gt;</code> Per-metric signal filters <code>timeRange</code> <code>SignalsTimeRange</code> Time range with presets <p>Time range presets: <code>7d</code>, <code>30d</code>, <code>90d</code>, <code>6m</code>, <code>1y</code>, <code>custom</code>.</p>"},{"location":"architecture/state-management/#other-stores","title":"Other Stores","text":"Store Purpose <code>annotation-store</code> Human annotation scores, tags, and undo history <code>calibration-store</code> LLM judge calibration state <code>copilot-store</code> AI copilot messages and thought stream <code>database-store</code> Database connection wizard step state <code>eval-runner-store</code> Evaluation runner workflow state and progress <code>theme-store</code> Active theme palette loaded from backend"},{"location":"architecture/state-management/#react-query-hooks","title":"React Query Hooks","text":"<p>React Query hooks live in <code>src/lib/hooks.ts</code> and wrap API calls from <code>src/lib/api.ts</code>. They handle loading states, caching, and store updates.</p>"},{"location":"architecture/state-management/#mutation-pattern-uploads","title":"Mutation Pattern (Uploads)","text":"<p>Mutations are used for data uploads and actions that modify server state:</p> <pre><code>export function useUploadFile() {\n  const queryClient = useQueryClient();\n  const { setData, setLoading, setError } = useDataStore();\n\n  return useMutation({\n    mutationFn: api.uploadFile,\n    onMutate: () =&gt; {\n      setLoading(true);\n    },\n    onSuccess: (response) =&gt; {\n      setData(\n        response.data as EvaluationRecord[],\n        response.format as DataFormat,\n        response.columns\n      );\n      queryClient.invalidateQueries({ queryKey: ['summary'] });\n    },\n    onError: (error) =&gt; {\n      setError(error.message);\n    },\n    onSettled: () =&gt; {\n      setLoading(false);\n    },\n  });\n}\n</code></pre> <p>Key points:</p> <ol> <li><code>onMutate</code> sets the loading state in the Zustand store</li> <li><code>onSuccess</code> populates the store with response data</li> <li>Related queries are invalidated to trigger refetches</li> <li><code>onSettled</code> clears loading regardless of outcome</li> </ol>"},{"location":"architecture/state-management/#query-pattern-analytics","title":"Query Pattern (Analytics)","text":"<p>Queries are used for derived computations that depend on uploaded data:</p> <pre><code>export function useSummaryStats(data: EvaluationRecord[]) {\n  return useQuery({\n    queryKey: ['summary', data.length],\n    queryFn: () =&gt; api.getSummaryStats(data),\n    enabled: data.length &gt; 0,  // Only fetch when data exists\n  });\n}\n</code></pre> <p>Key points:</p> <ol> <li><code>queryKey</code> includes data length for cache invalidation</li> <li><code>enabled</code> prevents unnecessary fetches when no data is loaded</li> <li>The query sends data to the backend for server-side computation</li> </ol>"},{"location":"architecture/state-management/#fetchapi-client","title":"fetchApi Client","text":"<p>The centralized API client in <code>src/lib/api.ts</code>:</p> <pre><code>const API_BASE_URL = process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8500';\n\nasync function fetchApi&lt;T&gt;(endpoint: string, options: RequestInit = {}): Promise&lt;T&gt; {\n  const url = `${API_BASE_URL}${endpoint}`;\n\n  const response = await fetch(url, {\n    ...options,\n    headers: {\n      'Content-Type': 'application/json',\n      ...options.headers,\n    },\n  });\n\n  if (!response.ok) {\n    const error = await response.json().catch(() =&gt; ({}));\n    throw new Error(error.detail || `API error: ${response.status}`);\n  }\n\n  return response.json();\n}\n</code></pre> <p>Features:</p> <ul> <li>Generic type parameter <code>&lt;T&gt;</code> for typed responses</li> <li>Automatic JSON headers on all requests</li> <li>Error extraction from FastAPI's <code>{ \"detail\": \"...\" }</code> format</li> <li>Connection error handling with helpful message when backend is unreachable</li> </ul>"},{"location":"architecture/state-management/#file-uploads","title":"File Uploads","text":"<p>File uploads bypass <code>fetchApi</code> because they use <code>FormData</code> instead of JSON:</p> <pre><code>export async function uploadFile(file: File): Promise&lt;UploadResponse&gt; {\n  const formData = new FormData();\n  formData.append('file', file);\n\n  const response = await fetch(`${API_BASE_URL}/api/data/upload`, {\n    method: 'POST',\n    body: formData,\n    // No Content-Type header -- browser sets multipart boundary\n  });\n\n  if (!response.ok) {\n    const error = await response.json().catch(() =&gt; ({}));\n    throw new Error(error.detail || 'Upload failed');\n  }\n\n  return response.json();\n}\n</code></pre>"},{"location":"architecture/state-management/#data-flow-upload-to-dashboard","title":"Data Flow: Upload to Dashboard","text":"<p>Here is the complete flow when a user uploads a monitoring CSV:</p> <pre><code>sequenceDiagram\n    participant U as User\n    participant Page as monitoring/page.tsx\n    participant Hook as useUploadFile hook\n    participant API as api.ts\n    participant Backend as FastAPI\n    participant Store as monitoringStore\n\n    U-&gt;&gt;Page: Drop CSV file\n    Page-&gt;&gt;Hook: mutate(file)\n    Hook-&gt;&gt;Store: setLoading(true)\n    Hook-&gt;&gt;API: uploadMonitoringFile(file)\n    API-&gt;&gt;Backend: POST /api/monitoring/upload\n    Backend-&gt;&gt;Backend: Detect format, normalize columns\n    Backend--&gt;&gt;API: { data, columns, metric_columns }\n    API--&gt;&gt;Hook: Response\n    Hook-&gt;&gt;Store: setData(data, columns, metricColumns)\n    Store-&gt;&gt;Store: Extract available filters\n    Store-&gt;&gt;Store: Calculate time range from data\n    Hook-&gt;&gt;Store: setLoading(false)\n    Store--&gt;&gt;Page: Re-render with data\n    Page-&gt;&gt;Page: Show dashboard charts</code></pre>"},{"location":"architecture/state-management/#store-interaction-patterns","title":"Store Interaction Patterns","text":""},{"location":"architecture/state-management/#cross-store-reads","title":"Cross-Store Reads","text":"<p>Components can read from multiple stores simultaneously:</p> <pre><code>export function ProductionPage() {\n  const { data: evalData } = useDataStore();\n  const { data: monitoringData } = useMonitoringStore();\n  const { cases: signalsCases } = useHumanSignalsStore();\n  // Combine data from all stores for the production overview\n}\n</code></pre>"},{"location":"architecture/state-management/#filter-driven-re-renders","title":"Filter-Driven Re-renders","text":"<p>Monitoring filters in the store drive chart re-computation:</p> <pre><code>export function TrendsChart() {\n  const { data, selectedEnvironment, selectedSourceName, chartGranularity }\n    = useMonitoringStore();\n\n  const filteredData = useMemo(() =&gt; {\n    return data.filter(r =&gt;\n      (!selectedEnvironment || r.environment === selectedEnvironment) &amp;&amp;\n      (!selectedSourceName || r.source_name === selectedSourceName)\n    );\n  }, [data, selectedEnvironment, selectedSourceName]);\n\n  // Pass filteredData to chart rendering\n}\n</code></pre>"},{"location":"architecture/state-management/#pagination-reset-pattern","title":"Pagination Reset Pattern","text":"<p>Stores that support filtering reset pagination when filters change:</p> <pre><code>useEffect(() =&gt; {\n  setCurrentPage(1);\n}, [filters.action, filters.product_type, filters.risk_category]);\n</code></pre> <p>This ensures users always see page 1 when filter criteria change.</p>"},{"location":"configuration/","title":"Configuration","text":"<p>AXIS is configured through a layered system of YAML files, environment variables, and sensible defaults. This section covers every configuration surface in the platform.</p>"},{"location":"configuration/#configuration-sources","title":"Configuration Sources","text":"<p>AXIS reads configuration from three layers, evaluated in a specific order:</p> Layer Location Purpose Defaults <code>backend/app/config.py</code> Hardcoded fallbacks for every setting Environment variables <code>backend/.env</code> Server, AI, database, and theme overrides YAML config files <code>custom/config/*.yaml</code> Database auto-load and theme palettes"},{"location":"configuration/#precedence-rules","title":"Precedence Rules","text":"<p>The resolution order depends on the configuration category:</p> Database configsTheme config <p>YAML files take precedence over environment variables. If a YAML file exists and contains a valid configuration block, environment variables for that database are ignored entirely.</p> <pre><code>YAML file (highest) --&gt; env vars --&gt; defaults (lowest)\n</code></pre> <p>For example, if <code>custom/config/eval_db.yaml</code> exists with <code>eval_db.enabled: true</code>, then <code>EVAL_DB_HOST</code>, <code>EVAL_DB_URL</code>, etc. in <code>.env</code> are not read.</p> <p>The YAML file is loaded first, then individual <code>AXIS_THEME_*</code> environment variables override specific values within the active palette. This allows you to define a full palette in YAML and tweak one color via an env var.</p> <pre><code>defaults --&gt; YAML file (base) --&gt; env vars (override individual values)\n</code></pre> <p>YAML files must be created manually</p> <p>The <code>backend/config/</code> directory ships with <code>.example</code> templates only. Run <code>make setup</code> to create the <code>custom/</code> directory and copy all templates:</p> <pre><code>make setup\n</code></pre> <p>Or copy them individually:</p> <pre><code>cp backend/config/eval_db.yaml.example custom/config/eval_db.yaml\ncp backend/config/monitoring_db.yaml.example custom/config/monitoring_db.yaml\ncp backend/config/human_signals_db.yaml.example custom/config/human_signals_db.yaml\ncp backend/config/kpi_db.yaml.example custom/config/kpi_db.yaml\ncp backend/config/agent_replay_db.yaml.example custom/config/agent_replay_db.yaml\ncp backend/config/theme.yaml.example custom/config/theme.yaml\ncp backend/config/agents.yaml.example custom/config/agents.yaml\ncp backend/config/signals_metrics.yaml.example custom/config/signals_metrics.yaml\ncp backend/config/duckdb.yaml.example custom/config/duckdb.yaml\ncp backend/config/memory.yaml.example custom/config/memory.yaml\n</code></pre>"},{"location":"configuration/#quick-reference","title":"Quick Reference","text":"What you want to configure Where to look Server host, port, CORS Environment Variables OpenAI / Anthropic API keys Environment Variables Database auto-load (eval, monitoring, human signals, KPI) YAML Configs CSV upload vs. Postgres ingestion Data Sources Colors, logo, hero image, favicon Theming App name, tagline, branding text Customization Agent registry (names, avatars) Customization Agent Replay (Langfuse, search DB) YAML Configs Multi-agent teams (per-agent overrides) Multi-Agent Teams KPI display (card values, trend lines) YAML Configs Signals dashboard layout Customization DuckDB analytics store DuckDB Memory module field mappings YAML Configs Frontend API URL Environment Variables"},{"location":"configuration/#file-layout","title":"File Layout","text":"<pre><code>backend/\n  .env                              # Environment variables (git-ignored)\n  config/\n    eval_db.yaml.example            # Evaluation DB template (tracked)\n    monitoring_db.yaml.example      # Monitoring DB template (tracked)\n    human_signals_db.yaml.example   # Human Signals DB template (tracked)\n    kpi_db.yaml.example             # KPI DB template (tracked)\n    agent_replay_db.yaml.example    # Agent Replay search DB template (tracked)\n    theme.yaml.example              # Theme + branding template (tracked)\n    agents.yaml.example             # Agent registry template (tracked)\n    signals_metrics.yaml.example    # Signals dashboard template (tracked)\n    duckdb.yaml.example             # DuckDB store template (tracked)\n    memory.yaml.example             # Memory module template (tracked)\ncustom/                             # All site-specific files (git-ignored)\n  config/\n    eval_db.yaml                    # Your eval DB config\n    monitoring_db.yaml              # Your monitoring DB config\n    human_signals_db.yaml           # Your human signals DB config\n    kpi_db.yaml                     # Your KPI DB config\n    agent_replay_db.yaml            # Your replay DB config\n    theme.yaml                      # Your theme config\n    agents.yaml                     # Your agents config\n    signals_metrics.yaml            # Your signals config\n    duckdb.yaml                     # Your DuckDB config\n    memory.yaml                     # Your memory config\n  agents/                           # Agent avatar images\n  branding/                         # Logo, hero, favicon, app icon\nfrontend/\n  .env.local                        # Frontend env vars (git-ignored)\n</code></pre>"},{"location":"configuration/#next-steps","title":"Next Steps","text":"<ul> <li> <p> Environment Variables</p> <p>Complete reference for backend and frontend env vars.</p> <p> Environment Variables</p> </li> <li> <p> YAML Configs</p> <p>Database auto-load and theme YAML file reference.</p> <p> YAML Configs</p> </li> <li> <p> Data Sources</p> <p>CSV upload vs. Postgres auto-load ingestion patterns.</p> <p> Data Sources</p> </li> <li> <p> Theming</p> <p>Color palettes, logos, and hero images.</p> <p> Theming</p> </li> <li> <p> Customization</p> <p>White-label branding, agent registry, and signals layout.</p> <p> Customization</p> </li> <li> <p> Multi-Agent Teams</p> <p>Per-agent credentials, KPI display, and trace lookup overrides.</p> <p> Multi-Agent Teams</p> </li> </ul>"},{"location":"configuration/customization/","title":"Customization","text":"<p>AXIS is designed to be cloned, branded, and deployed as your own AI evaluation platform. All site-specific configuration lives in the gitignored <code>custom/</code> directory \u2014 your customizations never pollute the repo.</p>"},{"location":"configuration/customization/#quick-start","title":"Quick Start","text":"<pre><code># Create custom/ directory and copy all .example templates\nmake setup\n</code></pre> <p>This creates the <code>custom/</code> directory structure and copies <code>.example</code> templates from <code>backend/config/</code> into <code>custom/config/</code> with sensible defaults. It also creates symlinks for frontend assets (<code>custom/branding/</code>, <code>custom/agents/</code>). The app runs out of the box without editing anything.</p> <p>Already have config files?</p> <p><code>make setup</code> is safe to re-run. It skips any files that already exist.</p>"},{"location":"configuration/customization/#what-can-be-customized","title":"What Can Be Customized","text":"Aspect Config File Section App name, tagline, subtitle <code>theme.yaml</code> Branding Color palette, hero image <code>theme.yaml</code> Theming Agent registry (names, avatars) <code>agents.yaml</code> Agents Signals dashboard layout <code>signals_metrics.yaml</code> Signals Display Evaluation DB connection <code>eval_db.yaml</code> YAML Configs Monitoring DB connection <code>monitoring_db.yaml</code> YAML Configs Human Signals DB connection <code>human_signals_db.yaml</code> YAML Configs KPI DB connection + display <code>kpi_db.yaml</code> YAML Configs Agent Replay search DB <code>agent_replay_db.yaml</code> YAML Configs Multi-agent teams <code>agents.yaml</code> + per-agent overrides Multi-Agent <p>All config files follow the same pattern:</p> <ol> <li>A <code>.example</code> template is tracked in git at <code>backend/config/</code></li> <li><code>make setup</code> copies it to <code>custom/config/</code> as an active <code>.yaml</code> file (gitignored)</li> <li>Edit the <code>.yaml</code> file in <code>custom/config/</code> to customize</li> <li>Restart the backend to apply changes</li> </ol>"},{"location":"configuration/customization/#config-load-order","title":"Config Load Order","text":"<p>AXIS resolves configuration in this order:</p> <pre><code>YAML file  \u2192  Environment variables  \u2192  Hardcoded defaults\n (highest)                                (lowest)\n</code></pre> <p>For theme settings specifically, YAML is loaded first as a base, then <code>AXIS_THEME_*</code> env vars override individual values. This lets you define a full palette in YAML and tweak one color at deploy time.</p>"},{"location":"configuration/customization/#config-strategy-for-custom-deployments","title":"Config Strategy for Custom Deployments","text":"<p>In the upstream AXIS repo, the entire <code>custom/</code> directory is gitignored \u2014 only <code>.example</code> templates in <code>backend/config/</code> are tracked. This prevents proprietary connection strings, agent names, and branding from leaking into the open-source repo.</p> <p>When you fork or clone AXIS for your own product, you have three options for managing config:</p>"},{"location":"configuration/customization/#option-a-commit-configs-directly-recommended-for-private-repos","title":"Option A: Commit configs directly (recommended for private repos)","text":"<p>If your fork is a private repository, remove the <code>custom/</code> directory from <code>.gitignore</code> and commit it. This is the simplest approach for internal teams.</p> <pre><code># In your fork's .gitignore, comment out or remove:\n# custom/\n\n# Then commit your configs\ngit add custom/\ngit commit -m \"Add project config files\"\n</code></pre>"},{"location":"configuration/customization/#option-b-keep-gitignored-inject-at-deploy-time","title":"Option B: Keep gitignored, inject at deploy time","text":"<p>Keep configs out of git and provide them through your deployment pipeline. Good for production environments with secrets management.</p> DockerEnvironment VariablesKubernetes <p>Mount the entire <code>custom/</code> directory or individual config files. The <code>AXIS_CUSTOM_DIR</code> env var controls where the backend looks for configs:</p> <pre><code>services:\n  backend:\n    environment:\n      AXIS_CUSTOM_DIR: /app/custom\n    volumes:\n      - ./my-configs:/app/custom/config\n</code></pre> <p>Override individual settings without YAML files at all:</p> <pre><code>AXIS_THEME_ACTIVE=my_palette\nEVAL_DB_HOST=db.internal\nEVAL_DB_NAME=evaluations\n</code></pre> <p>Use ConfigMaps or Secrets, mounting into the custom config directory:</p> <pre><code>env:\n  - name: AXIS_CUSTOM_DIR\n    value: /app/custom\nvolumeMounts:\n  - name: axis-config\n    mountPath: /app/custom/config\n</code></pre>"},{"location":"configuration/customization/#option-c-separate-config-repository","title":"Option C: Separate config repository","text":"<p>Some teams maintain a private config repo that gets merged or copied into the deployment artifact at build time. This keeps configs versioned without modifying the AXIS fork.</p> <p>See Repository Model for the full recommended 3-repo split (framework + use-case + deploy/platform).</p> <pre><code># At build/deploy time\ncp -r ../axis-config/custom/ custom/\n</code></pre> <p>Which option should I pick?</p> <ul> <li>Solo / small team, private repo \u2192 Option A (commit directly)</li> <li>Production with CI/CD and secrets \u2192 Option B (inject at deploy)</li> <li>Multiple environments or strict separation \u2192 Option C (config repo)</li> </ul>"},{"location":"configuration/customization/#branding","title":"Branding","text":"<p>The <code>branding</code> section in <code>theme.yaml</code> controls text shown throughout the application \u2014 the landing page, sidebar, and exported reports.</p> <p>Production best practice for image URLs</p> <p>In production, prefer backend asset proxy URLs: - <code>/api/config/assets/branding/&lt;file&gt;</code> - <code>/api/config/assets/agents/&lt;file&gt;</code></p> <p>This keeps frontend deploys independent from use-case asset files (Repo B). Plain <code>/branding/*</code> and <code>/agents/*</code> paths are mainly a local-dev convenience when assets are present in the frontend workspace.</p> custom/config/theme.yaml<pre><code>theme:\n  branding:\n    app_name: \"MyProduct\"\n    tagline: \"AI Quality Platform\"\n    subtitle: \"The AI Evaluation Studio\"\n    description: \"Intelligent Evaluation &amp; Analytics\"\n    report_footer: \"Report generated by MyProduct\"\n    docs_url: \"https://docs.myproduct.com/\"\n    footer_name: \"MyProduct Inc.\"\n    footer_icon: \"/api/config/assets/branding/my-footer-icon.png\"\n\n  active: \"sage_green\"\n  palettes:\n    # ... palette definitions\n</code></pre>"},{"location":"configuration/customization/#branding-fields","title":"Branding Fields","text":"Field Default Where it appears <code>app_name</code> <code>AXIS</code> Landing page title, sidebar brand name, image alt text <code>tagline</code> <code>AI Evaluation Platform</code> Landing page badge above the title <code>subtitle</code> <code>The AI Evaluation Studio</code> Landing page subtitle (gradient text) <code>description</code> <code>Agent X-ray Interface &amp; Statistics</code> Landing page acronym line <code>report_footer</code> <code>Report generated by AXIS AI Evaluation Platform</code> Exported comparison reports <code>docs_url</code> <code>https://ax-foundry.github.io/axis/</code> Documentation link in the UI <code>footer_name</code> (falls back to <code>app_name</code>) Footer brand name in the UI <code>footer_icon</code> -- Optional footer icon image path or URL"},{"location":"configuration/customization/#frontend-usage","title":"Frontend Usage","text":"<p>In frontend code, branding is accessed via the <code>useBranding()</code> hook:</p> <pre><code>import { useBranding } from '@/lib/theme';\n\nfunction MyComponent() {\n  const branding = useBranding();\n  return &lt;h1&gt;{branding.app_name}&lt;/h1&gt;;\n}\n</code></pre> <p>Never hardcode branding strings</p> <p>Always use <code>useBranding()</code> instead of writing <code>\"AXIS\"</code> directly in components. This ensures white-labeled deployments show the correct text everywhere.</p>"},{"location":"configuration/customization/#agents","title":"Agents","text":"<p>The agent registry defines the AI agents shown in the SourceSelector bar and throughout the dashboard. Each agent maps to a <code>source_name</code> value in your monitoring or signals data.</p>"},{"location":"configuration/customization/#configuration","title":"Configuration","text":"custom/config/agents.yaml<pre><code>agents:\n  - name: my_agent        # Must match source_name in data\n    label: \"My Agent\"      # Display name in the UI\n    role: \"Assistant\"      # Short description shown under the name\n    avatar: \"/api/config/assets/agents/my_agent.png\"  # Production-recommended path\n    description: \"Handles customer onboarding\"\n    biography: \"My Agent was built to streamline...\"\n    active: true\n    trace_names:           # Langfuse trace name aliases\n      - \"my_agent_v1\"\n      - \"my-agent-production\"\n</code></pre>"},{"location":"configuration/customization/#agent-fields","title":"Agent Fields","text":"Field Required Default Description <code>name</code> Yes -- Must exactly match the <code>source_name</code> value in your data <code>label</code> Yes -- Display name shown in the SourceSelector and dashboards <code>role</code> No -- Short role description shown below the agent name <code>avatar</code> No -- Path to avatar image (relative to web root; place files in <code>custom/agents/</code>). Supports PNG, JPG, ICO, SVG <code>description</code> No -- Short description shown in agent cards <code>biography</code> No -- Longer biography text shown in the \"Meet the Team\" modal on the landing page <code>active</code> No <code>true</code> Whether the agent is active. Inactive agents are hidden from the SourceSelector <code>trace_names</code> No <code>[]</code> List of Langfuse trace name aliases. Used by Agent Replay to match traces to this agent when the trace name differs from <code>name</code>"},{"location":"configuration/customization/#avatar-images","title":"Avatar Images","text":"<p>Place agent avatar images in <code>custom/agents/</code>:</p> <pre><code>custom/agents/\n  my_agent.png     \u2192 accessible at /agents/my_agent.png\n  other_agent.ico  \u2192 accessible at /agents/other_agent.ico\n</code></pre> <p><code>make setup</code> creates a symlink so that files in <code>custom/agents/</code> are served by Next.js at <code>/agents/</code>. The <code>custom/</code> directory is gitignored (avatars are site-specific).</p> <p>For production deployments with separate frontend/backend hosting, prefer:</p> <pre><code>avatar: \"/api/config/assets/agents/my_agent.png\"\n</code></pre> <p>This serves assets from the backend (using <code>AXIS_CUSTOM_DIR</code>) and avoids coupling frontend builds to branding/avatar file injection.</p> <p>Fallback behavior</p> <p>If an agent from the data doesn't have a matching entry in <code>agents.yaml</code>, it still appears in the SourceSelector with a generic bot icon and the raw <code>source_name</code> as the label.</p>"},{"location":"configuration/customization/#frontend-usage_1","title":"Frontend Usage","text":"<p>Agent configs are loaded from the backend API at startup. In code:</p> <pre><code>import { getAgentConfig, getAgentRegistry } from '@/config/agents';\n\n// Look up a specific agent\nconst agent = getAgentConfig('my_agent');\n\n// Get all registered agents\nconst allAgents = getAgentRegistry();\n</code></pre>"},{"location":"configuration/customization/#signals-display-config","title":"Signals Display Config","text":"<p>The <code>signals_metrics.yaml</code> file controls how the Human Signals V2 dashboard renders KPIs, charts, and colors. It overrides auto-discovered defaults with domain-specific preferences.</p> <p>Optional file</p> <p>If this file doesn't exist, the Signals dashboard auto-generates a layout from the data schema. The config file lets you customize what's highlighted.</p> custom/config/signals_metrics.yaml<pre><code>signals_metrics:\n  # KPI strip at the top of the dashboard\n  kpi_strip:\n    - metric: intervention_type\n      signal: is_stp\n      label: \"STP Rate\"\n      format: percent\n      icon: zap\n      highlight: true\n    - aggregate: total_cases\n      label: \"Total Cases\"\n      icon: database\n\n  # Chart sections with layout control\n  chart_sections:\n    - title: \"Outcome Distribution\"\n      layout: full              # full | grid_2 | grid_3\n      charts:\n        - metric: resolution_status\n          signal: final_status\n          type: stacked_bar     # bar | donut | horizontal_bar | stacked_bar | ranked_list | single_stat\n          title: \"Resolution Status\"\n\n    - title: \"Category Analysis\"\n      layout: grid_2\n      charts:\n        - metric: escalation_type\n          signal: escalation_type\n          type: donut\n          title: \"Escalation Breakdown\"\n        - metric: failed_step\n          signal: failed_step\n          type: horizontal_bar\n          title: \"Top Failure Modes\"\n\n  # Map signal values to specific colors\n  color_maps:\n    resolution_status__final_status:\n      approved: \"#8B9F4F\"\n      declined: \"#E74C3C\"\n      blocked: \"#C0392B\"\n\n  # Source filter dropdowns\n  source_filters:\n    - field: source_name\n      label: \"Source\"\n    - field: environment\n      label: \"Environment\"\n</code></pre>"},{"location":"configuration/customization/#kpi-strip-fields","title":"KPI Strip Fields","text":"Field Description <code>metric</code> Metric name from data (paired with <code>signal</code>) <code>signal</code> Signal key within the metric <code>aggregate</code> Built-in aggregate: <code>avg_message_count</code>, <code>total_cases</code> <code>label</code> Display label <code>format</code> <code>percent</code> or <code>number</code> <code>icon</code> Lucide icon name (e.g., <code>zap</code>, <code>target</code>, <code>database</code>) <code>highlight</code> <code>true</code> to visually emphasize this KPI"},{"location":"configuration/customization/#chart-types","title":"Chart Types","text":"Type Best for <code>bar</code> Comparing counts across categories <code>stacked_bar</code> Showing composition over categories <code>horizontal_bar</code> Ranked lists with long labels <code>donut</code> Proportional breakdowns <code>ranked_list</code> Top-N lists (e.g., feature requests) <code>single_stat</code> Single boolean/count metric"},{"location":"configuration/customization/#white-label-checklist","title":"White-Label Checklist","text":"<p>When deploying AXIS as a branded product:</p> <ul> <li> Run <code>make setup</code> to create the <code>custom/</code> directory and config files</li> <li> Edit <code>custom/config/theme.yaml</code> \u2014 set branding text and create a custom color palette</li> <li> Edit <code>custom/config/agents.yaml</code> \u2014 register your agents with names, roles, and avatars</li> <li> Place branding images in <code>custom/branding/</code> (served via <code>/api/config/assets/branding/</code>) and agent avatars in <code>custom/agents/</code></li> <li> Edit <code>custom/config/signals_metrics.yaml</code> \u2014 customize the Signals dashboard layout (if using)</li> <li> Configure database connections in <code>custom/config/*_db.yaml</code> files (if using auto-load)</li> <li> Set <code>AXIS_THEME_ACTIVE</code> to your custom palette name</li> <li> Restart the backend and verify the UI reflects your branding</li> </ul>"},{"location":"configuration/customization/#file-layout","title":"File Layout","text":"<pre><code>backend/\n  config/\n    theme.yaml.example              # Template (tracked in git)\n    agents.yaml.example             # Template (tracked in git)\n    signals_metrics.yaml.example    # Template (tracked in git)\n    eval_db.yaml.example            # Template (tracked in git)\n    monitoring_db.yaml.example      # Template (tracked in git)\n    human_signals_db.yaml.example   # Template (tracked in git)\n    kpi_db.yaml.example             # Template (tracked in git)\n    agent_replay_db.yaml.example    # Template (tracked in git)\n    duckdb.yaml.example             # Template (tracked in git)\n    memory.yaml.example             # Template (tracked in git)\ncustom/                             # All site-specific files (gitignored)\n  config/\n    theme.yaml                      # Your theme config\n    agents.yaml                     # Your agents config\n    signals_metrics.yaml            # Your signals config\n    eval_db.yaml                    # Your eval DB config\n    monitoring_db.yaml              # Your monitoring DB config\n    human_signals_db.yaml           # Your human signals DB config\n    kpi_db.yaml                     # Your KPI DB config\n    agent_replay_db.yaml            # Your replay DB config\n    duckdb.yaml                     # Your DuckDB config\n    memory.yaml                     # Your memory config\n  agents/                           # Agent avatar images\n    alpha_bot.png\n  branding/                         # Logo, hero, favicon, app icon\n    hero.jpg\n    logo.svg\n</code></pre>"},{"location":"configuration/customization/#related","title":"Related","text":"<ul> <li>Theming \u2014 detailed color palette and hero image configuration</li> <li>YAML Configs \u2014 database auto-load configuration</li> <li>Environment Variables \u2014 env var reference and overrides</li> </ul>"},{"location":"configuration/data-sources/","title":"Data Sources","text":"<p>AXIS supports two data ingestion patterns: CSV upload through the UI (the default) and Postgres auto-load via YAML configuration. You can use both at the same time -- each AXIS page (Evaluate, Monitoring, Human Signals) has its own data pipeline.</p>"},{"location":"configuration/data-sources/#at-a-glance","title":"At a Glance","text":"CSV Upload Postgres Auto-Load Setup effort None YAML config file per database Data freshness Manual -- upload when ready Automatic on startup + periodic incremental sync Best for Quick exploration, demos, ad-hoc analysis Production pipelines, recurring data Pages supported Evaluate, Monitoring, Human Signals Evaluate, Monitoring, Human Signals Analytics engine In-memory (per session) DuckDB embedded store (persistent)"},{"location":"configuration/data-sources/#option-1-csv-upload-default","title":"Option 1: CSV Upload (Default)","text":"<p>CSV upload requires no configuration. Start the backend and frontend, then drag-and-drop a CSV file through the UI.</p>"},{"location":"configuration/data-sources/#how-it-works","title":"How it works","text":"<ol> <li>Navigate to the target page (Evaluate, Monitoring, or Human Signals).</li> <li>Use the upload area to select or drag a CSV file.</li> <li>AXIS parses, validates, and normalizes the columns automatically.</li> <li>Data is held in memory for the duration of the session.</li> </ol>"},{"location":"configuration/data-sources/#column-normalization","title":"Column normalization","text":"<p>AXIS auto-maps common column name variations to its internal schema. For example:</p> Your column name AXIS maps it to <code>id</code>, <code>record_id</code> <code>dataset_id</code> <code>input</code>, <code>prompt</code>, <code>question</code> <code>query</code> <code>output</code>, <code>response</code>, <code>completion</code> <code>actual_output</code> <code>expected</code>, <code>ground_truth</code>, <code>reference</code> <code>expected_output</code> <code>time</code>, <code>created_at</code> <code>timestamp</code> <code>model</code>, <code>agent</code> <code>model_name</code> <code>score</code>, <code>metric_value</code> <code>metric_score</code> <code>metric</code> <code>metric_name</code> <p>No pre-processing needed</p> <p>In most cases you can export directly from your evaluation framework or observability tool and upload without renaming columns.</p>"},{"location":"configuration/data-sources/#option-2-postgres-auto-load","title":"Option 2: Postgres Auto-Load","text":"<p>Postgres auto-load executes SQL queries on app startup, syncs data into a local DuckDB analytics store, and populates the dashboard automatically. Each page has its own YAML config file with split queries \u2014 one for the dataset/records table and one for the metrics/results table.</p> Page Config file Top-level key Evaluate / Analytics <code>custom/config/eval_db.yaml</code> <code>eval_db</code> Monitoring <code>custom/config/monitoring_db.yaml</code> <code>monitoring_db</code> Human Signals <code>custom/config/human_signals_db.yaml</code> <code>human_signals_db</code> Production / KPIs <code>custom/config/kpi_db.yaml</code> <code>kpi_db</code>"},{"location":"configuration/data-sources/#step-1-copy-the-template","title":"Step 1 -- Copy the template","text":"<pre><code># Copy the template you need from backend/config/ to custom/config/\ncp backend/config/eval_db.yaml.example custom/config/eval_db.yaml        # for Evaluate\ncp backend/config/monitoring_db.yaml.example custom/config/monitoring_db.yaml  # for Monitoring\ncp backend/config/human_signals_db.yaml.example custom/config/human_signals_db.yaml  # for Human Signals\n</code></pre> <p>Or run <code>make setup</code> to copy all templates at once.</p>"},{"location":"configuration/data-sources/#step-2-configure-the-connection","title":"Step 2 -- Configure the connection","text":"<p>Open the YAML file and set your connection details. You have two options:</p> Full URL (recommended)Individual fields <pre><code>eval_db:\n  enabled: true\n  auto_load: true\n  url: \"postgresql://axis_reader:${DB_PASSWORD}@db.example.com:5432/evaluations\"\n</code></pre> <p>Set <code>DB_PASSWORD</code> as an environment variable to avoid storing secrets in the YAML file.</p> <pre><code>eval_db:\n  enabled: true\n  auto_load: true\n  host: \"db.example.com\"\n  port: 5432\n  database: \"evaluations\"\n  username: \"axis_reader\"\n  password: \"your_password_here\"\n  ssl_mode: \"require\"\n</code></pre>"},{"location":"configuration/data-sources/#step-3-write-split-queries","title":"Step 3 -- Write split queries","text":"<p>Each config uses two SQL queries: <code>dataset_query</code> (records/traces) and <code>results_query</code> (metrics/scores). Both must include a <code>dataset_id</code> column \u2014 AXIS joins them in DuckDB.</p> Using SQL aliasesUsing column mappings <pre><code>eval_db:\n  enabled: true\n  auto_load: true\n  url: \"postgresql://axis_reader:${DB_PASSWORD}@db.example.com:5432/evals\"\n\n  dataset_query: |\n    SELECT\n      e.id AS dataset_id,\n      e.experiment_name AS evaluation_name,\n      e.input AS query,\n      e.output AS actual_output,\n      e.expected AS expected_output,\n      e.metadata AS data_metadata\n    FROM evaluations e\n    WHERE e.created_at &gt; NOW() - INTERVAL '7 days'\n\n  results_query: |\n    SELECT\n      m.eval_id AS dataset_id,\n      m.metric_name,\n      m.score AS metric_score\n    FROM metrics m\n    JOIN evaluations e ON e.id = m.eval_id\n    WHERE e.created_at &gt; NOW() - INTERVAL '7 days'\n\n  query_timeout: 60\n  row_limit: 10000\n</code></pre> <pre><code>eval_db:\n  enabled: true\n  auto_load: true\n  url: \"postgresql://axis_reader:${DB_PASSWORD}@db.example.com:5432/evals\"\n  columns:\n    my_id_field: dataset_id\n    user_prompt: query\n    llm_response: actual_output\n    gold_answer: expected_output\n    run_name: evaluation_name\n    eval_metric: metric_name\n    eval_score: metric_score\n\n  dataset_query: \"SELECT * FROM my_evaluations WHERE created_at &gt; NOW() - INTERVAL '7 days'\"\n  results_query: \"SELECT * FROM my_metrics WHERE created_at &gt; NOW() - INTERVAL '7 days'\"\n\n  query_timeout: 60\n  row_limit: 10000\n</code></pre> <p>Both queries must include <code>dataset_id</code></p> <p>The <code>dataset_query</code> and <code>results_query</code> are joined on <code>dataset_id</code> in DuckDB. Make sure both queries alias or include a column named <code>dataset_id</code>.</p>"},{"location":"configuration/data-sources/#step-4-restart-the-backend","title":"Step 4 -- Restart the backend","text":"<pre><code># If using make\nmake backend\n\n# Or directly\ncd backend &amp;&amp; uvicorn app.main:app --reload --port 8500\n</code></pre> <p>On startup you will see a log line confirming the auto-load:</p> <pre><code>INFO: Loaded eval DB config from custom/config/eval_db.yaml\n</code></pre> <p>Safety limits</p> <p>AXIS enforces hard caps on query execution:</p> <ul> <li><code>query_timeout</code>: clamped to a maximum of 120 seconds</li> <li><code>row_limit</code>: clamped to a maximum of 50,000 rows</li> </ul> <p>Values above these caps are silently reduced to the maximum.</p>"},{"location":"configuration/data-sources/#monitoring-data-formats","title":"Monitoring Data Formats","text":"<p>The Monitoring module accepts two CSV formats. AXIS auto-detects which format you're using.</p>"},{"location":"configuration/data-sources/#long-format-recommended-for-production","title":"Long Format (recommended for production)","text":"<p>Each row represents a single metric observation. Used when metrics are stored in a normalized database schema.</p> <pre><code>dataset_id,query,actual_output,metric_name,metric_score,timestamp,environment,source_name\n01KFX...,What is...,The answer...,Faithfulness,0.85,2024-01-15T10:30:00,production,alpha_bot\n01KFX...,What is...,The answer...,Relevance,0.92,2024-01-15T10:30:00,production,alpha_bot\n</code></pre> <p>Key columns: <code>metric_name</code> (name of the metric) and <code>metric_score</code> (numeric score value).</p>"},{"location":"configuration/data-sources/#wide-format","title":"Wide Format","text":"<p>Each row contains all metrics as separate columns. Common when exporting from evaluation runs.</p> <pre><code>dataset_id,query,actual_output,faithfulness_score,relevance_score,timestamp\n01KFX...,What is...,The answer...,0.85,0.92,2024-01-15T10:30:00\n</code></pre> <p>Columns ending in <code>_score</code> are auto-detected as metrics.</p> <p>Format detection logic</p> <p>If the data contains both <code>metric_name</code> and <code>metric_score</code> columns, AXIS uses long format. Otherwise, it scans for columns ending in <code>_score</code> (wide format).</p>"},{"location":"configuration/data-sources/#metric-categories","title":"Metric Categories","text":"<p>The <code>metric_category</code> column in monitoring data controls how metrics are displayed in the Monitoring dashboard. Three categories are supported:</p> Category Description Example values UI rendering <code>SCORE</code> Numeric scores (default) <code>0.85</code>, <code>0.92</code> Time-series charts, pass/fail thresholds, sparklines <code>CLASSIFICATION</code> Categorical labels <code>\"POSITIVE\"</code>, <code>\"HALLUCINATION\"</code> Category breakdowns, stacked bar charts, distribution panels <code>ANALYSIS</code> Structured insights/reasoning <code>{\"issues\": [...]}</code> Detail views with formatted JSON, paginated insights table"},{"location":"configuration/data-sources/#how-to-use","title":"How to use","text":"<p>Add <code>metric_category</code> to your monitoring data or SQL query:</p> CSVSQL (long format) <pre><code>dataset_id,metric_name,metric_score,metric_category\n01KFX...,Faithfulness,0.85,SCORE\n01KFX...,Sentiment,POSITIVE,CLASSIFICATION\n01KFX...,QualityAnalysis,\"{\"\"issues\"\": []}\",ANALYSIS\n</code></pre> <pre><code>SELECT\n  e.id AS dataset_id,\n  m.metric_name,\n  m.score AS metric_score,\n  m.category AS metric_category    -- SCORE, CLASSIFICATION, or ANALYSIS\nFROM metrics m\nJOIN evaluations e ON e.id = m.eval_id\n</code></pre> <p>If <code>metric_category</code> is omitted, all metrics default to <code>SCORE</code>.</p> <p>Monitoring tabs</p> <p>The Monitoring page shows separate tabs for each category type:</p> <ul> <li>Score tab \u2014 numeric metric trends, pass rates, latency distribution</li> <li>Classification tab \u2014 category value counts and trends (only appears when CLASSIFICATION metrics exist)</li> <li>Analysis tab \u2014 paginated structured insights (only appears when ANALYSIS metrics exist)</li> </ul>"},{"location":"configuration/data-sources/#mixing-both-approaches","title":"Mixing Both Approaches","text":"<p>You can auto-load data from Postgres for one page and use CSV upload for another. For example:</p> <ul> <li>Monitoring: auto-load from your observability database via <code>monitoring_db.yaml</code></li> <li>Evaluate: upload experiment CSVs manually through the UI</li> <li>Human Signals: auto-load HITL cases from your support database via <code>human_signals_db.yaml</code></li> </ul> <p>Each page's data source is independent.</p>"},{"location":"configuration/data-sources/#duckdb-analytics-store","title":"DuckDB Analytics Store","text":"<p>When using Postgres auto-load, data is synced into an embedded DuckDB analytics store that acts as a local cache. This provides fast analytical queries without hitting your source database on every request.</p>"},{"location":"configuration/data-sources/#how-it-works_1","title":"How it works","text":"<ol> <li>On startup, each configured database runs its <code>dataset_query</code> and <code>results_query</code> concurrently against Postgres</li> <li>Results are written to internal DuckDB tables (e.g., <code>monitoring_dataset</code>, <code>monitoring_results</code>)</li> <li>A JOIN view is created (e.g., <code>monitoring_data</code>) that combines both tables on <code>dataset_id</code></li> <li>Subsequent API requests read from DuckDB, not Postgres</li> </ol>"},{"location":"configuration/data-sources/#incremental-sync","title":"Incremental sync","text":"<p>Add <code>incremental_column</code> to your YAML config to enable watermark-based incremental sync \u2014 only new rows are appended on each refresh:</p> <pre><code>monitoring_db:\n  incremental_column: created_at\n  refresh_interval_minutes: 15   # auto-sync every 15 minutes\n</code></pre>"},{"location":"configuration/data-sources/#learn-more","title":"Learn more","text":"<ul> <li>DuckDB Configuration -- store settings, sync workers, concurrency</li> <li>DuckDB Architecture -- technical deep-dive into the sync engine</li> <li>DuckDB Sync Runbook -- production sync patterns</li> </ul>"},{"location":"configuration/data-sources/#env-var-fallback","title":"Env-Var Fallback","text":"<p>If you prefer environment variables over YAML files, you can configure database connections entirely through <code>backend/.env</code>. However, YAML files offer additional features not available via env vars:</p> Feature YAML Env vars Split queries <code>dataset_query</code> + <code>results_query</code> Not available Column mappings <code>columns</code> map Not available Incremental sync <code>incremental_column</code> field Not available Periodic refresh <code>refresh_interval_minutes</code> Not available Row limit / timeout Per-file Per-database (eval only) Auto-load with query All three databases Eval DB only <p>Note</p> <p>If a YAML file exists for a database, its env vars are ignored entirely. Delete or rename the YAML file to fall back to env vars.</p> <p>See Environment Variables for the complete env var reference and YAML Configs for the full YAML schema.</p>"},{"location":"configuration/data-sources/#troubleshooting","title":"Troubleshooting","text":"My data does not appear after startup <p>Check the backend logs for connection errors. Common issues:</p> <ul> <li><code>enabled: false</code> -- the master switch is off</li> <li><code>auto_load: false</code> -- the data is configured but not loading automatically</li> <li>Incorrect <code>url</code> or host/port/database values</li> <li>Firewall blocking the database port</li> <li><code>${DB_PASSWORD}</code> placeholder without the env var set</li> </ul> Columns are not mapping correctly <ul> <li>Verify your <code>columns</code> mapping in the YAML matches your actual database column names</li> <li>Alternatively, use <code>AS</code> aliases in your SQL query to rename columns</li> <li>Check the AXIS schema for the target column names in YAML Configs</li> </ul> Query is timing out <ul> <li>Increase <code>query_timeout</code> (max 120 seconds)</li> <li>Add a <code>WHERE</code> clause to limit the date range</li> <li>Reduce <code>row_limit</code> to fetch fewer rows</li> <li>Ensure the database has appropriate indexes on filtered columns</li> <li>Add <code>partition_column</code> to enable parallel COPY reads for large tables</li> </ul> DuckDB sync is slow or stuck <ul> <li>Check sync status: <code>curl http://localhost:8500/api/store/status</code></li> <li>Force a full rebuild: <code>curl -X POST http://localhost:8500/api/store/sync/monitoring?full=true</code></li> <li>Reset watermarks: <code>curl -X POST http://localhost:8500/api/store/sync/monitoring/reset-watermark</code></li> <li>See the DuckDB Sync Runbook for troubleshooting details</li> </ul>"},{"location":"configuration/duckdb/","title":"DuckDB Configuration","text":"<p>The DuckDB embedded analytics store is configured via <code>custom/config/duckdb.yaml</code>. This file controls sync behavior, storage location, query concurrency, and parallel read settings.</p>"},{"location":"configuration/duckdb/#setup","title":"Setup","text":"<pre><code>cp backend/config/duckdb.yaml.example custom/config/duckdb.yaml\n</code></pre> <p>Or use the project-level setup command which copies all <code>.example</code> templates:</p> <pre><code>make setup\n</code></pre>"},{"location":"configuration/duckdb/#config-file","title":"Config File","text":"custom/config/duckdb.yaml<pre><code>duckdb:\n  # Enable/disable DuckDB analytics store\n  enabled: true\n\n  # Path to the DuckDB database file (relative to backend directory)\n  path: \"data/local_store.duckdb\"\n\n  # Single global startup sync switch:\n  # - startup: run startup sync\n  # - manual: no startup sync (use /api/store/sync)\n  sync_mode: \"startup\"\n\n  # Number of rows per chunk during Postgres -&gt; DuckDB streaming\n  sync_chunk_size: 10000\n\n  # Safety cap: stop sync if this many rows are read (logs warning)\n  # Primary volume control should be via YAML query WHERE clauses\n  max_sync_rows: 2000000\n\n  # Max concurrent DuckDB read queries (thread pool limit)\n  query_concurrency: 8\n\n  # Parallel readers per dataset sync (for COPY-based reads)\n  # Requires partition_column in the database config\n  sync_workers: 4\n</code></pre>"},{"location":"configuration/duckdb/#field-reference","title":"Field Reference","text":"Field Type Default Description <code>enabled</code> <code>bool</code> <code>true</code> Master switch. Set to <code>false</code> to disable DuckDB entirely <code>path</code> <code>str</code> <code>data/local_store.duckdb</code> Path to the DuckDB file, relative to the <code>backend/</code> directory <code>sync_mode</code> <code>str</code> <code>\"startup\"</code> Global startup behavior: <code>\"startup\"</code> or <code>\"manual\"</code> <code>sync_chunk_size</code> <code>int</code> <code>10000</code> Rows per chunk during sync. Larger values use more memory but sync faster <code>max_sync_rows</code> <code>int</code> <code>2000000</code> Safety cap. If hit, sync completes with available rows and sets <code>truncated: true</code> <code>query_concurrency</code> <code>int</code> <code>8</code> Maximum concurrent DuckDB read queries via <code>anyio.CapacityLimiter</code> <code>sync_workers</code> <code>int</code> <code>1</code> Number of parallel readers per dataset sync. Requires <code>partition_column</code> in the database config to take effect"},{"location":"configuration/duckdb/#how-sync-works","title":"How Sync Works","text":"<p>DuckDB acts as a local cache of your PostgreSQL data. All datasets use a split sync pattern:</p> <ol> <li>Each database config provides two SQL queries: <code>dataset_query</code> (records) and <code>results_query</code> (metrics)</li> <li>Both queries are read concurrently from Postgres using the configured read strategy</li> <li>Each half is written to its own DuckDB internal table (e.g., <code>monitoring_dataset</code>, <code>monitoring_results</code>)</li> <li>A DuckDB JOIN view is created: <code>CREATE VIEW monitoring_data AS SELECT ... FROM results JOIN dataset ON dataset_id</code></li> <li>Metadata (columns, filter values, time range, summary stats) is computed and cached</li> </ol>"},{"location":"configuration/duckdb/#read-strategy-tiered-fallback","title":"Read Strategy (tiered fallback)","text":"<p>The sync engine selects the fastest available read method:</p> <ol> <li>Parallel COPY \u2014 <code>sync_workers</code> concurrent <code>COPY TO</code> commands, each reading a partition range via <code>partition_column</code>. Writes CSV to temp files, loads into DuckDB via <code>read_csv_auto</code>. Best for large tables.</li> <li>Single COPY \u2014 One <code>COPY TO</code> for the whole query. Used when <code>partition_column</code> or <code>sync_workers</code> is not set.</li> <li>Sequential chunked \u2014 asyncpg cursor reading <code>sync_chunk_size</code> rows per fetch. Fallback when the database backend does not support COPY.</li> </ol>"},{"location":"configuration/duckdb/#incremental-sync","title":"Incremental Sync","text":"<p>When <code>incremental_column</code> is configured in the database YAML (e.g., <code>created_at</code>), the sync engine can skip unchanged data:</p> <ol> <li>Reads stored watermarks (MAX value of <code>incremental_column</code> from previous sync)</li> <li>Wraps each query with <code>WHERE {column} &gt; '{watermark}'</code></li> <li>Appends new rows to existing DuckDB tables (INSERT INTO, no staging swap)</li> <li>Updates watermarks to the new MAX value</li> </ol> <p>Incremental mode is used automatically when watermarks are available. On failure, watermarks are cleared and the next sync does a full rebuild.</p>"},{"location":"configuration/duckdb/#periodic-scheduler","title":"Periodic Scheduler","text":"<p>Datasets with <code>refresh_interval_minutes &gt; 0</code> are automatically synced on a timer:</p> custom/config/monitoring_db.yaml<pre><code>monitoring_db:\n  refresh_interval_minutes: 15   # sync every 15 minutes\n  incremental_column: created_at  # use incremental mode\n</code></pre> <p>The scheduler starts after the startup sync completes and runs until shutdown.</p>"},{"location":"configuration/duckdb/#startup-sync-eligibility","title":"Startup Sync Eligibility","text":"<p>On startup (if <code>sync_mode: \"startup\"</code>), each dataset is synced if:</p> <ul> <li><code>enabled: true</code> in the database config</li> <li><code>dataset_query</code> and <code>results_query</code> are both configured</li> <li><code>auto_load</code> / <code>auto_connect</code> is enabled in its YAML config</li> </ul> <p>Data volume control</p> <p>The <code>max_sync_rows</code> field is a safety net, not the primary volume control. Use the <code>query</code> fields in your database YAML configs to control data volume:</p> custom/config/monitoring_db.yaml<pre><code>monitoring_db:\n  results_query: |\n    SELECT ...\n    FROM metric_results\n    WHERE created_at &gt; NOW() - INTERVAL '7 days'\n</code></pre> <p>The <code>WHERE</code> clause is the recommended way to limit how much data is synced.</p>"},{"location":"configuration/duckdb/#manual-sync","title":"Manual Sync","text":"<p>You can trigger a sync manually via the API:</p> <pre><code># Sync all configured datasets\ncurl -X POST http://localhost:8500/api/store/sync\n\n# Sync a single dataset\ncurl -X POST http://localhost:8500/api/store/sync/monitoring\n\n# Force full rebuild (ignore watermarks)\ncurl -X POST \"http://localhost:8500/api/store/sync/monitoring?full=true\"\n\n# Reset watermarks (next sync will do full rebuild)\ncurl -X POST http://localhost:8500/api/store/sync/monitoring/reset-watermark\n\n# Check sync status (includes watermarks and refresh intervals)\ncurl http://localhost:8500/api/store/status\n</code></pre>"},{"location":"configuration/duckdb/#storage-location","title":"Storage Location","text":"<p>The DuckDB file is created at the configured <code>path</code> (default: <code>backend/data/local_store.duckdb</code>). The parent directory is created automatically if it doesn't exist.</p> <p>Docker deployments</p> <p>Mount a persistent volume at <code>backend/data/</code> to preserve the DuckDB file across container restarts. This avoids re-syncing on every deployment.</p>"},{"location":"configuration/duckdb/#disabling-duckdb","title":"Disabling DuckDB","text":"<p>Set <code>enabled: false</code> to disable the DuckDB store entirely. The backend will still function -- monitoring and analytics endpoints will fall back to processing data from POST request bodies (the pre-DuckDB behavior).</p> <pre><code>duckdb:\n  enabled: false\n</code></pre>"},{"location":"configuration/duckdb/#database-config-split-queries","title":"Database Config: Split Queries","text":"<p>Each database YAML now uses split queries instead of a single <code>query</code> field:</p> custom/config/monitoring_db.yaml<pre><code>monitoring_db:\n  enabled: true\n  auto_load: true\n  url: \"postgresql://user:pass@host:5432/db\"\n\n  # Split queries (required for sync)\n  dataset_query: |\n    SELECT\n      id AS dataset_id,\n      input AS query,\n      output AS actual_output,\n      created_at AS timestamp,\n      environment,\n      source_name,\n      trace_id,\n      latency\n    FROM traces\n\n  results_query: |\n    SELECT\n      trace_id AS dataset_id,\n      metric_name,\n      score AS metric_score,\n      metric_category,\n      explanation\n    FROM metric_results\n\n  # Performance tuning (optional)\n  partition_column: \"id\"            # Column to split parallel COPY reads\n  incremental_column: \"created_at\"  # Column for watermark-based incremental sync\n  refresh_interval_minutes: 15      # Periodic sync interval (0 = disabled)\n  query_timeout: 120                # Max seconds per query\n</code></pre>"},{"location":"configuration/duckdb/#new-database-config-fields","title":"New Database Config Fields","text":"Field Type Default Description <code>dataset_query</code> <code>str</code> -- SQL query for the records/dataset table. Must include <code>dataset_id</code> <code>results_query</code> <code>str</code> -- SQL query for the metrics/results table. Must include <code>dataset_id</code> <code>partition_column</code> <code>str</code> <code>null</code> Column to partition parallel COPY reads on (integer or timestamp) <code>incremental_column</code> <code>str</code> <code>null</code> Column used as watermark for incremental sync (e.g., <code>created_at</code>) <code>refresh_interval_minutes</code> <code>int</code> <code>0</code> Periodic sync interval in minutes. <code>0</code> = disabled <p>Both <code>dataset_query</code> and <code>results_query</code> must be configured for sync to work. They must share a <code>dataset_id</code> column for the JOIN view.</p>"},{"location":"configuration/duckdb/#related","title":"Related","text":"<ul> <li>YAML Configs -- Database connection configs that define what data is synced</li> <li>DuckDB Architecture -- Technical deep-dive into the sync engine and store</li> <li>Data Sources -- CSV upload vs. Postgres auto-load setup guide</li> <li>DuckDB Sync Runbook -- Production sync patterns</li> </ul>"},{"location":"configuration/environment-variables/","title":"Environment Variables","text":"<p>AXIS reads environment variables from <code>.env</code> files using Pydantic Settings. Variable names are case-insensitive -- <code>HOST</code> and <code>host</code> both work.</p>"},{"location":"configuration/environment-variables/#backend-backendenv","title":"Backend -- <code>backend/.env</code>","text":""},{"location":"configuration/environment-variables/#server","title":"Server","text":"Variable Type Default Description <code>HOST</code> <code>str</code> <code>127.0.0.1</code> Bind address for the FastAPI server <code>PORT</code> <code>int</code> <code>8500</code> Bind port for the FastAPI server <code>DEBUG</code> <code>bool</code> <code>true</code> Enable debug mode (auto-reload, verbose logs) <code>APP_NAME</code> <code>str</code> <code>AXIS</code> Application name shown in API docs <code>FRONTEND_URL</code> <code>str</code> <code>http://localhost:3500</code> Primary allowed CORS origin for the frontend <code>FRONTEND_URLS</code> <code>str</code> -- Optional comma-separated additional CORS origins <code>COPILOT_ENABLED</code> <code>bool</code> <code>true</code> Enable the AI Copilot sidebar in the frontend <code>AXIS_PLUGINS_ENABLED</code> <code>str</code> <code>*</code> Comma-separated plugin names to enable, or <code>*</code> for all. Empty string disables all"},{"location":"configuration/environment-variables/#ai-llm","title":"AI / LLM","text":"Variable Type Default Description <code>OPENAI_API_KEY</code> <code>str</code> -- OpenAI API key for LLM judge and Copilot <code>ANTHROPIC_API_KEY</code> <code>str</code> -- Anthropic API key for Claude-based judge <code>GATEWAY_API_KEY</code> <code>str</code> -- API key for gateway or platform auth <code>AI_TOOLKIT_URL</code> <code>str</code> -- URL of AI Toolkit server <code>LLM_MODEL_NAME</code> <code>str</code> <code>gpt-4</code> Default language model name <code>EMBEDDING_MODEL_NAME</code> <code>str</code> <code>text-embedding-ada-002</code> Default embedding model name <code>OPENAI_API_BASE</code> <code>str</code> -- Base URL for OpenAI-compatible APIs (e.g. Azure, vLLM) <p>Using Azure OpenAI or a local model</p> <p>Set <code>OPENAI_API_BASE</code> to point at your Azure endpoint or a local vLLM / Ollama server. Combined with <code>LLM_MODEL_NAME</code>, this lets you use any OpenAI-compatible API without code changes.</p>"},{"location":"configuration/environment-variables/#evaluation-database","title":"Evaluation Database","text":"<p>These are the env-var equivalents of <code>eval_db.yaml</code>. If the YAML file exists, these are ignored.</p> Variable Type Default Description <code>EVAL_DB_URL</code> <code>str</code> -- Full PostgreSQL connection URL (overrides individual fields) <code>EVAL_DB_HOST</code> <code>str</code> -- Database host <code>EVAL_DB_PORT</code> <code>int</code> <code>5432</code> Database port <code>EVAL_DB_NAME</code> <code>str</code> -- Database name <code>EVAL_DB_USER</code> <code>str</code> -- Database username <code>EVAL_DB_PASSWORD</code> <code>str</code> -- Database password <code>EVAL_DB_SSL_MODE</code> <code>str</code> <code>prefer</code> SSL mode: <code>disable</code>, <code>prefer</code>, <code>require</code> <code>EVAL_DB_AUTO_LOAD</code> <code>bool</code> <code>false</code> Auto-load evaluation data on startup <code>EVAL_DB_DATASET_QUERY</code> <code>str</code> -- SQL query for the evaluation dataset table <code>EVAL_DB_RESULTS_QUERY</code> <code>str</code> -- SQL query for the evaluation results table <code>EVAL_DB_QUERY_TIMEOUT</code> <code>int</code> <code>60</code> Query timeout in seconds (max 120) <code>EVAL_DB_ROW_LIMIT</code> <code>int</code> <code>10000</code> Max rows to load (max 50,000)"},{"location":"configuration/environment-variables/#monitoring-database","title":"Monitoring Database","text":"<p>These are the env-var equivalents of <code>monitoring_db.yaml</code>. If the YAML file exists, these are ignored.</p> Variable Type Default Description <code>MONITORING_DB_URL</code> <code>str</code> -- Full PostgreSQL connection URL <code>MONITORING_DB_HOST</code> <code>str</code> -- Database host <code>MONITORING_DB_PORT</code> <code>int</code> <code>5432</code> Database port <code>MONITORING_DB_NAME</code> <code>str</code> -- Database name <code>MONITORING_DB_USER</code> <code>str</code> -- Database username <code>MONITORING_DB_PASSWORD</code> <code>str</code> -- Database password <code>MONITORING_DB_SCHEMA</code> <code>str</code> <code>public</code> Database schema <code>MONITORING_DB_TABLE</code> <code>str</code> -- Table name (legacy auto-connect) <code>MONITORING_DB_SSL_MODE</code> <code>str</code> <code>prefer</code> SSL mode <code>MONITORING_DB_AUTO_CONNECT</code> <code>bool</code> <code>false</code> Auto-connect on page load"},{"location":"configuration/environment-variables/#human-signals-database","title":"Human Signals Database","text":"<p>These are the env-var equivalents of <code>human_signals_db.yaml</code>. If the YAML file exists, these are ignored.</p> Variable Type Default Description <code>HUMAN_SIGNALS_DB_URL</code> <code>str</code> -- Full PostgreSQL connection URL <code>HUMAN_SIGNALS_DB_HOST</code> <code>str</code> -- Database host <code>HUMAN_SIGNALS_DB_PORT</code> <code>int</code> <code>5432</code> Database port <code>HUMAN_SIGNALS_DB_NAME</code> <code>str</code> -- Database name <code>HUMAN_SIGNALS_DB_USER</code> <code>str</code> -- Database username <code>HUMAN_SIGNALS_DB_PASSWORD</code> <code>str</code> -- Database password <code>HUMAN_SIGNALS_DB_SCHEMA</code> <code>str</code> <code>public</code> Database schema <code>HUMAN_SIGNALS_DB_TABLE</code> <code>str</code> -- Table name (legacy auto-connect) <code>HUMAN_SIGNALS_DB_SSL_MODE</code> <code>str</code> <code>prefer</code> SSL mode <code>HUMAN_SIGNALS_DB_AUTO_CONNECT</code> <code>bool</code> <code>false</code> Auto-connect on page load"},{"location":"configuration/environment-variables/#kpi-database","title":"KPI Database","text":"<p>These are the env-var equivalents of <code>kpi_db.yaml</code>. If the YAML file exists, these are ignored.</p> Variable Type Default Description <code>KPI_DB_URL</code> <code>str</code> -- Full PostgreSQL connection URL (overrides individual fields) <code>KPI_DB_HOST</code> <code>str</code> -- Database host <code>KPI_DB_PORT</code> <code>int</code> <code>5432</code> Database port <code>KPI_DB_NAME</code> <code>str</code> -- Database name <code>KPI_DB_USER</code> <code>str</code> -- Database username <code>KPI_DB_PASSWORD</code> <code>str</code> -- Database password <code>KPI_DB_SSL_MODE</code> <code>str</code> <code>prefer</code> SSL mode: <code>disable</code>, <code>prefer</code>, <code>require</code> <code>KPI_DB_AUTO_LOAD</code> <code>bool</code> <code>false</code> Auto-load KPI data on startup <p>Display config is YAML-only</p> <p>KPI display settings (<code>visible_kpis</code>, <code>card_display_value</code>, <code>kpi_overrides</code>, <code>categories</code>, etc.) are only configurable via the YAML file. See kpi_db.yaml for the full reference.</p>"},{"location":"configuration/environment-variables/#agent-replay","title":"Agent Replay","text":"Variable Type Default Description <code>AGENT_REPLAY_ENABLED</code> <code>bool</code> <code>false</code> Master switch for the Agent Replay feature <code>LANGFUSE_PUBLIC_KEY</code> <code>str</code> -- Default Langfuse public API key <code>LANGFUSE_SECRET_KEY</code> <code>str</code> -- Default Langfuse secret API key <code>LANGFUSE_HOST</code> <code>str</code> <code>https://cloud.langfuse.com</code> Langfuse server URL <p>Per-agent Langfuse credentials use the pattern <code>LANGFUSE_{AGENT}_PUBLIC_KEY</code> and <code>LANGFUSE_{AGENT}_SECRET_KEY</code>:</p> <pre><code># Agent-specific Langfuse credentials\nLANGFUSE_ALPHA_BOT_PUBLIC_KEY=pk-lf-...\nLANGFUSE_ALPHA_BOT_SECRET_KEY=sk-lf-...\nLANGFUSE_BETA_BOT_PUBLIC_KEY=pk-lf-...\nLANGFUSE_BETA_BOT_SECRET_KEY=sk-lf-...\n</code></pre> <p>Agent names are canonicalized: lowercased with hyphens converted to underscores.</p>"},{"location":"configuration/environment-variables/#agent-replay-search-database","title":"Agent Replay Search Database","text":"<p>These are the env-var equivalents of <code>agent_replay_db.yaml</code>. If the YAML file exists, these are ignored.</p> Variable Type Default Description <code>AGENT_REPLAY_DB_ENABLED</code> <code>bool</code> <code>false</code> Enable the search database <code>AGENT_REPLAY_DB_URL</code> <code>str</code> -- Full PostgreSQL connection URL <code>AGENT_REPLAY_DB_HOST</code> <code>str</code> -- Database host <code>AGENT_REPLAY_DB_PORT</code> <code>int</code> <code>5432</code> Database port <code>AGENT_REPLAY_DB_NAME</code> <code>str</code> -- Database name <code>AGENT_REPLAY_DB_USER</code> <code>str</code> -- Database username <code>AGENT_REPLAY_DB_PASSWORD</code> <code>str</code> -- Database password <code>AGENT_REPLAY_DB_SSL_MODE</code> <code>str</code> <code>prefer</code> SSL mode <code>AGENT_REPLAY_DB_SCHEMA</code> <code>str</code> <code>public</code> Database schema <code>AGENT_REPLAY_DB_TABLE</code> <code>str</code> <code>trace_lookup</code> Lookup table name <code>AGENT_REPLAY_DB_SEARCH_COLUMN</code> <code>str</code> (empty) Column to match search queries. Empty = trace ID only. Sets a single-entry <code>search_columns</code> dict <code>AGENT_REPLAY_DB_SEARCH_COLUMN_LABEL</code> <code>str</code> (empty) Display label for the search column in the UI <code>AGENT_REPLAY_DB_TRACE_ID_COLUMN</code> <code>str</code> <code>langfuse_trace_id</code> Column with Langfuse trace IDs <code>AGENT_REPLAY_DB_AGENT_NAME_COLUMN</code> <code>str</code> -- Column with agent names (optional) <code>AGENT_REPLAY_DB_QUERY_TIMEOUT</code> <code>int</code> <code>10</code> Query timeout in seconds (max 30) <code>AGENT_REPLAY_DB_CONNECT_TIMEOUT</code> <code>int</code> <code>10</code> Connection timeout in seconds (max 30) <code>AGENT_REPLAY_DB_POOL_MIN_SIZE</code> <code>int</code> <code>0</code> Min idle connections <code>AGENT_REPLAY_DB_POOL_MAX_SIZE</code> <code>int</code> <code>5</code> Max connections (max 20)"},{"location":"configuration/environment-variables/#graph-database-falkordb","title":"Graph Database (FalkorDB)","text":"Variable Type Default Description <code>GRAPH_DB_HOST</code> <code>str</code> <code>localhost</code> FalkorDB host <code>GRAPH_DB_PORT</code> <code>int</code> <code>6379</code> FalkorDB port <code>GRAPH_DB_NAME</code> <code>str</code> <code>knowledge_graph</code> Graph name inside FalkorDB <code>GRAPH_DB_PASSWORD</code> <code>str</code> -- FalkorDB password"},{"location":"configuration/environment-variables/#theme","title":"Theme","text":"<p>Environment-level theme overrides. These are applied on top of the YAML theme config, allowing you to tweak individual values without editing the YAML file.</p> Variable Type Default Description <code>AXIS_THEME_ACTIVE</code> <code>str</code> -- Active palette name (e.g. <code>sage_green</code>, <code>professional_blue</code>) <code>AXIS_THEME_PRIMARY</code> <code>str</code> -- Primary color hex <code>AXIS_THEME_PRIMARY_LIGHT</code> <code>str</code> -- Primary light color hex <code>AXIS_THEME_PRIMARY_DARK</code> <code>str</code> -- Primary dark color hex <code>AXIS_THEME_PRIMARY_SOFT</code> <code>str</code> -- Primary soft color hex <code>AXIS_THEME_PRIMARY_PALE</code> <code>str</code> -- Primary pale color hex <code>AXIS_THEME_ACCENT_GOLD</code> <code>str</code> -- Accent gold color hex <code>AXIS_THEME_ACCENT_SILVER</code> <code>str</code> -- Accent silver color hex <code>AXIS_THEME_HERO_IMAGE</code> <code>str</code> -- URL or path to hero background image <code>AXIS_THEME_LOGO_URL</code> <code>str</code> -- URL or path to logo image <code>AXIS_THEME_FAVICON_URL</code> <code>str</code> -- URL or path to favicon <code>AXIS_THEME_APP_ICON_URL</code> <code>str</code> -- URL or path to app icon (sidebar) <code>AXIS_THEME_HERO_CONTRAST</code> <code>float</code> -- Hero image contrast filter (1.0 = normal) <code>AXIS_THEME_HERO_SATURATION</code> <code>float</code> -- Hero image saturation filter (1.0 = normal) <code>AXIS_THEME_HERO_BRIGHTNESS</code> <code>float</code> -- Hero image brightness filter (1.0 = normal) <code>AXIS_THEME_HERO_OPACITY</code> <code>float</code> -- Hero image opacity (1.0 = fully visible) <code>AXIS_THEME_HERO_MODE</code> <code>str</code> -- Hero section mode: <code>dark</code> (default) or <code>light</code>"},{"location":"configuration/environment-variables/#frontend-frontendenvlocal","title":"Frontend -- <code>frontend/.env.local</code>","text":"<p>The Next.js frontend only exposes variables prefixed with <code>NEXT_PUBLIC_</code> to the browser bundle.</p> Variable Type Default Description <code>NEXT_PUBLIC_API_URL</code> <code>str</code> <code>http://localhost:8500</code> Backend API base URL <p>No secrets in frontend env</p> <p><code>NEXT_PUBLIC_*</code> variables are embedded into the JavaScript bundle at build time and are visible to anyone using the browser. Never place API keys, passwords, or other credentials in <code>frontend/.env.local</code>.</p>"},{"location":"configuration/environment-variables/#minimal-working-example","title":"Minimal Working Example","text":"<p>A backend <code>.env</code> file that gets you started with CSV upload mode (no databases):</p> backend/.env<pre><code>HOST=127.0.0.1\nPORT=8500\nDEBUG=true\nFRONTEND_URL=http://localhost:3500\n# Optional extra origins (comma-separated)\nFRONTEND_URLS=http://localhost:3500,http://127.0.0.1:3500\n</code></pre> <p>Add AI keys when you want to use the Copilot or LLM judge:</p> backend/.env (with AI)<pre><code>HOST=127.0.0.1\nPORT=8500\nDEBUG=true\nFRONTEND_URL=http://localhost:3500\nFRONTEND_URLS=http://localhost:3500,http://127.0.0.1:3500\n\nOPENAI_API_KEY=sk-...\nLLM_MODEL_NAME=gpt-4o-mini\n</code></pre>"},{"location":"configuration/environment-variables/#related","title":"Related","text":"<ul> <li>YAML Configs -- database and theme YAML files (override env vars for DB configs)</li> <li>Data Sources -- choosing between CSV upload and Postgres auto-load</li> <li>Theming -- detailed guide to color palettes and branding assets</li> </ul>"},{"location":"configuration/multi-agent/","title":"Multi-Agent Teams","text":"<p>AXIS supports multi-agent deployments where several AI agents share a single AXIS instance. Each agent can have its own identity, credentials, KPI display preferences, and trace lookup configuration. This page consolidates the per-agent settings that are spread across multiple config files.</p>"},{"location":"configuration/multi-agent/#overview","title":"Overview","text":"<p>When your platform runs multiple agents (e.g., one for customer support, another for order processing), AXIS lets you:</p> <ul> <li>Show each agent's identity \u2014 name, avatar, role, and biography in the UI</li> <li>Connect separate Langfuse projects \u2014 per-agent API keys for Agent Replay</li> <li>Customize KPI display \u2014 different visible KPIs, card values, and trend lines per agent</li> <li>Search different DB tables \u2014 per-agent trace lookup tables for the Replay search feature</li> <li>Filter dashboards \u2014 the SourceSelector bar lets users switch between agents</li> </ul> <p>All per-agent configuration is optional. Without it, AXIS treats all data uniformly.</p>"},{"location":"configuration/multi-agent/#1-agent-registry-agentsyaml","title":"1. Agent Registry \u2014 <code>agents.yaml</code>","text":"<p>The agent registry defines who your agents are. Each entry maps to a <code>source_name</code> value in your monitoring, KPI, or signals data.</p> custom/config/agents.yaml<pre><code>agents:\n  - name: alpha_bot             # Must match source_name in data\n    label: \"Alpha Bot\"\n    role: \"Customer Support\"\n    avatar: \"/agents/alpha_bot.png\"\n    description: \"Handles inbound customer requests\"\n    biography: |\n      ## About Alpha Bot\n      Alpha Bot processes inbound customer requests using a multi-step\n      reasoning pipeline with tool access.\n    active: true\n    trace_names:              # Langfuse trace aliases\n      - \"alpha_bot-gpt4\"\n      - \"alpha_bot-production\"\n\n  - name: beta_bot\n    label: \"Beta Bot\"\n    role: \"Order Processing\"\n    avatar: \"/agents/beta_bot.png\"\n    description: \"Manages order workflows end to end\"\n    active: true\n    trace_names:\n      - \"beta_bot-v2\"\n</code></pre>"},{"location":"configuration/multi-agent/#key-fields","title":"Key fields","text":"Field Purpose <code>name</code> Must exactly match the <code>source_name</code> column in your data <code>trace_names</code> Langfuse trace names that should map to this agent (useful when trace names differ from <code>name</code>) <code>active</code> Set to <code>false</code> to hide the agent from the SourceSelector <p>See Customization &gt; Agents for the full field reference.</p>"},{"location":"configuration/multi-agent/#2-per-agent-langfuse-credentials","title":"2. Per-Agent Langfuse Credentials","text":"<p>By default, Agent Replay uses the global <code>LANGFUSE_PUBLIC_KEY</code> and <code>LANGFUSE_SECRET_KEY</code>. When agents live in separate Langfuse projects, provide per-agent credentials using this naming pattern:</p> backend/.env<pre><code># Global fallback\nLANGFUSE_PUBLIC_KEY=pk-lf-...\nLANGFUSE_SECRET_KEY=sk-lf-...\nLANGFUSE_HOST=https://cloud.langfuse.com\n\n# Per-agent overrides\nLANGFUSE_ALPHA_BOT_PUBLIC_KEY=pk-lf-alpha-...\nLANGFUSE_ALPHA_BOT_SECRET_KEY=sk-lf-alpha-...\n\nLANGFUSE_BETA_BOT_PUBLIC_KEY=pk-lf-beta-...\nLANGFUSE_BETA_BOT_SECRET_KEY=sk-lf-beta-...\n</code></pre> <p>Agent names in env vars are canonicalized: uppercased, hyphens converted to underscores. So <code>my-agent</code> becomes <code>LANGFUSE_MY_AGENT_PUBLIC_KEY</code>.</p> <p>AXIS discovers these automatically at startup \u2014 no YAML entry needed.</p>"},{"location":"configuration/multi-agent/#3-per-agent-kpi-display-kpi_dbyaml","title":"3. Per-Agent KPI Display \u2014 <code>kpi_db.yaml</code>","text":"<p>The KPI dashboard can show different metrics and display styles per agent.</p>"},{"location":"configuration/multi-agent/#visibility-overrides","title":"Visibility overrides","text":"<p>Control which KPIs appear when a specific agent is selected:</p> custom/config/kpi_db.yaml<pre><code>kpi_db:\n  # Global: show these KPIs for all agents\n  visible_kpis:\n    - auto_resolve_rate\n    - escalation_rate\n    - time_to_response\n\n  # Per-agent: override when an agent is selected\n  visible_kpis_per_source:\n    alpha_bot:\n      - auto_resolve_rate\n      - escalation_rate\n      - actionable_output_rate\n    beta_bot:\n      - time_to_response\n      - correction_rate\n      - resolution_accuracy\n</code></pre>"},{"location":"configuration/multi-agent/#display-overrides","title":"Display overrides","text":"<p>Customize card values and trend lines per agent:</p> custom/config/kpi_db.yaml<pre><code>kpi_db:\n  # Global defaults\n  card_display_value: \"latest\"\n  trend_lines: [\"daily\", \"avg_7d\", \"avg_30d\"]\n\n  # Per-agent display overrides\n  display_per_source:\n    alpha_bot:\n      card_display_value: avg_7d\n      trend_lines: [daily, avg_7d]\n      kpi_overrides:\n        auto_resolve_rate:\n          card_display_value: avg_30d\n    beta_bot:\n      card_display_value: latest\n</code></pre> <p>Resolution order (first match wins):</p> <ol> <li><code>display_per_source.&lt;agent&gt;.kpi_overrides.&lt;kpi&gt;</code> \u2014 agent + KPI specific</li> <li><code>display_per_source.&lt;agent&gt;</code> \u2014 agent-level default</li> <li><code>kpi_overrides.&lt;kpi&gt;</code> \u2014 global KPI override</li> <li>Top-level <code>card_display_value</code> / <code>trend_lines</code> \u2014 global default</li> </ol> <p>See YAML Configs &gt; KPI DB for the full reference.</p>"},{"location":"configuration/multi-agent/#4-per-agent-trace-lookup-agent_replay_dbyaml","title":"4. Per-Agent Trace Lookup \u2014 <code>agent_replay_db.yaml</code>","text":"<p>When different agents store their trace mappings in different database tables (or use different business identifiers), configure per-agent overrides:</p> custom/config/agent_replay_db.yaml<pre><code>agent_replay_db:\n  enabled: true\n  url: \"postgresql://axis_reader:${DB_PASSWORD}@db.example.com:5432/traces\"\n\n  # Defaults (used when no agent override matches)\n  schema: public\n  table: trace_lookup\n  search_column: case_reference\n  search_column_label: Case Reference\n  trace_id_column: langfuse_trace_id\n\n  # Per-agent overrides\n  agents:\n    alpha_bot:\n      table: alpha_bot_cases\n      search_column: case_reference\n      search_column_label: Case Reference\n    beta_bot:\n      table: beta_bot_orders\n      search_column: ticket_number\n      search_column_label: Ticket Number\n      trace_id_column: trace_id\n</code></pre> <p>Only specify the fields that differ \u2014 everything else inherits from the top-level defaults. Agent names are canonicalized (lowercased, hyphens \u2192 underscores).</p> <p>See YAML Configs &gt; Agent Replay DB for the full reference.</p>"},{"location":"configuration/multi-agent/#5-how-agent-filtering-works","title":"5. How Agent Filtering Works","text":"<p>Across the AXIS UI, the SourceSelector bar lets users pick an agent. When an agent is selected:</p> Module What happens Production / KPIs Filters KPI data by <code>source_name</code>, applies <code>visible_kpis_per_source</code> and <code>display_per_source</code> overrides Monitoring Filters time-series by <code>source_name</code> Human Signals Filters signals by <code>source_name</code> Agent Replay Uses per-agent Langfuse credentials and per-agent search DB table/columns Memory Filters extracted rules by <code>agent_name</code> <p>The <code>source_name</code> value in your data must exactly match the <code>name</code> field in <code>agents.yaml</code>.</p>"},{"location":"configuration/multi-agent/#minimal-example","title":"Minimal Example","text":"<p>A two-agent setup with separate Langfuse projects and custom KPI display:</p> custom/config/agents.yaml<pre><code>agents:\n  - name: alpha_bot\n    label: \"Alpha Bot\"\n    role: \"Customer Support\"\n    avatar: \"/agents/alpha_bot.png\"\n  - name: beta_bot\n    label: \"Beta Bot\"\n    role: \"Order Processing\"\n    avatar: \"/agents/beta_bot.png\"\n</code></pre> backend/.env<pre><code>LANGFUSE_ALPHA_BOT_PUBLIC_KEY=pk-lf-...\nLANGFUSE_ALPHA_BOT_SECRET_KEY=sk-lf-...\nLANGFUSE_BETA_BOT_PUBLIC_KEY=pk-lf-...\nLANGFUSE_BETA_BOT_SECRET_KEY=sk-lf-...\nAGENT_REPLAY_ENABLED=true\n</code></pre> custom/config/kpi_db.yaml<pre><code>kpi_db:\n  enabled: true\n  auto_load: true\n  url: \"postgresql://...\"\n  query: \"SELECT ... FROM agent_kpi_logs ...\"\n  visible_kpis_per_source:\n    alpha_bot: [auto_resolve_rate, escalation_rate]\n    beta_bot: [time_to_response, resolution_accuracy]\n</code></pre>"},{"location":"configuration/multi-agent/#related","title":"Related","text":"<ul> <li>Customization &gt; Agents \u2014 agent registry field reference</li> <li>YAML Configs &gt; KPI DB \u2014 KPI database and display config</li> <li>YAML Configs &gt; Agent Replay DB \u2014 trace lookup DB config</li> <li>Environment Variables &gt; Agent Replay \u2014 Langfuse credential env vars</li> <li>Agent Replay Guide \u2014 user guide for the Replay feature</li> </ul>"},{"location":"configuration/theming/","title":"Theming","text":"<p>AXIS ships with a configurable design system that controls colors, branding assets, and the hero section appearance. You can customize the look through a YAML palette, environment variables, or a combination of both.</p>"},{"location":"configuration/theming/#built-in-palettes","title":"Built-in Palettes","text":"<p>Two palettes are available out of the box:</p> Sage GreenProfessional Blue (default) Token Hex Preview <code>primary</code> <code>#8B9F4F</code> <code>primaryLight</code> <code>#A4B86C</code> <code>primaryDark</code> <code>#6B7A3A</code> <code>primarySoft</code> <code>#B8C78A</code> <code>primaryPale</code> <code>#D4E0B8</code> <code>accentGold</code> <code>#D4AF37</code> <code>accentSilver</code> <code>#B8C5D3</code> <p>Natural, approachable, growth-oriented. Suitable for internal tooling and technical audiences.</p> Token Hex Preview <code>primary</code> <code>#3D5A80</code> <code>primaryLight</code> <code>#5C7AA3</code> <code>primaryDark</code> <code>#2B3C73</code> <code>primarySoft</code> <code>#8BA4C4</code> <code>primaryPale</code> <code>#C5D4E8</code> <code>accentGold</code> <code>#D4AF37</code> <code>accentSilver</code> <code>#B8C5D3</code> <p>Trust, stability, expertise. Designed for enterprise clients and investor presentations.</p>"},{"location":"configuration/theming/#customization-methods","title":"Customization Methods","text":""},{"location":"configuration/theming/#option-a-yaml-file-full-control","title":"Option A: YAML File (Full Control)","text":"<p>The YAML approach lets you define complete palettes with branding assets. This is the recommended method for production deployments.</p> <p>Step 1 -- Copy the template:</p> <pre><code>cp backend/config/theme.yaml.example custom/config/theme.yaml\n</code></pre> <p>Step 2 -- Edit <code>custom/config/theme.yaml</code> to set your active palette and define custom palettes:</p> custom/config/theme.yaml<pre><code>theme:\n  active: \"acme_corp\"\n\n  palettes:\n    # Keep the built-ins if you want to switch back\n    sage_green:\n      name: \"Sage Green\"\n      primary: \"#8B9F4F\"\n      primaryLight: \"#A4B86C\"\n      primaryDark: \"#6B7A3A\"\n      primarySoft: \"#B8C78A\"\n      primaryPale: \"#D4E0B8\"\n      accentGold: \"#D4AF37\"\n      accentSilver: \"#B8C5D3\"\n\n    # Your custom branded palette\n    acme_corp:\n      name: \"Acme Corporation\"\n      primary: \"#1E3A5F\"\n      primaryLight: \"#2E5A8F\"\n      primaryDark: \"#0F2A4F\"\n      primarySoft: \"#5E8ABF\"\n      primaryPale: \"#B8D0E8\"\n      accentGold: \"#C9A227\"\n      accentSilver: \"#A8B8C8\"\n      heroImage: \"/api/config/assets/branding/acme-hero.jpg\"\n      logoUrl: \"/api/config/assets/branding/acme-logo.svg\"\n      faviconUrl: \"/api/config/assets/branding/acme-favicon.ico\"\n      appIconUrl: \"/api/config/assets/branding/acme-icon.png\"\n      heroContrast: 0.85\n      heroSaturation: 0.9\n      heroBrightness: 1.1\n      heroOpacity: 0.95\n      heroMode: \"dark\"\n</code></pre> <p>Step 3 -- Restart the backend to load the new theme.</p>"},{"location":"configuration/theming/#option-b-environment-variables-quick-overrides","title":"Option B: Environment Variables (Quick Overrides)","text":"<p>Environment variables let you change the active palette or override individual colors without creating a YAML file. This is useful for CI/CD pipelines or quick experiments.</p> backend/.env<pre><code># Switch to a different built-in palette\nAXIS_THEME_ACTIVE=professional_blue\n\n# Or override individual colors on the active palette\nAXIS_THEME_PRIMARY=#1E3A5F\nAXIS_THEME_PRIMARY_DARK=#0F2A4F\nAXIS_THEME_HERO_IMAGE=/api/config/assets/branding/custom-hero.jpg\nAXIS_THEME_LOGO_URL=/api/config/assets/branding/custom-logo.png\n</code></pre> <p>Precedence: YAML base + env var overrides</p> <p>When both a YAML file and <code>AXIS_THEME_*</code> env vars are present, the YAML palette is loaded first as the base, then env vars override individual values within the active palette. This means you can define a full palette in YAML and tweak one color at deploy time via an env var.</p>"},{"location":"configuration/theming/#option-c-combining-both","title":"Option C: Combining Both","text":"<p>A common pattern is to define your branded palette in YAML and use env vars for per-environment tweaks:</p> custom/config/theme.yaml<pre><code>theme:\n  active: \"acme_corp\"\n  palettes:\n    acme_corp:\n      name: \"Acme Corporation\"\n      primary: \"#1E3A5F\"\n      primaryLight: \"#2E5A8F\"\n      primaryDark: \"#0F2A4F\"\n      primarySoft: \"#5E8ABF\"\n      primaryPale: \"#B8D0E8\"\n      accentGold: \"#C9A227\"\n      accentSilver: \"#A8B8C8\"\n      heroImage: \"/api/config/assets/branding/acme-hero.jpg\"\n      logoUrl: \"/api/config/assets/branding/acme-logo.svg\"\n</code></pre> backend/.env (staging override)<pre><code># Use a different hero image in staging\nAXIS_THEME_HERO_IMAGE=/api/config/assets/branding/staging-banner.jpg\nAXIS_THEME_HERO_OPACITY=0.7\n</code></pre>"},{"location":"configuration/theming/#color-token-reference","title":"Color Token Reference","text":"<p>Every palette consists of the following color tokens. These are applied across the entire UI -- sidebar, headers, buttons, charts, and status indicators.</p> Token Usage <code>primary</code> Main brand color. Sidebar, primary buttons, chart accents <code>primaryLight</code> Hover states, interactive highlights <code>primaryDark</code> Headers, emphasis text, dark accents <code>primarySoft</code> Soft backgrounds, selected states <code>primaryPale</code> Subtle backgrounds, card tints <code>accentGold</code> Call-to-action highlights, premium indicators <code>accentSilver</code> Secondary accents, muted borders"},{"location":"configuration/theming/#branding-assets","title":"Branding Assets","text":""},{"location":"configuration/theming/#asset-paths","title":"Asset Paths","text":"<p>Branding fields (<code>heroImage</code>, <code>logoUrl</code>, <code>faviconUrl</code>, <code>appIconUrl</code>) accept either:</p> <ul> <li>Absolute URLs: <code>https://cdn.example.com/logo.png</code></li> <li>Backend asset proxy paths (recommended): <code>/api/config/assets/branding/logo.png</code></li> </ul>"},{"location":"configuration/theming/#backend-asset-proxy","title":"Backend Asset Proxy","text":"<p>The backend serves branding files from <code>custom/branding/</code> through a dedicated endpoint:</p> <pre><code>GET /api/config/assets/branding/{filename}\n</code></pre> <p>This is the recommended approach for referencing branding assets because it works consistently across all environments:</p> <ul> <li>Local development: The Next.js dev server rewrites <code>/api/config/assets/*</code> requests to the backend at port 8500, so assets resolve automatically.</li> <li>Production: Your reverse proxy (Nginx, Vercel, etc.) routes <code>/api/*</code> to the backend, so the same paths work without any changes.</li> </ul> <p>Using <code>/api/config/assets/branding/*</code> paths eliminates the need to manage symlinks or worry about how static files are served in different deployment targets.</p>"},{"location":"configuration/theming/#branding-assets-in-custombranding","title":"Branding Assets in <code>custom/branding/</code>","text":"<p>Place branding images in <code>custom/branding/</code>. They are served by the backend asset proxy at <code>/api/config/assets/branding/</code>.</p> <pre><code>custom/branding/\n  hero.jpg        --&gt; accessible at /api/config/assets/branding/hero.jpg\n  logo.svg        --&gt; accessible at /api/config/assets/branding/logo.svg\n  ax-icon.png     --&gt; accessible at /api/config/assets/branding/ax-icon.png\n  favicon.ico     --&gt; accessible at /api/config/assets/branding/favicon.ico\n</code></pre> <p>For local development, <code>make setup</code> also creates a symlink (<code>frontend/public/branding -&gt; ../../custom/branding</code>) so that <code>/branding/*</code> paths work directly through Next.js static serving. However, using the <code>/api/config/assets/branding/*</code> paths is preferred because they work in both local and production environments without additional setup.</p> <p>To use a custom hero image:</p> <ol> <li>Place the image file in <code>custom/branding/</code>.</li> <li> <p>Reference it in your theme config:</p> <pre><code>heroImage: \"/api/config/assets/branding/my-hero.jpg\"\n</code></pre> </li> </ol> <p>Cache behavior</p> <p>Branding images served through the asset proxy get a 1-year immutable cache header. Use filename changes (not overwrites) when updating assets.</p>"},{"location":"configuration/theming/#recommended-asset-sizes","title":"Recommended Asset Sizes","text":"Asset Format Recommended Size Hero image JPG, PNG, WebP 1920x400 or wider Logo SVG, PNG 200x50 (landscape) Favicon ICO, PNG 32x32 or 16x16 App icon PNG, SVG 40x40 (square)"},{"location":"configuration/theming/#hero-image-filters","title":"Hero Image Filters","text":"<p>The hero section supports CSS-based image filters to adjust the appearance of your background image without editing the source file.</p> Filter Default Description <code>heroContrast</code> <code>1.0</code> Contrast level. Values below 1.0 reduce contrast <code>heroSaturation</code> <code>1.0</code> Color saturation. Values below 1.0 desaturate toward grayscale <code>heroBrightness</code> <code>1.0</code> Brightness level. Values below 1.0 darken the image <code>heroOpacity</code> <code>1.0</code> Opacity. Values below 1.0 make the image semi-transparent <code>heroMode</code> <code>dark</code> <code>dark</code> uses a dark overlay; <code>light</code> uses a white background <p>Example -- a subtle, professional hero:</p> <pre><code>heroContrast: 0.85\nheroSaturation: 0.8\nheroBrightness: 1.0\nheroOpacity: 0.9\nheroMode: \"dark\"\n</code></pre>"},{"location":"configuration/theming/#fork-white-label-checklist","title":"Fork / White-Label Checklist","text":"<p>When deploying AXIS as a white-labeled product, follow this checklist:</p> <ul> <li> Create <code>custom/config/theme.yaml</code> with your branded palette</li> <li> Set <code>theme.active</code> to your custom palette name</li> <li> Place logo, favicon, app icon, and hero image in <code>custom/branding/</code></li> <li> Set <code>heroImage</code>, <code>logoUrl</code>, <code>faviconUrl</code>, and <code>appIconUrl</code> in the palette</li> <li> Adjust hero filters (<code>heroContrast</code>, <code>heroSaturation</code>, etc.) to match your brand</li> <li> Update <code>APP_NAME</code> in <code>backend/.env</code> if you want a different name in the API docs</li> <li> Test both light and dark mode in the frontend to verify contrast</li> </ul>"},{"location":"configuration/theming/#full-environment-variable-reference","title":"Full Environment Variable Reference","text":"<p>For quick reference, here are all <code>AXIS_THEME_*</code> variables. See Environment Variables for the complete table.</p> Variable Type Description <code>AXIS_THEME_ACTIVE</code> <code>str</code> Active palette name <code>AXIS_THEME_PRIMARY</code> <code>str</code> Primary color (hex) <code>AXIS_THEME_PRIMARY_LIGHT</code> <code>str</code> Primary light (hex) <code>AXIS_THEME_PRIMARY_DARK</code> <code>str</code> Primary dark (hex) <code>AXIS_THEME_PRIMARY_SOFT</code> <code>str</code> Primary soft (hex) <code>AXIS_THEME_PRIMARY_PALE</code> <code>str</code> Primary pale (hex) <code>AXIS_THEME_ACCENT_GOLD</code> <code>str</code> Accent gold (hex) <code>AXIS_THEME_ACCENT_SILVER</code> <code>str</code> Accent silver (hex) <code>AXIS_THEME_HERO_IMAGE</code> <code>str</code> Hero background image <code>AXIS_THEME_LOGO_URL</code> <code>str</code> Logo image <code>AXIS_THEME_FAVICON_URL</code> <code>str</code> Favicon <code>AXIS_THEME_APP_ICON_URL</code> <code>str</code> Sidebar app icon <code>AXIS_THEME_HERO_CONTRAST</code> <code>float</code> Contrast filter <code>AXIS_THEME_HERO_SATURATION</code> <code>float</code> Saturation filter <code>AXIS_THEME_HERO_BRIGHTNESS</code> <code>float</code> Brightness filter <code>AXIS_THEME_HERO_OPACITY</code> <code>float</code> Opacity <code>AXIS_THEME_HERO_MODE</code> <code>str</code> <code>dark</code> or <code>light</code>"},{"location":"configuration/theming/#related","title":"Related","text":"<ul> <li>YAML Configs -- full YAML file schema including theme palette fields</li> <li>Environment Variables -- complete env var reference</li> <li>Configuration Overview -- precedence rules and file layout</li> </ul>"},{"location":"configuration/yaml-configs/","title":"YAML Config Files","text":"<p>AXIS uses YAML files in <code>custom/config/</code> to configure database auto-load connections and the theme system. Each file ships as a <code>.example</code> template in <code>backend/config/</code> that you copy and customize.</p>"},{"location":"configuration/yaml-configs/#setup","title":"Setup","text":"<pre><code># Create custom/ directory and copy all .example templates\nmake setup\n</code></pre> <p>This creates <code>custom/config/</code> and copies each <code>.example</code> template from <code>backend/config/</code> into it. You can also copy individual templates manually:</p> <pre><code>cp backend/config/eval_db.yaml.example custom/config/eval_db.yaml\ncp backend/config/monitoring_db.yaml.example custom/config/monitoring_db.yaml\n# ... etc.\n</code></pre> <p>Precedence reminder</p> <p>For database configs, YAML takes precedence over environment variables. If a YAML file exists and contains a valid config block, the corresponding <code>*_DB_*</code> env vars are not read. See Configuration Overview for the full precedence rules.</p>"},{"location":"configuration/yaml-configs/#database-config-files","title":"Database Config Files","text":"<p>All three database configs (<code>eval_db.yaml</code>, <code>monitoring_db.yaml</code>, <code>human_signals_db.yaml</code>) share the same structure. The only difference is the top-level key name.</p>"},{"location":"configuration/yaml-configs/#common-structure","title":"Common Structure","text":"custom/config/_db.yaml<pre><code>&lt;name&gt;_db:\n  # Master switch\n  enabled: true\n\n  # Auto-load behavior\n  auto_load: true       # Execute query on app startup\n  # auto_connect: true  # Legacy: use table name instead of query\n\n  # Connection -- Option A: full URL (recommended)\n  url: \"postgresql://user:pass@host:5432/dbname\"\n\n  # Connection -- Option B: individual fields\n  # host: \"db.example.com\"\n  # port: 5432\n  # database: \"dbname\"\n  # username: \"axis_reader\"\n  # password: \"secret\"\n  # ssl_mode: \"require\"    # disable | prefer | require\n\n  # Split queries (required for DuckDB sync)\n  dataset_query: |\n    SELECT id AS dataset_id, input AS query, output AS actual_output, ...\n    FROM my_records_table\n    WHERE created_at &gt; NOW() - INTERVAL '7 days'\n\n  results_query: |\n    SELECT record_id AS dataset_id, metric_name, score AS metric_score, ...\n    FROM my_metrics_table\n    WHERE created_at &gt; NOW() - INTERVAL '7 days'\n\n  # Limits\n  query_timeout: 60   # seconds (max 120)\n  row_limit: 10000     # max rows (max 50000)\n\n  # Column mappings (optional)\n  columns:\n    source_column: target_column\n\n  # Performance tuning (optional)\n  partition_column: \"id\"            # Column to split parallel COPY reads\n  incremental_column: \"created_at\"  # Column for watermark-based incremental sync\n  refresh_interval_minutes: 0       # Periodic sync interval (0 = disabled)\n</code></pre>"},{"location":"configuration/yaml-configs/#field-reference","title":"Field Reference","text":"Field Type Default Description <code>enabled</code> <code>bool</code> <code>false</code> Master switch -- must be <code>true</code> to activate <code>auto_load</code> <code>bool</code> <code>false</code> Execute the query automatically on app startup <code>auto_connect</code> <code>bool</code> <code>false</code> Legacy mode: auto-connect using <code>table</code> name <code>url</code> <code>str</code> -- Full PostgreSQL URL. Overrides individual host/port/database fields <code>host</code> <code>str</code> -- Database hostname <code>port</code> <code>int</code> <code>5432</code> Database port <code>database</code> <code>str</code> -- Database name <code>username</code> <code>str</code> -- Database user <code>password</code> <code>str</code> -- Database password <code>schema</code> <code>str</code> <code>public</code> PostgreSQL schema (monitoring and human signals only) <code>table</code> <code>str</code> -- Table name for legacy <code>auto_connect</code> mode <code>ssl_mode</code> <code>str</code> <code>prefer</code> SSL mode: <code>disable</code>, <code>prefer</code>, or <code>require</code> <code>dataset_query</code> <code>str</code> -- SQL query for the records/dataset table. Must include <code>dataset_id</code> <code>results_query</code> <code>str</code> -- SQL query for the metrics/results table. Must include <code>dataset_id</code> <code>query_timeout</code> <code>int</code> <code>60</code> Query timeout in seconds. Clamped to max 120 <code>row_limit</code> <code>int</code> <code>10000</code> Maximum rows returned. Clamped to max 50,000 <code>columns</code> <code>map</code> <code>{}</code> Column name mappings: <code>source_name: axis_name</code> <code>partition_column</code> <code>str</code> -- Column to partition parallel COPY reads on (integer or timestamp) <code>incremental_column</code> <code>str</code> -- Column used as watermark for incremental sync (e.g., <code>created_at</code>) <code>refresh_interval_minutes</code> <code>int</code> <code>0</code> Periodic sync interval in minutes. <code>0</code> = disabled <p>Environment variable placeholders in URLs</p> <p>Connection URLs support <code>${VAR}</code> placeholders for secrets:</p> <pre><code>url: \"postgresql://axis_reader:${DB_PASSWORD}@db.example.com:5432/evals\"\n</code></pre> <p>Set <code>DB_PASSWORD</code> as an environment variable and the runtime will substitute it.</p>"},{"location":"configuration/yaml-configs/#column-mappings","title":"Column Mappings","text":"<p>The <code>columns</code> map lets you rename your database columns to match the AXIS schema without rewriting your SQL query. The format is <code>source_column: axis_column</code>.</p> Evaluation columnsMonitoring columnsHuman Signals columns <pre><code>columns:\n  my_id_field: dataset_id\n  user_prompt: query\n  llm_response: actual_output\n  gold_answer: expected_output\n  run_name: evaluation_name\n  eval_metric: metric_name\n  eval_score: metric_score\n</code></pre> <p>If no <code>columns</code> mapping is provided, AXIS auto-normalizes common names: <code>id</code> / <code>record_id</code> to <code>dataset_id</code>, <code>input</code> / <code>prompt</code> to <code>query</code>, <code>output</code> / <code>response</code> to <code>actual_output</code>, etc.</p> <pre><code>columns:\n  record_id: dataset_id\n  created_at: timestamp\n  user_input: query\n  model_response: actual_output\n  metric: metric_name\n  score: metric_score\n  env: environment\n  app_name: source_name\n  component: source_component\n</code></pre> <pre><code>columns:\n  id: Case_ID\n  thread: Thread_ID\n  company: Business\n  intervened: Has_Intervention\n  intervention: Intervention_Type\n  friction: Friction_Point\n  mood: Sentiment\n  notes: Human_Summary\n  result: Final_Outcome\n  msg_count: Message_Count\n  agent: Agent_Name\n  created_at: Timestamp\n</code></pre>"},{"location":"configuration/yaml-configs/#eval-db-eval_dbyaml","title":"Eval DB \u2013 <code>eval_db.yaml</code>","text":"<p>Loads evaluation data (experiments, metric scores) into the Evaluate and Analytics pages.</p> custom/config/eval_db.yaml<pre><code>eval_db:\n  enabled: true\n  auto_load: true\n  url: \"postgresql://axis_reader:${DB_PASSWORD}@db.example.com:5432/evaluations\"\n\n  # Feature flag: enable/disable the batch Evaluation Runner\n  eval_runner_enabled: true\n\n  dataset_query: |\n    SELECT\n      e.id AS dataset_id,\n      e.experiment_name AS evaluation_name,\n      e.input AS query,\n      e.output AS actual_output,\n      e.expected AS expected_output,\n      e.metadata AS data_metadata\n    FROM evaluations e\n    WHERE e.created_at &gt; NOW() - INTERVAL '7 days'\n\n  results_query: |\n    SELECT\n      m.eval_id AS dataset_id,\n      m.metric_name,\n      m.score AS metric_score\n    FROM metrics m\n    JOIN evaluations e ON e.id = m.eval_id\n    WHERE e.created_at &gt; NOW() - INTERVAL '7 days'\n\n  query_timeout: 60\n  row_limit: 10000\n</code></pre> <p>Disabling the Evaluation Runner</p> <p>Set <code>eval_runner_enabled: false</code> to hide the batch evaluation wizard from the Evaluate page. The Runner tab shows a lock icon and \"Disabled by Admin\" tooltip. This is useful for read-only deployments where users should only view results.</p>"},{"location":"configuration/yaml-configs/#monitoring-db-monitoring_dbyaml","title":"Monitoring DB \u2013 <code>monitoring_db.yaml</code>","text":"<p>Loads observability data (time-series metrics, traces) into the Monitoring page.</p> custom/config/monitoring_db.yaml<pre><code>monitoring_db:\n  enabled: true\n  auto_load: true\n  url: \"postgresql://axis_reader:${DB_PASSWORD}@db.example.com:5432/monitoring\"\n\n  dataset_query: |\n    SELECT\n      e.id AS dataset_id,\n      e.created_at AS timestamp,\n      e.input AS query,\n      e.output AS actual_output,\n      e.environment,\n      e.source_name,\n      e.source_component,\n      e.trace_id,\n      e.latency\n    FROM evaluation_logs e\n    WHERE e.created_at &gt; NOW() - INTERVAL '7 days'\n\n  results_query: |\n    SELECT\n      m.log_id AS dataset_id,\n      m.metric_name,\n      m.score AS metric_score,\n      m.metric_type,\n      m.metric_category,\n      m.explanation\n    FROM metrics m\n    JOIN evaluation_logs e ON e.id = m.log_id\n    WHERE e.created_at &gt; NOW() - INTERVAL '7 days'\n\n  # Performance tuning\n  partition_column: \"id\"\n  incremental_column: \"created_at\"\n  refresh_interval_minutes: 15\n\n  query_timeout: 60\n  row_limit: 10000\n\n  # Anomaly detection (optional)\n  anomaly_detection:\n    enabled: true\n    min_data_points: 5\n\n    # Z-Score: flags points that deviate significantly from the mean\n    z_score_enabled: true\n    z_score_threshold: 2.0           # standard deviations\n    z_score_severity: \"warning\"      # warning | error\n    z_score_lookback_window: 20      # historical points to use\n    z_score_metrics: []              # empty = all metrics\n\n    # Moving Average: flags points that deviate from the rolling average\n    ma_enabled: true\n    ma_window_size: 5\n    ma_deviation_threshold: 0.15     # 15% deviation\n    ma_severity: \"warning\"\n    ma_metrics: []\n\n    # Rate of Change: flags sudden jumps between consecutive points\n    roc_enabled: true\n    roc_threshold: 0.3               # 30% change\n    roc_severity: \"error\"\n    roc_metrics: []\n</code></pre>"},{"location":"configuration/yaml-configs/#anomaly-detection","title":"Anomaly Detection","text":"<p>The <code>anomaly_detection</code> block enables automatic anomaly flagging on monitoring trend data. Three detection methods run independently and produce severity-tagged annotations on trend charts.</p> Field Type Default Description <code>enabled</code> <code>bool</code> <code>false</code> Master switch for anomaly detection <code>min_data_points</code> <code>int</code> <code>5</code> Minimum points before detection activates (min 3) <code>z_score_enabled</code> <code>bool</code> <code>true</code> Enable z-score detection <code>z_score_threshold</code> <code>float</code> <code>2.0</code> Standard deviations from mean to flag <code>z_score_severity</code> <code>str</code> <code>warning</code> <code>warning</code> or <code>error</code> <code>z_score_lookback_window</code> <code>int</code> <code>20</code> Historical window size <code>z_score_metrics</code> <code>list</code> <code>[]</code> Restrict to specific metrics (empty = all) <code>ma_enabled</code> <code>bool</code> <code>true</code> Enable moving average detection <code>ma_window_size</code> <code>int</code> <code>5</code> Rolling window size (min 2) <code>ma_deviation_threshold</code> <code>float</code> <code>0.15</code> Fractional deviation from moving average <code>ma_severity</code> <code>str</code> <code>warning</code> <code>warning</code> or <code>error</code> <code>ma_metrics</code> <code>list</code> <code>[]</code> Restrict to specific metrics (empty = all) <code>roc_enabled</code> <code>bool</code> <code>true</code> Enable rate-of-change detection <code>roc_threshold</code> <code>float</code> <code>0.3</code> Fractional change between consecutive points <code>roc_severity</code> <code>str</code> <code>error</code> <code>warning</code> or <code>error</code> <code>roc_metrics</code> <code>list</code> <code>[]</code> Restrict to specific metrics (empty = all)"},{"location":"configuration/yaml-configs/#human-signals-db-human_signals_dbyaml","title":"Human Signals DB \u2013 <code>human_signals_db.yaml</code>","text":"<p>Loads human-in-the-loop signal data into the Human Signals page.</p> custom/config/human_signals_db.yaml<pre><code>human_signals_db:\n  enabled: true\n  auto_load: true\n  url: \"postgresql://axis_reader:${DB_PASSWORD}@db.example.com:5432/human_signals\"\n\n  dataset_query: |\n    SELECT\n      c.id AS Case_ID,\n      c.thread_id AS Thread_ID,\n      c.business_name AS Business,\n      c.message_count AS Message_Count,\n      c.agent_name AS Agent_Name,\n      c.created_at AS Timestamp\n    FROM hitl_cases c\n    WHERE c.created_at &gt; NOW() - INTERVAL '30 days'\n\n  results_query: |\n    SELECT\n      r.case_id AS Case_ID,\n      r.has_intervention AS Has_Intervention,\n      r.intervention_type AS Intervention_Type,\n      r.friction_point AS Friction_Point,\n      r.sentiment AS Sentiment,\n      r.human_summary AS Human_Summary,\n      r.final_outcome AS Final_Outcome\n    FROM hitl_results r\n    JOIN hitl_cases c ON c.id = r.case_id\n    WHERE c.created_at &gt; NOW() - INTERVAL '30 days'\n\n  query_timeout: 60\n  row_limit: 10000\n</code></pre>"},{"location":"configuration/yaml-configs/#theme-config-themeyaml","title":"Theme Config \u2013 <code>theme.yaml</code>","text":"<p>Controls the AXIS color palette, branding assets, and hero image. See the Theming page for a detailed guide.</p> custom/config/theme.yaml<pre><code>theme:\n  # Active palette -- must match a key under 'palettes'\n  active: \"sage_green\"\n\n  palettes:\n    sage_green:\n      name: \"Sage Green\"\n      primary: \"#8B9F4F\"\n      primaryLight: \"#A4B86C\"\n      primaryDark: \"#6B7A3A\"\n      primarySoft: \"#B8C78A\"\n      primaryPale: \"#D4E0B8\"\n      accentGold: \"#D4AF37\"\n      accentSilver: \"#B8C5D3\"\n      # Branding assets (optional)\n      # heroImage: \"/api/config/assets/branding/hero.jpg\"\n      # logoUrl: \"/api/config/assets/branding/logo.png\"\n      # faviconUrl: \"/api/config/assets/branding/favicon.ico\"\n      # appIconUrl: \"/api/config/assets/branding/ax-icon.png\"\n\n    professional_blue:\n      name: \"Professional Blue\"\n      primary: \"#3D5A80\"\n      primaryLight: \"#5C7AA3\"\n      primaryDark: \"#2B3C73\"\n      primarySoft: \"#8BA4C4\"\n      primaryPale: \"#C5D4E8\"\n      accentGold: \"#D4AF37\"\n      accentSilver: \"#B8C5D3\"\n</code></pre>"},{"location":"configuration/yaml-configs/#palette-fields","title":"Palette Fields","text":"Field Type Description <code>name</code> <code>str</code> Display name for the palette <code>primary</code> <code>hex</code> Primary brand color <code>primaryLight</code> <code>hex</code> Lighter variant for hover states <code>primaryDark</code> <code>hex</code> Darker variant for headers and emphasis <code>primarySoft</code> <code>hex</code> Soft background highlights <code>primaryPale</code> <code>hex</code> Subtle backgrounds <code>accentGold</code> <code>hex</code> Gold accent for CTAs and highlights <code>accentSilver</code> <code>hex</code> Silver accent for secondary elements <code>heroImage</code> <code>str</code> URL or path to hero background image <code>logoUrl</code> <code>str</code> URL or path to logo image <code>faviconUrl</code> <code>str</code> URL or path to browser tab favicon <code>appIconUrl</code> <code>str</code> URL or path to sidebar app icon <code>heroContrast</code> <code>float</code> CSS contrast filter (1.0 = normal) <code>heroSaturation</code> <code>float</code> CSS saturation filter (1.0 = normal) <code>heroBrightness</code> <code>float</code> CSS brightness filter (1.0 = normal) <code>heroOpacity</code> <code>float</code> Image opacity (1.0 = fully visible) <code>heroMode</code> <code>str</code> Hero section mode: <code>dark</code> (default) or <code>light</code>"},{"location":"configuration/yaml-configs/#duckdb-config-duckdbyaml","title":"DuckDB Config \u2013 <code>duckdb.yaml</code>","text":"<p>Controls the embedded DuckDB analytics store. See the DuckDB Configuration page for a detailed guide.</p> custom/config/duckdb.yaml<pre><code>duckdb:\n  enabled: true\n  path: \"data/local_store.duckdb\"\n  sync_mode: \"startup\"\n  sync_chunk_size: 10000\n  max_sync_rows: 2000000\n  query_concurrency: 8\n  sync_workers: 4\n</code></pre> Field Type Default Description <code>enabled</code> <code>bool</code> <code>true</code> Master switch for the DuckDB store <code>path</code> <code>str</code> <code>data/local_store.duckdb</code> DuckDB file path (relative to <code>backend/</code>) <code>sync_mode</code> <code>str</code> <code>\"startup\"</code> Global startup behavior: <code>\"startup\"</code> or <code>\"manual\"</code> <code>sync_chunk_size</code> <code>int</code> <code>10000</code> Rows per chunk during sync <code>max_sync_rows</code> <code>int</code> <code>2000000</code> Safety cap -- sync stops and warns if hit <code>query_concurrency</code> <code>int</code> <code>8</code> Max concurrent DuckDB read threads <code>sync_workers</code> <code>int</code> <code>1</code> Parallel readers per dataset sync. Requires <code>partition_column</code> in DB config"},{"location":"configuration/yaml-configs/#kpi-db-kpi_dbyaml","title":"KPI DB \u2013 <code>kpi_db.yaml</code>","text":"<p>Loads Agent KPI data (operational metrics, trend lines) into the Production dashboard. Unlike the eval/monitoring/human-signals configs, KPI uses a single query (no dataset/results split) and adds display-layer configuration for card values, trend lines, and per-agent overrides.</p> custom/config/kpi_db.yaml<pre><code>kpi_db:\n  # Master switch\n  enabled: true\n  auto_load: true\n\n  # Connection -- Option A: full URL (recommended)\n  url: \"postgresql://axis_reader:${DB_PASSWORD}@db.example.com:5432/kpi_data\"\n\n  # Connection -- Option B: individual fields\n  # host: \"db.example.com\"\n  # port: 5432\n  # database: \"kpi_data\"\n  # username: \"axis_reader\"\n  # password: \"secret\"\n  # ssl_mode: \"require\"\n\n  # Single query (no dataset/results split)\n  query: |\n    SELECT\n      k.kpi_name,\n      k.kpi_category,\n      k.numeric_value,\n      k.source_name,\n      k.environment,\n      k.source_type,\n      k.recorded_at\n    FROM agent_kpi_logs k\n    WHERE k.recorded_at &gt; NOW() - INTERVAL '90 days'\n\n  query_timeout: 60\n  row_limit: 50000\n\n  # --- Visibility Filters ---\n  visible_kpis: []                     # Empty = show all KPIs\n  # visible_kpis:\n  #   - auto_resolve_rate\n  #   - time_to_response\n  #   - escalation_rate\n\n  # Per-agent KPI visibility (takes precedence over visible_kpis)\n  # visible_kpis_per_source:\n  #   alpha_bot:\n  #     - auto_resolve_rate\n  #     - escalation_rate\n  #   beta_bot:\n  #     - time_to_response\n  #     - correction_rate\n\n  # --- Display Configuration ---\n  card_display_value: \"latest\"         # latest | avg_7d | avg_30d\n  trend_lines: [\"daily\", \"avg_7d\", \"avg_30d\"]\n\n  # Category metadata (auto-discovered from kpi_category if omitted)\n  categories:\n    operational_efficiency:\n      display_name: Operational Efficiency\n      icon: Zap\n    commercial_impact:\n      display_name: Commercial Impact\n      icon: TrendingUp\n\n  # Per-KPI display overrides\n  kpi_overrides:\n    auto_resolve_rate:\n      display_name: Auto-Resolve Rate\n      unit: percent                    # percent | seconds | count | score\n      polarity: higher_better          # higher_better | lower_better\n      card_display_value: avg_7d       # Override global setting\n    time_to_response:\n      display_name: Time to Response\n      unit: seconds\n      polarity: lower_better\n\n  # Per-agent display overrides (resolution: source+kpi &gt; source &gt; global kpi &gt; default)\n  # display_per_source:\n  #   alpha_bot:\n  #     card_display_value: avg_7d\n  #     trend_lines: [daily, avg_7d]\n  #     kpi_overrides:\n  #       auto_resolve_rate:\n  #         card_display_value: avg_30d\n\n  # Performance tuning\n  # refresh_interval_minutes: 15\n  # incremental_column: \"recorded_at\"\n</code></pre>"},{"location":"configuration/yaml-configs/#kpi-field-reference","title":"KPI Field Reference","text":"Field Type Default Description <code>enabled</code> <code>bool</code> <code>false</code> Master switch -- must be <code>true</code> to activate <code>auto_load</code> <code>bool</code> <code>false</code> Execute the query on app startup <code>url</code> <code>str</code> -- Full PostgreSQL URL (overrides individual fields) <code>host</code> <code>str</code> -- Database hostname <code>port</code> <code>int</code> <code>5432</code> Database port <code>database</code> <code>str</code> -- Database name <code>username</code> <code>str</code> -- Database user <code>password</code> <code>str</code> -- Database password <code>ssl_mode</code> <code>str</code> <code>prefer</code> SSL mode: <code>disable</code>, <code>prefer</code>, <code>require</code> <code>query</code> <code>str</code> -- SQL query to load KPI data. Must return <code>kpi_name</code>, <code>numeric_value</code>, and ideally <code>kpi_category</code>, <code>source_name</code>, <code>recorded_at</code> <code>query_timeout</code> <code>int</code> <code>60</code> Query timeout in seconds (max 120) <code>row_limit</code> <code>int</code> <code>50000</code> Max rows (max 50,000) <code>visible_kpis</code> <code>list</code> <code>[]</code> KPI names to display. Empty = show all <code>visible_kpis_per_source</code> <code>map</code> <code>{}</code> Per-agent KPI visibility overrides <code>card_display_value</code> <code>str</code> <code>latest</code> Main card number: <code>latest</code>, <code>avg_7d</code>, <code>avg_30d</code> <code>trend_lines</code> <code>list</code> <code>[daily, avg_7d, avg_30d]</code> Trend lines on expanded charts <code>categories</code> <code>map</code> <code>{}</code> Category slug \u2192 <code>{display_name, icon}</code>. Empty = auto-discover from data <code>kpi_overrides</code> <code>map</code> <code>{}</code> Per-KPI display customization (<code>display_name</code>, <code>unit</code>, <code>polarity</code>, etc.) <code>display_per_source</code> <code>map</code> <code>{}</code> Per-agent display overrides with nested <code>kpi_overrides</code> <code>refresh_interval_minutes</code> <code>int</code> <code>0</code> Periodic sync interval (0 = disabled) <code>incremental_column</code> <code>str</code> -- Watermark column for incremental sync <p>Display resolution order</p> <p>When the frontend renders a KPI card, it resolves display settings in this order (first match wins):</p> <ol> <li><code>display_per_source.&lt;agent&gt;.kpi_overrides.&lt;kpi&gt;</code> -- agent + KPI specific</li> <li><code>display_per_source.&lt;agent&gt;</code> -- agent-level default</li> <li><code>kpi_overrides.&lt;kpi&gt;</code> -- global KPI override</li> <li>Top-level <code>card_display_value</code> / <code>trend_lines</code> -- global default</li> </ol>"},{"location":"configuration/yaml-configs/#agent-replay-db-agent_replay_dbyaml","title":"Agent Replay DB \u2013 <code>agent_replay_db.yaml</code>","text":"<p>Connects the Agent Replay search feature to a PostgreSQL lookup table that maps business identifiers (e.g., case references, ticket numbers) to Langfuse trace IDs. This is optional \u2014 trace ID search works without a database.</p> custom/config/agent_replay_db.yaml<pre><code>agent_replay_db:\n  # Master switch\n  enabled: true\n\n  # Connection -- Option A: full URL (recommended)\n  url: \"postgresql://axis_reader:${DB_PASSWORD}@db.example.com:5432/agent_traces\"\n\n  # Connection -- Option B: individual fields\n  # host: \"db.example.com\"\n  # port: 5432\n  # database: \"agent_traces\"\n  # username: \"axis_reader\"\n  # password: \"changeme\"\n  # ssl_mode: \"require\"\n\n  # Default schema and table\n  schema: public\n  table: trace_lookup\n\n  # Searchable columns \u2014 maps DB column names to display labels.\n  # All entries appear in the frontend search dropdown.\n  # Omit or leave empty for trace-ID-only search.\n  search_columns:\n    case_reference: Case Reference\n    # business_name: Business Name\n\n  trace_id_column: langfuse_trace_id    # Column containing the Langfuse trace ID\n  # agent_name_column: agent_name       # Column with agent name (optional)\n\n  # Per-agent overrides (only override what differs from defaults)\n  # agents:\n  #   alpha_bot:\n  #     table: alpha_bot_cases\n  #     search_columns:\n  #       case_reference: Case Reference\n  #     trace_id_column: langfuse_trace_id\n  #   beta_bot:\n  #     table: beta_bot_cases\n  #     search_columns:\n  #       ticket_number: Ticket Number\n  #       business_name: Business Name\n  #     trace_id_column: langfuse_trace_id\n\n  # Timeouts and pool\n  query_timeout: 10\n  connect_timeout: 10\n  pool_min_size: 0\n  pool_max_size: 5\n</code></pre>"},{"location":"configuration/yaml-configs/#agent-replay-db-field-reference","title":"Agent Replay DB Field Reference","text":"Field Type Default Description <code>enabled</code> <code>bool</code> <code>false</code> Master switch for the search database <code>url</code> <code>str</code> -- Full PostgreSQL URL (overrides individual fields) <code>host</code> <code>str</code> -- Database hostname <code>port</code> <code>int</code> <code>5432</code> Database port <code>database</code> <code>str</code> -- Database name <code>username</code> <code>str</code> -- Database user <code>password</code> <code>str</code> -- Database password <code>ssl_mode</code> <code>str</code> <code>prefer</code> SSL mode: <code>disable</code>, <code>prefer</code>, <code>require</code> <code>schema</code> <code>str</code> <code>public</code> PostgreSQL schema <code>table</code> <code>str</code> <code>trace_lookup</code> Default lookup table name <code>search_columns</code> <code>map</code> <code>{}</code> Maps DB column names to display labels. Each entry appears in the frontend search dropdown. Empty = trace ID only <code>trace_id_column</code> <code>str</code> <code>langfuse_trace_id</code> Column containing the Langfuse trace ID <code>agent_name_column</code> <code>str</code> -- Column with agent name (optional, enables agent-aware lookup) <code>agents</code> <code>map</code> <code>{}</code> Per-agent overrides for <code>table</code>, <code>search_columns</code>, <code>trace_id_column</code> <code>query_timeout</code> <code>int</code> <code>10</code> Query timeout in seconds (max 30) <code>connect_timeout</code> <code>int</code> <code>10</code> Connection timeout in seconds (max 30) <code>pool_min_size</code> <code>int</code> <code>0</code> Minimum idle connections <code>pool_max_size</code> <code>int</code> <code>5</code> Maximum connections (max 20) <p>Per-agent overrides</p> <p>When different agents store traces in different tables or use different business identifiers, use the <code>agents</code> map to override column/table settings per agent. Only specify the fields that differ \u2014 everything else inherits from the top-level defaults.</p> <p>Agent names are canonicalized (lowercased, hyphens \u2192 underscores) to match the naming convention used by Langfuse credential discovery.</p>"},{"location":"configuration/yaml-configs/#agent-replay-config-agent_replayyaml","title":"Agent Replay Config \u2013 <code>agent_replay.yaml</code>","text":"<p>Non-secret defaults for the Agent Replay plugin. Langfuse credentials are always set via environment variables (see Environment Variables).</p> custom/config/agent_replay.yaml<pre><code>agent_replay:\n  default_limit: 20              # Max recent traces to show (1-100)\n  default_days_back: 7           # How far back to look for traces (1-90)\n  max_chars: 50000               # Default truncation limit for step content (1-200000)\n  search_metadata_key: caseReference  # Langfuse metadata key used for smart search\n</code></pre>"},{"location":"configuration/yaml-configs/#field-reference_1","title":"Field Reference","text":"Field Type Default Description <code>default_limit</code> <code>int</code> <code>20</code> Maximum number of recent traces to return per request (1--100) <code>default_days_back</code> <code>int</code> <code>7</code> Default lookback window in days (1--90) <code>max_chars</code> <code>int</code> <code>50000</code> Truncation limit for observation input/output content (1--200,000) <code>search_metadata_key</code> <code>str</code> <code>caseReference</code> Langfuse metadata key used for smart search matching <p>Langfuse credentials are env-var-only</p> <p>API keys (<code>LANGFUSE_PUBLIC_KEY</code>, <code>LANGFUSE_SECRET_KEY</code>, per-agent variants) are never stored in YAML. Set them as environment variables or in <code>backend/.env</code>.</p>"},{"location":"configuration/yaml-configs/#signals-metrics-config-signals_metricsyaml","title":"Signals Metrics Config \u2013 <code>signals_metrics.yaml</code>","text":"<p>An optional display configuration file for the Human Signals V2 dashboard. It overrides auto-discovered defaults with domain-specific labels, colors, icons, and chart layout preferences. Remove this file to use fully auto-generated configuration.</p> custom/config/signals_metrics.yaml<pre><code>signals_metrics:\n  kpi_strip:\n    - metric: intervention_type\n      signal: is_stp\n      label: \"STP Rate\"\n      format: percent\n      icon: zap\n\n  chart_sections:\n    - title: \"Outcome Distribution\"\n      layout: full          # full | grid_2 | grid_3\n      charts:\n        - metric: resolution_status\n          signal: final_status\n          type: stacked_bar  # bar | donut | horizontal_bar | ...\n          title: \"Resolution Status\"\n\n  color_maps:\n    intervention_type__intervention_type:\n      no_intervention: \"#8B9F4F\"\n      tech_issue: \"#C0392B\"\n\n  source_filters:\n    - field: source_name\n      label: \"Source\"\n</code></pre>"},{"location":"configuration/yaml-configs/#field-reference_2","title":"Field Reference","text":"Field Type Default Description <code>kpi_strip</code> <code>list</code> <code>[]</code> KPI cards shown at the top of the dashboard. Each item specifies <code>metric</code>, <code>signal</code>, <code>label</code>, <code>format</code> (<code>percent</code>, <code>count</code>, <code>number</code>), and <code>icon</code> (Lucide name) <code>chart_sections</code> <code>list</code> <code>[]</code> Groups of charts. Each section has <code>title</code>, <code>layout</code> (<code>full</code>, <code>grid_2</code>, <code>grid_3</code>), and a <code>charts</code> list <code>chart_sections[].charts[]</code> <code>object</code> -- Chart definition: <code>metric</code>, <code>signal</code>, <code>type</code> (<code>bar</code>, <code>donut</code>, <code>horizontal_bar</code>, <code>stacked_bar</code>, <code>line</code>), <code>title</code> <code>color_maps</code> <code>map</code> <code>{}</code> Custom color assignments for chart values. Key format: <code>&lt;metric&gt;__&lt;signal&gt;</code>, value: <code>{category_value: hex_color}</code> <code>source_filters</code> <code>list</code> <code>[]</code> Filter dropdowns for the dashboard. Each item: <code>field</code> (column name), <code>label</code> (display text) <p>Auto-discovery vs explicit config</p> <p>When <code>signals_metrics.yaml</code> is absent, the Human Signals dashboard auto-discovers metrics from the data and generates default KPI strips, chart sections, and color maps. Add the YAML file only when you want to customize display names, chart types, layouts, or colors.</p>"},{"location":"configuration/yaml-configs/#memory-config-memoryyaml","title":"Memory Config \u2013 <code>memory.yaml</code>","text":"<p>Controls how the Memory module interprets CSV columns, which fields appear as filters, and how computed views (hard stops, decision quality, conflicts) are derived. The module works out of the box with no config file \u2014 every setting has a sensible default matching the standard column names.</p> custom/config/memory.yaml<pre><code>memory:\n  # --- Field Role Mappings ---\n  # Maps functional roles to your CSV column names.\n  # Defaults match the standard column names if omitted.\n  field_roles:\n    id: id\n    name: rule_name\n    action: action\n    category: risk_category\n    group_by: risk_factor\n    product: product_type\n    quality: decision_quality\n    threshold_type: threshold_type\n    threshold_value: threshold\n    description: outcome_description\n    mitigants: mitigants\n    status: ingestion_status\n    batch: batch_id\n    agent: agent_name\n    created_at: created_at\n    confidence: confidence\n    compound_trigger: compound_trigger\n    source: source\n    source_type: source_type\n    historical_exceptions: historical_exceptions\n    data_fields: data_fields\n    ingestion_error: ingestion_error\n    ingested_at: ingested_at\n\n  # Roles that MUST exist in uploaded data (upload fails if missing)\n  required_roles: [id, name, action, batch, status]\n\n  # Display labels for roles (auto-titlecased from role name if omitted)\n  labels:\n    action: Action\n    category: Risk Category\n    group_by: Risk Factor\n    product: Product Type\n    quality: Decision Quality\n    threshold_type: Threshold\n    status: Status\n    name: Rule Name\n    description: Outcome\n\n  # Roles containing list/array data (parsed from CSV comma-separated strings)\n  list_fields: [mitigants, data_fields]\n\n  # Which roles appear as filter dropdowns (order = UI order)\n  filter_roles: [action, product, category, threshold_type, status]\n\n  # --- Computed View Config ---\n  hard_stops:\n    action_value: decline              # Which action value is a \"hard stop\"\n    require_empty_mitigants: true      # Must have zero mitigants to qualify\n\n  quality_values:\n    aligned: aligned\n    divergent: divergent\n    partial: partial\n\n  soft_threshold_value: soft           # threshold_type value for \"soft\" thresholds\n\n  # --- Action colors (for summary charts) ---\n  action_colors:\n    decline: \"#E74C3C\"\n    refer: \"#F39C12\"\n    approve_with_conditions: \"#3498DB\"\n    flag_for_review: \"#9B59B6\"\n    verify: \"#1ABC9C\"\n    exclude: \"#E67E22\"\n\n  # --- Contradictory action pairs (for conflict detection) ---\n  contradictory_pairs:\n    - [decline, approve_with_conditions]\n    - [decline, verify]\n    - [exclude, refer]\n    - [exclude, approve_with_conditions]\n</code></pre>"},{"location":"configuration/yaml-configs/#how-it-works","title":"How It Works","text":"<p>The Memory module maps CSV columns to role names at import time. Internally, all storage, API responses, and frontend rendering use role names \u2014 the raw CSV column names are never exposed past the ingest boundary.</p> <pre><code>CSV Upload \u2192 field_roles mapping \u2192 Role-keyed storage \u2192 API \u2192 Frontend\n</code></pre> <p>This means you can use any CSV column names by adjusting <code>field_roles</code>. For example, if your CSV uses <code>compliance_area</code> instead of <code>risk_category</code>:</p> <pre><code>field_roles:\n  category: compliance_area   # Maps \"category\" role to your column name\n</code></pre>"},{"location":"configuration/yaml-configs/#field-reference_3","title":"Field Reference","text":"Field Type Default Description <code>field_roles</code> <code>map</code> Standard column names Maps each functional role (e.g. <code>name</code>, <code>action</code>) to your CSV column name <code>required_roles</code> <code>list</code> <code>[id, name, action, batch, status]</code> Roles that must exist in uploaded data. Upload fails with a clear error if missing <code>labels</code> <code>map</code> Titlecased role names Display labels for each role in the UI (filters, table headers) <code>list_fields</code> <code>list</code> <code>[mitigants, data_fields]</code> Roles containing comma-separated list data <code>filter_roles</code> <code>list</code> <code>[action, product, category, threshold_type, status]</code> Roles shown as filter dropdowns (order = UI order) <code>hard_stops.action_value</code> <code>str</code> <code>decline</code> Action value that identifies hard stop rules <code>hard_stops.require_empty_mitigants</code> <code>bool</code> <code>true</code> Whether hard stops must also have zero mitigants <code>quality_values.aligned</code> <code>str</code> <code>aligned</code> Value in the <code>quality</code> role for aligned rules <code>quality_values.divergent</code> <code>str</code> <code>divergent</code> Value in the <code>quality</code> role for divergent rules <code>quality_values.partial</code> <code>str</code> <code>partial</code> Value in the <code>quality</code> role for partial rules <code>soft_threshold_value</code> <code>str</code> <code>soft</code> Value in <code>threshold_type</code> role for soft thresholds <code>action_colors</code> <code>map</code> See example Color hex codes for each action value in summary charts <code>contradictory_pairs</code> <code>list</code> See example Pairs of action values that conflict (triggers conflict banner)"},{"location":"configuration/yaml-configs/#config-validation","title":"Config Validation","text":"<p>The loader validates at startup:</p> <ul> <li><code>field_roles</code> values are unique (no two roles map to the same column)</li> <li>All <code>required_roles</code> entries are valid role names</li> <li>All <code>list_fields</code> entries are valid role names</li> <li>All <code>filter_roles</code> entries are valid role names</li> <li><code>hard_stops</code> has required keys with correct types</li> <li><code>quality_values</code> has all three keys (<code>aligned</code>, <code>divergent</code>, <code>partial</code>)</li> </ul> <p>Invalid config produces a clear error message in the server log and falls back to defaults.</p>"},{"location":"configuration/yaml-configs/#config-api","title":"Config API","text":"<p>The frontend fetches memory config from <code>GET /api/config/memory</code>, which returns the full config including a <code>config_hash</code> for cache invalidation. The frontend <code>useMemoryConfig()</code> hook caches this with <code>staleTime: Infinity</code>.</p>"},{"location":"configuration/yaml-configs/#related","title":"Related","text":"<ul> <li>Environment Variables -- env var reference (fallback when YAML is absent)</li> <li>Data Sources -- CSV upload vs. Postgres auto-load setup guide</li> <li>Theming -- detailed branding and customization guide</li> <li>Memory Guide -- user guide for the Memory dashboard</li> <li>Agent Replay Guide -- user guide for the Agent Replay feature</li> </ul>"},{"location":"deployment/","title":"Deployment","text":"<p>AXIS ships as a monorepo with two independently deployable services:</p> Service Runtime Default Port Image Base Frontend Next.js 14 (standalone) 3500 <code>node:20-alpine</code> Backend FastAPI + Uvicorn 8500 <code>python:3.12-slim</code> <p>Both services include production-ready Dockerfiles and a <code>docker-compose.yml</code> for local orchestration. For production, you typically place a reverse proxy in front of the two containers to handle TLS termination, compression, and path-based routing.</p>"},{"location":"deployment/#deployment-options","title":"Deployment Options","text":"Approach Best For Complexity Docker Compose Local dev, staging, single-server Low Container orchestrator (K8s, ECS, Cloud Run) Production, auto-scaling Medium--High Bare-metal / VM Air-gapped environments Medium"},{"location":"deployment/#architecture-at-a-glance","title":"Architecture at a Glance","text":"<pre><code>flowchart LR\n    Browser --&gt;|HTTPS| RP[Reverse Proxy]\n    RP --&gt;|:3500| FE[Frontend&lt;br/&gt;Next.js]\n    RP --&gt;|:8500| BE[Backend&lt;br/&gt;FastAPI]\n    FE --&gt;|NEXT_PUBLIC_API_URL| BE\n    BE --&gt; DB[(PostgreSQL)]\n    DB --&gt;|Sync| DUCK[(DuckDB)]\n    BE --&gt; DUCK\n    BE --&gt; Graph[(FalkorDB)]</code></pre> <p>The frontend calls the backend via <code>NEXT_PUBLIC_API_URL</code>. The backend reads <code>FRONTEND_URL</code> to configure its CORS allow-list. PostgreSQL data is synced into a local DuckDB file that serves all analytics queries. All other secrets (API keys, database credentials) live exclusively in the backend runtime environment.</p>"},{"location":"deployment/#quick-links","title":"Quick Links","text":"<ul> <li> <p> Docker</p> <p>Run AXIS locally with Docker Compose or build production images.</p> <p> Docker guide</p> </li> <li> <p> Production</p> <p>Reverse proxy setup, health checks, scaling, and database configuration.</p> <p> Production guide</p> </li> <li> <p> Security</p> <p>Secrets management, CORS, frontend exposure risks, and hardening tips.</p> <p> Security notes</p> </li> <li> <p> DuckDB Sync Runbook</p> <p>Split sync, incremental refresh, periodic scheduler, and watermark management for PostgreSQL -&gt; DuckDB.</p> <p> Sync runbook</p> </li> </ul>"},{"location":"deployment/#deployment-checklist","title":"Deployment Checklist","text":"<p>Use this as a final gate before going live:</p> <ul> <li> Frontend <code>NEXT_PUBLIC_API_URL</code> points to the production backend</li> <li> Backend <code>FRONTEND_URL</code> (and optional <code>FRONTEND_URLS</code>) matches frontend origins</li> <li> All secrets (API keys, DB passwords) exist only in backend runtime env</li> <li> <code>DEBUG=false</code> is set on the backend</li> <li> Backend runs Uvicorn without <code>--reload</code></li> <li> YAML auto-load configs (<code>custom/config/*.yaml</code>) are present in the image or mounted (controlled by <code>AXIS_CUSTOM_DIR</code> in containers)</li> <li> DuckDB config (<code>custom/config/duckdb.yaml</code>) is present with <code>sync_mode: \"startup\"</code></li> <li> Persistent volume mounted at <code>backend/data/</code> for DuckDB file</li> <li> Monitoring sync pattern defined (split queries + incremental refresh via <code>incremental_column</code>)</li> <li> Periodic sync configured (<code>refresh_interval_minutes &gt; 0</code>) or external scheduler wired</li> <li> Health checks (<code>GET /health</code>) are wired into your orchestrator</li> <li> TLS is terminated at the reverse proxy or load balancer</li> <li> <code>.env</code> files are excluded from the container image (<code>.dockerignore</code>)</li> </ul>"},{"location":"deployment/docker/","title":"Docker","text":"<p>AXIS includes Dockerfiles for both services and a <code>docker-compose.yml</code> at the repository root for one-command orchestration.</p>"},{"location":"deployment/docker/#prerequisites","title":"Prerequisites","text":"<ul> <li>Docker Engine 20.10+ (or Docker Desktop)</li> <li>Docker Compose v2+</li> </ul>"},{"location":"deployment/docker/#quick-start-with-docker-compose","title":"Quick Start with Docker Compose","text":"<p>From the repository root:</p> <pre><code># Create a root-level .env (used by docker-compose.yml)\ncat &gt; .env &lt;&lt;'EOF'\nOPENAI_API_KEY=your_key_here\nANTHROPIC_API_KEY=your_key_here\nDB_PASSWORD=your_db_password\nEOF\n\n# Start services (frontend, backend, falkordb)\ndocker compose up --build\n</code></pre> Service URL Frontend http://localhost:3500 Backend http://localhost:8500 API Docs http://localhost:8500/docs FalkorDB <code>localhost:6379</code> <p>Press ++ctrl+c++ to stop both services.</p>"},{"location":"deployment/docker/#docker-composeyml-reference","title":"docker-compose.yml Reference","text":"<p>The default Compose file ships configured for development (hot-reload, volume mounts):</p> docker-compose.yml<pre><code>services:\n  falkordb:\n    image: falkordb/falkordb:latest\n    ports:\n      - \"6379:6379\"\n    volumes:\n      - ./data/falkordb:/var/lib/falkordb/data\n\n  frontend:\n    build:\n      context: ./frontend\n      dockerfile: Dockerfile\n    ports:\n      - \"3500:3500\"\n    environment:\n      - NEXT_PUBLIC_API_URL=http://localhost:8500\n    volumes:\n      - ./frontend:/app\n      - /app/node_modules\n      - /app/.next\n    depends_on:\n      - backend\n    command: npm run dev\n\n  backend:\n    build:\n      context: ./backend\n      dockerfile: Dockerfile\n    ports:\n      - \"8500:8500\"\n    environment:\n      - HOST=0.0.0.0\n      - PORT=8500\n      - DEBUG=true\n      - FRONTEND_URL=http://localhost:3500\n      - GRAPH_DB_HOST=${GRAPH_DB_HOST:-falkordb}\n      - GRAPH_DB_PORT=${GRAPH_DB_PORT:-6379}\n      - GRAPH_DB_NAME=${GRAPH_DB_NAME:-knowledge_graph}\n      - GRAPH_DB_PASSWORD=${GRAPH_DB_PASSWORD:-}\n    env_file:\n      - .env\n    volumes:\n      - ./backend:/app\n      - ./data:/app/data\n    command: uvicorn app.main:app --host 0.0.0.0 --port 8500 --reload\n    depends_on:\n      - falkordb\n\nvolumes:\n  node_modules:\n</code></pre>"},{"location":"deployment/docker/#key-points","title":"Key Points","text":"Setting Purpose <code>NEXT_PUBLIC_API_URL</code> Tells the frontend where the backend lives <code>FRONTEND_URL</code> Primary frontend origin allowed by backend CORS <code>FRONTEND_URLS</code> Optional comma-separated additional CORS origins (e.g. preview URLs) <code>GRAPH_DB_*</code> Connects backend graph endpoints to FalkorDB <code>env_file: [.env]</code> Injects backend secrets (API keys, DB credentials) <code>depends_on</code> Ensures service startup order (<code>frontend -&gt; backend</code>, <code>backend -&gt; falkordb</code>) Volume mounts Enable hot-reload during development"},{"location":"deployment/docker/#environment-variables-in-docker","title":"Environment Variables in Docker","text":"<p>Environment variables can be provided in three ways:</p> Inline in Composeenv_fileShell export <pre><code>environment:\n  - DEBUG=true\n  - FRONTEND_URL=http://localhost:3500\n</code></pre> <pre><code>env_file:\n  - .env\n</code></pre> <p>The <code>.env</code> file should live at the repository root (next to <code>docker-compose.yml</code>). It is git-ignored by default.</p> <pre><code>export OPENAI_API_KEY=sk-...\ndocker compose up\n</code></pre> <p>Docker Compose automatically interpolates host environment variables into the Compose file.</p> <p>Never bake secrets into an image</p> <p>Do not use <code>ENV</code> in a Dockerfile for API keys or passwords. Pass them at runtime via <code>environment</code> or <code>env_file</code> in Compose, or via your orchestrator's secrets manager.</p>"},{"location":"deployment/docker/#building-production-images","title":"Building Production Images","text":"<p>The Dockerfiles support multi-stage builds. To build production-optimized images:</p>"},{"location":"deployment/docker/#frontend","title":"Frontend","text":"<p>The frontend Dockerfile has four stages: <code>base</code>, <code>deps</code>, <code>builder</code>, and <code>runner</code>. The final <code>runner</code> stage produces a minimal image with only the standalone Next.js output.</p> <pre><code>docker build \\\n  --target runner \\\n  -t axis-frontend:latest \\\n  ./frontend\n</code></pre> <p>The production image runs as a non-root user (<code>nextjs</code>, UID 1001) and serves the standalone bundle via <code>node server.js</code>.</p>"},{"location":"deployment/docker/#backend","title":"Backend","text":"<pre><code>docker build \\\n  -t axis-backend:latest \\\n  ./backend\n</code></pre> <p>The backend image runs as a non-root user (<code>appuser</code>, UID 1000). The default command is already production-oriented (no hot-reload) and is compatible with platforms like Cloud Run using <code>${PORT}</code>:</p> <pre><code>docker run -p 8500:8500 \\\n  -e PORT=8500 \\\n  -e DEBUG=false \\\n  -e FRONTEND_URL=https://your-frontend.example.com \\\n  -e FRONTEND_URLS=https://your-frontend.example.com,https://preview-your-team.vercel.app \\\n  --env-file .env \\\n  axis-backend:latest\n</code></pre>"},{"location":"deployment/docker/#production-compose-override","title":"Production Compose Override","text":"<p>For production, create a <code>docker-compose.prod.yml</code> override that removes volume mounts and dev commands:</p> docker-compose.prod.yml<pre><code>services:\n  frontend:\n    build:\n      context: ./frontend\n      dockerfile: Dockerfile\n      target: runner\n    volumes: []  # No source mounts in production\n    command: [\"node\", \"server.js\"]\n    environment:\n      - NEXT_PUBLIC_API_URL=https://api.your-domain.com\n\n  backend:\n    volumes: []  # No source mounts in production\n    environment:\n      - DEBUG=false\n      - FRONTEND_URL=https://your-domain.com\n      - FRONTEND_URLS=https://your-domain.com,https://preview-your-team.vercel.app\n      - PORT=8500\n</code></pre> <p>Run with both files:</p> <pre><code>docker compose -f docker-compose.yml -f docker-compose.prod.yml up --build -d\n</code></pre>"},{"location":"deployment/docker/#useful-commands","title":"Useful Commands","text":"<pre><code># Rebuild images after dependency changes\ndocker compose build --no-cache\n\n# View logs\ndocker compose logs -f backend\ndocker compose logs -f frontend\n\n# Run a one-off command in the backend container\ndocker compose exec backend python -m pytest\n\n# Tear down containers and volumes\ndocker compose down -v\n</code></pre>"},{"location":"deployment/docker/#related","title":"Related","text":"<ul> <li>Production -- reverse proxy, health checks, and scaling</li> <li>Security -- secrets management and hardening</li> <li>Environment Variables -- full env var reference</li> </ul>"},{"location":"deployment/duckdb-sync-runbook/","title":"DuckDB Sync Runbook","text":"<p>This runbook covers production-friendly patterns for loading data from PostgreSQL into DuckDB:</p> <ol> <li>Configure split queries (dataset + results)</li> <li>Run an initial one-time backfill</li> <li>Enable incremental sync with periodic scheduling</li> <li>Manage watermarks and force rebuilds when needed</li> </ol>"},{"location":"deployment/duckdb-sync-runbook/#recommended-pattern","title":"Recommended Pattern","text":"<ul> <li>Keep PostgreSQL as source of truth</li> <li>Treat DuckDB as an analytics cache</li> <li>Use split queries (<code>dataset_query</code> + <code>results_query</code>) for each data source</li> <li>Enable incremental sync via <code>incremental_column</code> for low-latency refreshes</li> <li>Use the periodic scheduler (<code>refresh_interval_minutes</code>) for automatic sync</li> <li>Reserve <code>?full=true</code> for schema changes or data corrections</li> </ul>"},{"location":"deployment/duckdb-sync-runbook/#1-configure-split-queries","title":"1) Configure Split Queries","text":"<p>Each database config now uses two queries instead of one. The sync engine reads both concurrently and joins them as a DuckDB view.</p> custom/config/monitoring_db.yaml<pre><code>monitoring_db:\n  enabled: true\n  auto_load: true\n  url: \"postgresql://axis_reader:${DB_PASSWORD}@prod-db.internal:5432/observability\"\n\n  dataset_query: |\n    SELECT\n      trace_id AS dataset_id,\n      timestamp,\n      prompt AS query,\n      completion AS actual_output,\n      deployment_env AS environment,\n      service_name AS source_name,\n      component_name AS source_component,\n      response_time_ms AS latency\n    FROM llm_traces\n    ORDER BY timestamp DESC\n\n  results_query: |\n    SELECT\n      trace_id AS dataset_id,\n      metric_name,\n      metric_value AS metric_score,\n      metric_category,\n      explanation\n    FROM llm_metric_results\n    ORDER BY created_at DESC\n\n  # Performance tuning\n  partition_column: \"id\"            # Enables parallel COPY reads\n  incremental_column: \"created_at\"  # Enables watermark-based incremental sync\n  refresh_interval_minutes: 15      # Auto-sync every 15 minutes\n  query_timeout: 120\n</code></pre> <p>Both queries must include <code>dataset_id</code></p> <p>The <code>dataset_query</code> and <code>results_query</code> are joined on <code>dataset_id</code> in DuckDB. Make sure both queries alias or include a column named <code>dataset_id</code>.</p>"},{"location":"deployment/duckdb-sync-runbook/#2-run-initial-one-time-backfill","title":"2) Run Initial One-Time Backfill","text":"<p>Trigger the first sync to populate DuckDB:</p> <pre><code>curl -X POST \"https://YOUR_BACKEND_DOMAIN/api/store/sync/monitoring\"\n</code></pre> <p>Poll status:</p> <pre><code>curl \"https://YOUR_BACKEND_DOMAIN/api/store/status\"\n</code></pre> <p>Wait for <code>monitoring_data.state</code> to become <code>ready</code>. The first sync always does a full rebuild (staging + atomic swap) since no watermarks exist yet.</p>"},{"location":"deployment/duckdb-sync-runbook/#3-enable-incremental-sync","title":"3) Enable Incremental Sync","text":"<p>After the initial backfill, subsequent syncs use incremental mode automatically when <code>incremental_column</code> is configured:</p> <ul> <li>The sync engine reads the stored watermark (MAX value of <code>incremental_column</code> from the previous sync)</li> <li>Each query is wrapped with <code>WHERE {column} &gt; '{watermark}'</code></li> <li>New rows are appended to existing DuckDB tables (INSERT INTO, no staging swap)</li> <li>Watermarks are updated to the new MAX value</li> </ul>"},{"location":"deployment/duckdb-sync-runbook/#verify-incremental-mode","title":"Verify Incremental Mode","text":"<p>Check the status endpoint to see watermarks and sync type:</p> <pre><code>curl \"https://YOUR_BACKEND_DOMAIN/api/store/status\" | jq '.datasets.monitoring_data'\n</code></pre> <p>Expected output:</p> <pre><code>{\n  \"state\": \"ready\",\n  \"rows\": 150000,\n  \"sync_type\": \"incremental\",\n  \"last_incremental\": \"2026-02-13T10:15:00+00:00\",\n  \"incremental_rows\": 1200,\n  \"watermarks\": {\n    \"monitoring_dataset\": \"2026-02-13T10:00:00\",\n    \"monitoring_results\": \"2026-02-13T10:00:00\"\n  },\n  \"refresh_interval_minutes\": 15,\n  \"incremental_column\": \"created_at\"\n}\n</code></pre>"},{"location":"deployment/duckdb-sync-runbook/#4-periodic-sync-built-in-scheduler","title":"4) Periodic Sync (Built-in Scheduler)","text":"<p>If <code>refresh_interval_minutes &gt; 0</code> is set in the database config, the backend automatically schedules periodic syncs:</p> <ol> <li>The scheduler starts after the startup sync completes</li> <li>It sleeps until the next dataset is due</li> <li>Syncs all due datasets concurrently using incremental mode</li> <li>Repeats until the application shuts down</li> </ol> <p>No external scheduler (Cloud Scheduler, cron) is needed for this pattern.</p>"},{"location":"deployment/duckdb-sync-runbook/#recommended-production-config","title":"Recommended Production Config","text":"custom/config/monitoring_db.yaml<pre><code>monitoring_db:\n  refresh_interval_minutes: 15\n  incremental_column: created_at\n</code></pre> custom/config/duckdb.yaml<pre><code>duckdb:\n  sync_mode: \"startup\"      # Initial full sync on boot\n  sync_workers: 4            # Parallel COPY readers\n</code></pre>"},{"location":"deployment/duckdb-sync-runbook/#5-external-scheduling-alternative","title":"5) External Scheduling (Alternative)","text":"<p>If you prefer external scheduling over the built-in scheduler (e.g., for centralized job management), set <code>refresh_interval_minutes: 0</code> and trigger syncs via API.</p>"},{"location":"deployment/duckdb-sync-runbook/#cloud-scheduler-gcp","title":"Cloud Scheduler (GCP)","text":"<pre><code>gcloud scheduler jobs create http axis-monitoring-sync-daily \\\n  --location=us-central1 \\\n  --schedule=\"*/15 * * * *\" \\\n  --uri=\"https://YOUR_CLOUD_RUN_URL/api/store/sync/monitoring\" \\\n  --http-method=POST \\\n  --oidc-service-account-email=\"scheduler-invoker@YOUR_PROJECT_ID.iam.gserviceaccount.com\" \\\n  --oidc-token-audience=\"https://YOUR_CLOUD_RUN_URL\" \\\n  --time-zone=\"Etc/UTC\"\n</code></pre> <p>Grant invoker permission:</p> <pre><code>gcloud run services add-iam-policy-binding YOUR_SERVICE_NAME \\\n  --region=us-central1 \\\n  --member=\"serviceAccount:scheduler-invoker@YOUR_PROJECT_ID.iam.gserviceaccount.com\" \\\n  --role=\"roles/run.invoker\"\n</code></pre>"},{"location":"deployment/duckdb-sync-runbook/#6-watermark-management","title":"6) Watermark Management","text":""},{"location":"deployment/duckdb-sync-runbook/#view-watermarks","title":"View Watermarks","text":"<pre><code>curl \"https://YOUR_BACKEND_DOMAIN/api/store/status\"\n</code></pre> <p>Each dataset shows per-sub-table watermarks (e.g., <code>monitoring_dataset</code>, <code>monitoring_results</code>).</p>"},{"location":"deployment/duckdb-sync-runbook/#reset-watermarks","title":"Reset Watermarks","text":"<p>Force the next sync to do a full rebuild by clearing watermarks:</p> <pre><code>curl -X POST \"https://YOUR_BACKEND_DOMAIN/api/store/sync/monitoring/reset-watermark\"\n</code></pre>"},{"location":"deployment/duckdb-sync-runbook/#force-full-rebuild","title":"Force Full Rebuild","text":"<p>Skip incremental mode for a single sync run:</p> <pre><code>curl -X POST \"https://YOUR_BACKEND_DOMAIN/api/store/sync/monitoring?full=true\"\n</code></pre>"},{"location":"deployment/duckdb-sync-runbook/#when-to-force-a-full-rebuild","title":"When to Force a Full Rebuild","text":"<ul> <li>After schema changes in the source database</li> <li>After data corrections or backfills in Postgres</li> <li>If incremental sync produces unexpected results</li> <li>When watermarks become stale (e.g., after a long outage)</li> </ul> <p>Auto-recovery on failure</p> <p>If an incremental sync fails, watermarks are automatically cleared. The next sync will do a full rebuild without manual intervention.</p>"},{"location":"deployment/duckdb-sync-runbook/#7-operational-checks","title":"7) Operational Checks","text":"<p>After each sync run:</p> <ul> <li><code>GET /api/store/status</code> to verify <code>state=ready</code></li> <li>Check <code>sync_type</code> \u2014 should be <code>\"incremental\"</code> for regular refreshes</li> <li>Check <code>incremental_rows</code> \u2014 should be &gt; 0 if source data is changing</li> <li>Alert on repeated <code>error</code> state or timeouts</li> </ul>"},{"location":"deployment/duckdb-sync-runbook/#troubleshooting","title":"Troubleshooting","text":"Symptom Cause Fix <code>sync_type: \"full\"</code> every time No <code>incremental_column</code> or watermarks cleared Add <code>incremental_column</code> to DB config <code>incremental_rows: 0</code> No new data since last sync Expected if source is quiet <code>state: \"error\"</code> Query timeout or connection failure Check <code>query_timeout</code>, source DB health <code>truncated: true</code> Hit <code>max_sync_rows</code> cap Use WHERE clauses to limit volume, or increase cap Slow sync Large tables without COPY Add <code>partition_column</code> and increase <code>sync_workers</code> <p>If the query still times out at 120s:</p> <ul> <li>Reduce the time window in your WHERE clause (e.g., 7 days instead of 30)</li> <li>Add indexes on source Postgres (<code>timestamp</code>, join/filter columns)</li> <li>Add <code>partition_column</code> to enable parallel COPY reads</li> <li>Simplify joins or precompute a materialized view</li> </ul>"},{"location":"deployment/production/","title":"Production Deployment","text":"<p>This guide covers the recommended setup for running AXIS in a production environment. The core pattern is: build container images, place a reverse proxy in front, and configure environment variables for production.</p>"},{"location":"deployment/production/#production-architecture","title":"Production Architecture","text":"<pre><code>flowchart TD\n    Client[Browser] --&gt;|HTTPS| LB[Load Balancer / Reverse Proxy]\n    LB --&gt;|/| FE[Frontend :3500]\n    LB --&gt;|/api/*| BE[Backend :8500]\n    BE --&gt; PG[(PostgreSQL)]\n    PG --&gt;|Split sync| SE[Sync Engine]\n    SE --&gt; DUCK[(DuckDB&lt;br/&gt;Analytics Store)]\n    BE --&gt; DUCK\n    BE --&gt; GDB[(FalkorDB)]\n    BE --&gt; LLM[LLM Provider API]</code></pre> <p>The reverse proxy handles TLS termination, gzip compression, and routes traffic to the appropriate service based on path prefix. The sync engine reads from PostgreSQL and writes to a local DuckDB file that serves all analytics queries.</p>"},{"location":"deployment/production/#recommended-pattern-vercel-gcp","title":"Recommended Pattern: Vercel + GCP","text":"<p>For most teams, a strong default is:</p> <ul> <li>Frontend on Vercel (Next.js hosting, previews, CDN edge delivery)</li> <li>Backend on GCP Cloud Run (containerized FastAPI API)</li> </ul> <p>Benefits:</p> <ul> <li>Independent deploy/release cadence for frontend and backend</li> <li>Frontend previews without redeploying backend</li> <li>Managed autoscaling for the API</li> </ul> <p>Key requirements:</p> <ul> <li>Set <code>NEXT_PUBLIC_API_URL</code> in Vercel to your Cloud Run URL</li> <li>Set backend <code>FRONTEND_URL</code> (and optionally <code>FRONTEND_URLS</code>) to your Vercel origins</li> <li>If using FalkorDB, host it where Cloud Run can reach it (private network/VPC as needed)</li> </ul>"},{"location":"deployment/production/#reverse-proxy-setup","title":"Reverse Proxy Setup","text":"<p>Any reverse proxy works (Nginx, Caddy, Traefik, AWS ALB, Cloudflare Tunnel). Below are examples for the two most common choices.</p> NginxCaddy nginx.conf<pre><code>upstream frontend {\n    server frontend:3500;\n}\n\nupstream backend {\n    server backend:8500;\n}\n\nserver {\n    listen 443 ssl http2;\n    server_name axis.your-domain.com;\n\n    ssl_certificate     /etc/ssl/certs/axis.pem;\n    ssl_certificate_key /etc/ssl/private/axis.key;\n\n    # Compression\n    gzip on;\n    gzip_types text/plain application/json application/javascript text/css;\n\n    # Frontend\n    location / {\n        proxy_pass http://frontend;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n    }\n\n    # Backend API\n    location /api/ {\n        proxy_pass http://backend;\n        proxy_set_header Host $host;\n        proxy_set_header X-Real-IP $remote_addr;\n        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n        proxy_set_header X-Forwarded-Proto $scheme;\n\n        # SSE support (AI Copilot streaming)\n        proxy_buffering off;\n        proxy_cache off;\n        proxy_read_timeout 300s;\n    }\n\n    # Health check pass-through\n    location /health {\n        proxy_pass http://backend/health;\n    }\n}\n</code></pre> Caddyfile<pre><code>axis.your-domain.com {\n    # Frontend\n    reverse_proxy / frontend:3500\n\n    # Backend API\n    reverse_proxy /api/* backend:8500\n    reverse_proxy /health backend:8500\n    reverse_proxy /docs backend:8500\n    reverse_proxy /openapi.json backend:8500\n}\n</code></pre> <p>Caddy handles TLS certificates automatically via Let's Encrypt.</p> <p>SSE endpoints</p> <p>The AI Copilot uses Server-Sent Events for streaming responses. Make sure your proxy has <code>proxy_buffering off</code> (Nginx) or equivalent to avoid buffering SSE chunks.</p>"},{"location":"deployment/production/#environment-configuration","title":"Environment Configuration","text":""},{"location":"deployment/production/#frontend","title":"Frontend","text":"<p>The frontend has a single required variable. It is set at build time because Next.js inlines <code>NEXT_PUBLIC_*</code> values into the JavaScript bundle.</p> Frontend environment<pre><code>NEXT_PUBLIC_API_URL=https://api.your-domain.com\n</code></pre> <p>Build-time variable</p> <p><code>NEXT_PUBLIC_API_URL</code> is embedded during <code>npm run build</code>. If you change the backend URL, you must rebuild the frontend image.</p>"},{"location":"deployment/production/#backend","title":"Backend","text":"Backend environment<pre><code># Server\nHOST=0.0.0.0\n# Cloud Run sets PORT automatically; keep default 8500 for local containers\nPORT=8500\nDEBUG=false\n\n# CORS -- must include your production frontend origin\nFRONTEND_URL=https://axis.your-domain.com\n# Optional additional origins (comma-separated), useful for preview/staging domains\nFRONTEND_URLS=https://axis.your-domain.com,https://preview-your-team.vercel.app\n\n# AI keys (required for Copilot and LLM judge features)\nOPENAI_API_KEY=sk-...\nANTHROPIC_API_KEY=sk-ant-...\nLLM_MODEL_NAME=gpt-4o-mini\n\n# Database (if using PostgreSQL auto-load)\nEVAL_DB_URL=postgresql://user:pass@db-host:5432/axis_eval\nMONITORING_DB_URL=postgresql://user:pass@db-host:5432/axis_monitoring\nHUMAN_SIGNALS_DB_URL=postgresql://user:pass@db-host:5432/axis_human_signals\n\n# Graph DB (if using Memory -&gt; Knowledge Graph)\nGRAPH_DB_HOST=falkordb.internal\nGRAPH_DB_PORT=6379\nGRAPH_DB_NAME=knowledge_graph\nGRAPH_DB_PASSWORD=...\n</code></pre> <p>See the Environment Variables reference for the complete list.</p>"},{"location":"deployment/production/#health-checks","title":"Health Checks","text":"<p>The backend exposes two health endpoints:</p>"},{"location":"deployment/production/#get-simple-ping","title":"<code>GET /</code> -- Simple ping","text":"<p>Returns the service name and version. Useful for basic liveness probes.</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"service\": \"AXIS API\",\n  \"version\": \"0.1.0\"\n}\n</code></pre>"},{"location":"deployment/production/#get-health-component-health","title":"<code>GET /health</code> -- Component health","text":"<p>Returns the status of internal components. Use this for readiness probes.</p> <pre><code>{\n  \"status\": \"healthy\",\n  \"components\": {\n    \"api\": \"up\",\n    \"data_processor\": \"up\"\n  }\n}\n</code></pre>"},{"location":"deployment/production/#wiring-health-checks","title":"Wiring Health Checks","text":"Docker ComposeKubernetesAWS ECS <pre><code>services:\n  backend:\n    healthcheck:\n      test: [\"CMD\", \"curl\", \"-f\", \"http://localhost:8500/health\"]\n      interval: 30s\n      timeout: 10s\n      retries: 3\n      start_period: 15s\n</code></pre> <pre><code>livenessProbe:\n  httpGet:\n    path: /\n    port: 8500\n  initialDelaySeconds: 10\n  periodSeconds: 30\n\nreadinessProbe:\n  httpGet:\n    path: /health\n    port: 8500\n  initialDelaySeconds: 5\n  periodSeconds: 10\n</code></pre> <pre><code>{\n  \"healthCheck\": {\n    \"command\": [\"CMD-SHELL\", \"curl -f http://localhost:8500/health || exit 1\"],\n    \"interval\": 30,\n    \"timeout\": 10,\n    \"retries\": 3,\n    \"startPeriod\": 15\n  }\n}\n</code></pre>"},{"location":"deployment/production/#uvicorn-configuration","title":"Uvicorn Configuration","text":"<p>In production, run Uvicorn without <code>--reload</code> and with multiple workers:</p> <pre><code>uvicorn app.main:app \\\n  --host 0.0.0.0 \\\n  --port 8500 \\\n  --workers 4 \\\n  --log-level info \\\n  --access-log\n</code></pre> Flag Dev Prod <code>--reload</code> Yes No <code>--workers</code> 1 (default) 2--4 (1 per CPU core) <code>--log-level</code> <code>debug</code> <code>info</code> or <code>warning</code> <code>--access-log</code> Optional Recommended <p>Worker count</p> <p>Each Uvicorn worker is an independent process. Start with <code>--workers 2</code> and increase based on load. If you run behind a process manager like Gunicorn, use its worker model instead:</p> <pre><code>gunicorn app.main:app \\\n  -w 4 \\\n  -k uvicorn.workers.UvicornWorker \\\n  --bind 0.0.0.0:8500\n</code></pre>"},{"location":"deployment/production/#database-configuration-in-production","title":"Database Configuration in Production","text":"<p>AXIS supports three database connections (evaluation, monitoring, human signals). Each can be configured via YAML files or environment variables.</p>"},{"location":"deployment/production/#option-1-environment-variables","title":"Option 1 -- Environment variables","text":"<p>Set connection URLs directly in your deployment environment:</p> <pre><code>EVAL_DB_URL=postgresql://user:pass@db-host:5432/axis_eval\nEVAL_DB_AUTO_LOAD=true\nEVAL_DB_QUERY=SELECT * FROM evaluations WHERE created_at &gt; NOW() - INTERVAL '30 days'\n</code></pre>"},{"location":"deployment/production/#option-2-yaml-config-files","title":"Option 2 -- YAML config files","text":"<p>Bake YAML files into the image or mount them at runtime:</p> custom/config/eval_db.yaml<pre><code>eval_db:\n  enabled: true\n  auto_load: true\n  url: \"postgresql://axis_user:${DB_PASSWORD}@db-host:5432/axis_eval\"\n  ssl_mode: require\n\n  dataset_query: |\n    SELECT id AS dataset_id, experiment_name AS evaluation_name,\n           input AS query, output AS actual_output, expected AS expected_output\n    FROM evaluations\n    WHERE created_at &gt; NOW() - INTERVAL '30 days'\n\n  results_query: |\n    SELECT eval_id AS dataset_id, metric_name, score AS metric_score\n    FROM metrics\n    WHERE created_at &gt; NOW() - INTERVAL '30 days'\n\n  query_timeout: 60\n  row_limit: 50000\n</code></pre>"},{"location":"deployment/production/#providing-yaml-files-to-containers","title":"Providing YAML files to containers","text":"<p>Set <code>AXIS_CUSTOM_DIR</code> so <code>resolve_config_path()</code> finds your files inside the container. See Customization &gt; Deployment Strategies for full examples.</p> Bake into imageVolume mountKubernetes ConfigMap <p>Add the custom directory during the Docker build:</p> <pre><code>COPY custom/ /app/custom/\nENV AXIS_CUSTOM_DIR=/app/custom\n</code></pre> <p>Mount at runtime via Compose or CLI:</p> <pre><code>environment:\n  - AXIS_CUSTOM_DIR=/app/custom\nvolumes:\n  - ./custom:/app/custom:ro\n</code></pre> <pre><code>env:\n  - name: AXIS_CUSTOM_DIR\n    value: /app/custom\nvolumeMounts:\n  - name: axis-config\n    mountPath: /app/custom/config\n    readOnly: true\nvolumes:\n  - name: axis-config\n    configMap:\n      name: axis-db-configs\n</code></pre> <p>YAML takes precedence</p> <p>When a YAML config file exists, the corresponding environment variables are ignored entirely. See Configuration &gt; YAML Configs for details.</p>"},{"location":"deployment/production/#duckdb-storage","title":"DuckDB Storage","text":"<p>The backend uses an embedded DuckDB file as an analytics cache. In containerized deployments, mount a persistent volume so the DuckDB file survives container restarts:</p> docker-compose.yml<pre><code>services:\n  backend:\n    volumes:\n      - axis-data:/app/data\nvolumes:\n  axis-data:\n</code></pre> <p>Configure DuckDB via <code>custom/config/duckdb.yaml</code>:</p> <pre><code>duckdb:\n  enabled: true\n  path: \"data/local_store.duckdb\"\n  sync_mode: \"startup\"\n  sync_workers: 4\n</code></pre> <p>For production sync patterns (incremental sync, periodic scheduler, watermark management), see the DuckDB Sync Runbook.</p>"},{"location":"deployment/production/#scaling-considerations","title":"Scaling Considerations","text":""},{"location":"deployment/production/#frontend_1","title":"Frontend","text":"<p>The Next.js standalone build is stateless. Scale horizontally by running multiple replicas behind a load balancer. No session affinity is required.</p>"},{"location":"deployment/production/#backend_1","title":"Backend","text":"<p>The backend maintains a local DuckDB file for analytics queries. When scaling:</p> <ul> <li>Single replica (recommended): The DuckDB file is local to the process. A single replica with multiple Uvicorn workers shares the same DuckDB file. The sync engine uses OS file locks to coordinate writes.</li> <li>Multiple replicas: Each replica manages its own DuckDB file and sync cycle. All replicas read from the same Postgres source, so data is eventually consistent. This is acceptable for read-heavy workloads.</li> <li>CSV upload mode: Data is held in memory per worker. Uploads only affect the replica that received the request. Acceptable for single-user or demo deployments.</li> </ul>"},{"location":"deployment/production/#resource-estimates","title":"Resource Estimates","text":"Service CPU Memory Notes Frontend 0.25 vCPU 256 MB Static assets, minimal server logic Backend (per worker) 0.5 vCPU 512 MB--1 GB Scales with dataset size; DuckDB sync and Pandas are memory-bound"},{"location":"deployment/production/#related","title":"Related","text":"<ul> <li>Docker -- image building and Compose reference</li> <li>DuckDB Sync Runbook -- one-time backfill + daily scheduled sync</li> <li>Security -- secrets, CORS, and hardening</li> <li>Environment Variables -- complete env var reference</li> <li>Data Sources -- CSV vs. database ingestion patterns</li> </ul>"},{"location":"deployment/security/","title":"Security","text":"<p>This page covers security best practices for deploying AXIS. While AXIS is designed as an internal evaluation tool, following these guidelines protects your data, credentials, and infrastructure.</p>"},{"location":"deployment/security/#secrets-management","title":"Secrets Management","text":""},{"location":"deployment/security/#never-commit-env-files","title":"Never commit <code>.env</code> files","text":"<p>The <code>.env</code> file contains API keys, database passwords, and other credentials. It is git-ignored by default, but verify your <code>.gitignore</code> includes:</p> <pre><code>.env\n.env.local\n.env.*.local\nbackend/.env\nfrontend/.env.local\n</code></pre> <p>Audit before pushing</p> <p>Run <code>git diff --cached --name-only</code> before every commit to ensure no <code>.env</code> file is staged. If a secret has been committed, rotate the affected credentials immediately -- removing the file from history is not sufficient.</p>"},{"location":"deployment/security/#frontend-environment-variables-are-public","title":"Frontend environment variables are public","text":"<p>Any variable prefixed with <code>NEXT_PUBLIC_</code> is embedded into the JavaScript bundle at build time and is visible to every user who opens the browser DevTools.</p> Safe for <code>NEXT_PUBLIC_*</code> NOT safe for <code>NEXT_PUBLIC_*</code> Backend URL API keys (OpenAI, Anthropic) Feature flags Database passwords Public app name Internal service tokens frontend/.env.local -- correct<pre><code># This is the ONLY frontend env var AXIS needs\nNEXT_PUBLIC_API_URL=https://api.your-domain.com\n</code></pre> <p>No secrets in the frontend</p> <p>Never place <code>OPENAI_API_KEY</code>, <code>ANTHROPIC_API_KEY</code>, database credentials, or any other secret in a <code>NEXT_PUBLIC_*</code> variable. These belong exclusively in the backend <code>.env</code> file.</p>"},{"location":"deployment/security/#rotate-keys-regularly","title":"Rotate keys regularly","text":"<ul> <li>Rotate LLM API keys (OpenAI, Anthropic) on a regular cadence</li> <li>Rotate database passwords when team members leave</li> <li>Use short-lived credentials where your infrastructure supports them (e.g., IAM database auth on AWS)</li> </ul>"},{"location":"deployment/security/#use-a-secrets-manager-in-production","title":"Use a secrets manager in production","text":"<p>For production deployments, inject secrets via your platform's secrets manager rather than <code>.env</code> files:</p> Platform Secrets Solution AWS Secrets Manager or SSM Parameter Store GCP Secret Manager Azure Key Vault Kubernetes Secrets (with encryption at rest) Docker Compose <code>docker secret</code> or <code>env_file</code> with restricted permissions"},{"location":"deployment/security/#cors-configuration","title":"CORS Configuration","text":"<p>The backend uses FastAPI's CORS middleware. By default, it allows three origins:</p> <pre><code>allow_origins=[\n    \"http://localhost:3500\",       # Local dev\n    \"http://127.0.0.1:3500\",      # Local dev (alt)\n    settings.FRONTEND_URL,         # Configured origin\n]\n</code></pre>"},{"location":"deployment/security/#production-cors-checklist","title":"Production CORS checklist","text":"<ul> <li> Set <code>FRONTEND_URL</code> to your exact production frontend origin (including scheme and port if non-standard)</li> <li> Do not use <code>*</code> as a wildcard origin in production</li> <li> If you serve the frontend and backend on the same domain via a reverse proxy, CORS is not required -- but <code>FRONTEND_URL</code> should still be set correctly for consistency</li> </ul> <p>Testing CORS</p> <p>Open the browser console on your production frontend and check for CORS errors. The most common issue is a mismatch between the actual frontend origin and the value of <code>FRONTEND_URL</code> (e.g., trailing slash, wrong port, <code>http</code> vs <code>https</code>).</p>"},{"location":"deployment/security/#database-security","title":"Database Security","text":""},{"location":"deployment/security/#parameterized-queries","title":"Parameterized queries","text":"<p>AXIS uses SQLAlchemy with parameterized queries for all database operations. SQL injection is mitigated by design -- table and column names are validated against the database schema before being used in queries.</p>"},{"location":"deployment/security/#connection-security","title":"Connection security","text":"Setting Recommended Value Purpose <code>ssl_mode</code> <code>require</code> Encrypt data in transit Connection timeout 10 seconds (hardcoded) Prevent hanging on unreachable hosts Query timeout 30--60 seconds (configurable) Prevent runaway queries Row limit 10,000--50,000 (configurable) Prevent memory exhaustion custom/config/eval_db.yaml<pre><code>eval_db:\n  enabled: true\n  ssl_mode: require\n  query_timeout: 60\n  row_limit: 50000\n</code></pre>"},{"location":"deployment/security/#connection-handles","title":"Connection handles","text":"<p>The database integration module uses ephemeral connection handles with a 15-minute TTL. After 15 minutes of inactivity, the handle expires and the user must reconnect. This limits the blast radius if a handle is leaked.</p>"},{"location":"deployment/security/#least-privilege","title":"Least privilege","text":"<p>Create a dedicated database user for AXIS with minimal permissions:</p> <pre><code>-- PostgreSQL example\nCREATE USER axis_reader WITH PASSWORD 'strong-random-password';\nGRANT CONNECT ON DATABASE axis_eval TO axis_reader;\nGRANT USAGE ON SCHEMA public TO axis_reader;\nGRANT SELECT ON ALL TABLES IN SCHEMA public TO axis_reader;\n</code></pre> <p>AXIS only reads data -- it never writes to your evaluation, monitoring, or human signals databases. A read-only user is sufficient.</p>"},{"location":"deployment/security/#network-security","title":"Network Security","text":""},{"location":"deployment/security/#tls-everywhere","title":"TLS everywhere","text":"<ul> <li>Terminate TLS at your reverse proxy or load balancer</li> <li>Use <code>ssl_mode: require</code> for all PostgreSQL connections</li> <li>Use HTTPS URLs for <code>NEXT_PUBLIC_API_URL</code> and <code>FRONTEND_URL</code> in production</li> </ul>"},{"location":"deployment/security/#restrict-network-access","title":"Restrict network access","text":"<ul> <li>The backend should only be reachable through the reverse proxy, not directly from the internet</li> <li>Database ports (5432 for PostgreSQL, 6379 for FalkorDB) should not be exposed to the internet</li> <li>Use private subnets or security groups to isolate the backend and database from public traffic</li> </ul> <pre><code>flowchart LR\n    Internet --&gt;|443| RP[Reverse Proxy&lt;br/&gt;Public Subnet]\n    RP --&gt;|3500| FE[Frontend&lt;br/&gt;Private Subnet]\n    RP --&gt;|8500| BE[Backend&lt;br/&gt;Private Subnet]\n    BE --&gt;|5432| DB[(Database&lt;br/&gt;Private Subnet)]</code></pre>"},{"location":"deployment/security/#disable-debug-mode","title":"Disable debug mode","text":"<p>In production, always set:</p> <pre><code>DEBUG=false\n</code></pre> <p>Debug mode enables Uvicorn's auto-reload watcher and more verbose logging. It should never be active in a production deployment.</p>"},{"location":"deployment/security/#container-hardening","title":"Container Hardening","text":"<p>Both Dockerfiles follow container security best practices:</p>"},{"location":"deployment/security/#non-root-users","title":"Non-root users","text":"Image User UID Frontend (<code>runner</code> stage) <code>nextjs</code> 1001 Backend <code>appuser</code> 1000"},{"location":"deployment/security/#minimal-images","title":"Minimal images","text":"<ul> <li>The frontend production image (<code>runner</code> stage) contains only the standalone Next.js output -- no <code>node_modules</code>, no source code</li> <li>The backend image installs only production dependencies from <code>requirements.txt</code></li> </ul>"},{"location":"deployment/security/#additional-hardening","title":"Additional hardening","text":"<p>Consider these steps for high-security environments:</p> <ul> <li> Scan images for vulnerabilities with <code>docker scout</code>, Trivy, or Snyk</li> <li> Pin base image digests instead of tags (<code>node:20-alpine@sha256:...</code>)</li> <li> Set <code>read_only: true</code> in Compose to make the container filesystem read-only</li> <li> Drop all Linux capabilities: <code>cap_drop: [ALL]</code></li> <li> Set <code>no-new-privileges: true</code> in the security options</li> </ul>"},{"location":"deployment/security/#api-documentation-endpoint","title":"API Documentation Endpoint","text":"<p>The backend serves interactive API docs at <code>/docs</code> (Swagger UI) and <code>/redoc</code> (ReDoc). In production, you may want to restrict access to these endpoints:</p> Reverse proxy restrictionDisable entirely <p>Block public access in Nginx:</p> <pre><code>location /docs {\n    allow 10.0.0.0/8;   # Internal network\n    deny all;\n}\nlocation /redoc {\n    allow 10.0.0.0/8;\n    deny all;\n}\nlocation /openapi.json {\n    allow 10.0.0.0/8;\n    deny all;\n}\n</code></pre> <p>Set <code>docs_url=None</code> and <code>redoc_url=None</code> in <code>app/main.py</code>:</p> <pre><code>app = FastAPI(\n    title=\"AXIS API\",\n    docs_url=None,\n    redoc_url=None,\n)\n</code></pre>"},{"location":"deployment/security/#summary-of-production-settings","title":"Summary of Production Settings","text":"Setting Value Notes <code>DEBUG</code> <code>false</code> Disables auto-reload and verbose logging <code>FRONTEND_URL</code> Exact production origin No trailing slash, correct scheme <code>ssl_mode</code> <code>require</code> For all database connections Uvicorn <code>--reload</code> Omitted Never use in production <code>.env</code> files Git-ignored, never in images Inject secrets at runtime <code>NEXT_PUBLIC_*</code> Only <code>NEXT_PUBLIC_API_URL</code> No secrets in frontend env Container user Non-root Both images run as unprivileged users"},{"location":"deployment/security/#related","title":"Related","text":"<ul> <li>Production -- deployment architecture and health checks</li> <li>Docker -- building and running container images</li> <li>Environment Variables -- complete env var reference</li> </ul>"},{"location":"development/","title":"Development","text":"<p>This section covers everything you need to contribute to AXIS -- from local setup and coding standards to testing workflows and UI design patterns.</p>"},{"location":"development/#quick-reference","title":"Quick Reference","text":""},{"location":"development/#start-development-servers","title":"Start Development Servers","text":"<pre><code>make dev\n</code></pre> <p>This starts both servers concurrently:</p> <ul> <li>Frontend: http://localhost:3500</li> <li>Backend: http://localhost:8500</li> <li>API Docs: http://localhost:8500/docs</li> </ul>"},{"location":"development/#lint-and-format","title":"Lint and Format","text":"All (Monorepo)Backend OnlyFrontend Only <pre><code>make lint          # Check only\nmake lint-fix      # Auto-fix\nmake format        # Format only\nmake typecheck     # Type checking\n</code></pre> <pre><code>cd backend\nruff check app --fix\nruff format app\nmypy app --ignore-missing-imports\n</code></pre> <pre><code>cd frontend\nnpm run format          # Prettier\nnpm run lint            # ESLint\nnpx tsc --noEmit        # TypeScript\n</code></pre>"},{"location":"development/#run-tests","title":"Run Tests","text":"<pre><code>make test              # All tests\nmake test-backend      # pytest\nmake test-frontend     # Vitest\nmake test-e2e          # Playwright\n</code></pre>"},{"location":"development/#clean-caches","title":"Clean Caches","text":"<pre><code>make clean\n</code></pre> <p>Removes <code>.ruff_cache</code>, <code>.mypy_cache</code>, <code>.pytest_cache</code>, <code>__pycache__</code>, <code>.next</code>, and <code>node_modules/.cache</code>.</p>"},{"location":"development/#section-overview","title":"Section Overview","text":"<ul> <li> <p>Setup</p> <p>Environment setup, IDE configuration, pre-commit hooks, and env files.</p> <p> Setup guide</p> </li> <li> <p>Code Conventions</p> <p>File naming, import order, type hints, router/service patterns, and component structure for both backend and frontend.</p> <p> Conventions</p> </li> <li> <p>Adding Features</p> <p>Step-by-step walkthroughs for adding routers, services, pages, stores, and environment variables.</p> <p> Feature guide</p> </li> <li> <p>Testing</p> <p>pytest for the backend, Vitest for unit tests, Playwright for E2E, and Makefile targets.</p> <p> Testing guide</p> </li> <li> <p>Design System</p> <p>Color palette, component patterns, spacing conventions, and Plotly chart defaults.</p> <p> Design system</p> </li> </ul>"},{"location":"development/#monorepo-layout","title":"Monorepo Layout","text":"<pre><code>axis/\n\u251c\u2500\u2500 backend/\n\u2502   \u251c\u2500\u2500 app/\n\u2502   \u2502   \u251c\u2500\u2500 main.py              # FastAPI entry, router mounting\n\u2502   \u2502   \u251c\u2500\u2500 config.py            # Pydantic Settings\n\u2502   \u2502   \u251c\u2500\u2500 routers/             # API route handlers\n\u2502   \u2502   \u251c\u2500\u2500 services/            # Business logic\n\u2502   \u2502   \u251c\u2500\u2500 models/              # Pydantic schemas\n\u2502   \u2502   \u2514\u2500\u2500 copilot/             # AI copilot agent + skills\n\u2502   \u251c\u2500\u2500 config/                  # YAML config templates (.yaml.example)\n\u2502   \u251c\u2500\u2500 tests/                   # pytest test suite\n\u2502   \u251c\u2500\u2500 requirements.txt\n\u2502   \u2514\u2500\u2500 .env                     # Backend environment variables\n\u2502\n\u251c\u2500\u2500 frontend/\n\u2502   \u251c\u2500\u2500 src/\n\u2502   \u2502   \u251c\u2500\u2500 app/                 # Next.js App Router pages\n\u2502   \u2502   \u251c\u2500\u2500 components/          # React components (by feature)\n\u2502   \u2502   \u251c\u2500\u2500 stores/              # Zustand state stores\n\u2502   \u2502   \u251c\u2500\u2500 lib/                 # API client, hooks, utilities\n\u2502   \u2502   \u2514\u2500\u2500 types/               # TypeScript type definitions\n\u2502   \u251c\u2500\u2500 e2e/                     # Playwright E2E tests\n\u2502   \u251c\u2500\u2500 .env.local               # Frontend environment variables\n\u2502   \u2514\u2500\u2500 package.json\n\u2502\n\u251c\u2500\u2500 custom/                      # Site-specific config + assets (gitignored)\n\u251c\u2500\u2500 docs/                        # MkDocs documentation (this site)\n\u251c\u2500\u2500 Makefile                     # Monorepo task runner\n\u2514\u2500\u2500 .pre-commit-config.yaml      # Git hook configuration\n</code></pre>"},{"location":"development/#related-pages","title":"Related Pages","text":"<ul> <li>Installation -- prerequisites and dependency install</li> <li>Architecture Overview -- system diagram and tech stack</li> <li>Configuration -- environment variables and YAML configs</li> </ul>"},{"location":"development/adding-features/","title":"Adding Features","text":"<p>This guide provides step-by-step walkthroughs for the most common feature additions in AXIS. Each section follows the established patterns documented in Code Conventions.</p>"},{"location":"development/adding-features/#add-a-new-backend-router-service","title":"Add a New Backend Router + Service","text":"<p>A typical backend feature requires three files: a Pydantic model, a service, and a router.</p>"},{"location":"development/adding-features/#step-1-define-the-pydantic-models","title":"Step 1 -- Define the Pydantic models","text":"<p>Create <code>backend/app/models/widgets_schemas.py</code>:</p> <pre><code>\"\"\"Pydantic schemas for the Widgets feature.\"\"\"\n\nfrom pydantic import BaseModel, Field\n\n\nclass WidgetRequest(BaseModel):\n    \"\"\"Request body for creating a widget.\"\"\"\n\n    name: str = Field(..., min_length=1, max_length=100)\n    category: str | None = None\n    value: float = Field(default=0.0, ge=0.0)\n\n\nclass WidgetResponse(BaseModel):\n    \"\"\"Response containing widget data.\"\"\"\n\n    success: bool = True\n    data: dict[str, object] | None = None\n    message: str | None = None\n\n\nclass WidgetSummary(BaseModel):\n    \"\"\"Aggregated widget statistics.\"\"\"\n\n    total_count: int\n    average_value: float\n    categories: list[str]\n</code></pre>"},{"location":"development/adding-features/#step-2-implement-the-service","title":"Step 2 -- Implement the service","text":"<p>Create <code>backend/app/services/widgets_service.py</code>:</p> <pre><code>\"\"\"Widgets service -- business logic for widget operations.\"\"\"\n\nimport logging\nfrom typing import Any\n\nlogger = logging.getLogger(__name__)\n\n\nclass WidgetsServiceError(Exception):\n    \"\"\"Base exception for widget operations.\"\"\"\n    pass\n\n\nclass WidgetNotFoundError(WidgetsServiceError):\n    \"\"\"Raised when a widget does not exist.\"\"\"\n    pass\n\n\nasync def get_all_widgets() -&gt; list[dict[str, Any]]:\n    \"\"\"Retrieve all widgets.\n\n    Returns:\n        List of widget dictionaries.\n    \"\"\"\n    logger.info(\"Fetching all widgets\")\n    # Implementation here\n    return []\n\n\nasync def get_widget_summary() -&gt; dict[str, Any]:\n    \"\"\"Compute aggregate statistics across all widgets.\n\n    Returns:\n        Summary dictionary with counts and averages.\n\n    Raises:\n        WidgetsServiceError: If data cannot be loaded.\n    \"\"\"\n    widgets = await get_all_widgets()\n    if not widgets:\n        raise WidgetsServiceError(\"No widget data available\")\n    return {\n        \"total_count\": len(widgets),\n        \"average_value\": sum(w[\"value\"] for w in widgets) / len(widgets),\n        \"categories\": list({w[\"category\"] for w in widgets if w.get(\"category\")}),\n    }\n</code></pre>"},{"location":"development/adding-features/#step-3-create-the-router","title":"Step 3 -- Create the router","text":"<p>Create <code>backend/app/routers/widgets.py</code>:</p> <pre><code>\"\"\"Widget API endpoints.\"\"\"\n\nimport logging\n\nfrom fastapi import APIRouter, HTTPException\n\nfrom app.models.widgets_schemas import WidgetResponse, WidgetSummary\nfrom app.services import widgets_service\n\nlogger = logging.getLogger(__name__)\n\nrouter = APIRouter()\n\n\n@router.get(\"/\", response_model=WidgetResponse)\nasync def list_widgets() -&gt; WidgetResponse:\n    \"\"\"List all widgets.\"\"\"\n    try:\n        data = await widgets_service.get_all_widgets()\n        return WidgetResponse(success=True, data={\"widgets\": data})\n    except widgets_service.WidgetsServiceError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception:\n        logger.exception(\"Unexpected error listing widgets\")\n        raise HTTPException(status_code=500, detail=\"An unexpected error occurred\")\n\n\n@router.get(\"/summary\", response_model=WidgetSummary)\nasync def widget_summary() -&gt; WidgetSummary:\n    \"\"\"Get aggregated widget statistics.\"\"\"\n    try:\n        summary = await widgets_service.get_widget_summary()\n        return WidgetSummary(**summary)\n    except widgets_service.WidgetsServiceError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n</code></pre>"},{"location":"development/adding-features/#step-4-register-in-mainpy","title":"Step 4 -- Register in main.py","text":"<p>Add the import and <code>include_router</code> call in <code>backend/app/main.py</code>:</p> <pre><code>from app.routers import (\n    # ... existing imports ...\n    widgets,\n)\n\n# ... after existing include_router calls ...\napp.include_router(widgets.router, prefix=\"/api/widgets\", tags=[\"widgets\"])\n</code></pre>"},{"location":"development/adding-features/#step-5-verify","title":"Step 5 -- Verify","text":"<pre><code>cd backend\nruff check app --fix &amp;&amp; ruff format app\nuvicorn app.main:app --reload --port 8500\n</code></pre> <p>Visit http://localhost:8500/docs to confirm the new endpoints appear under the \"widgets\" tag.</p>"},{"location":"development/adding-features/#add-a-new-frontend-page-components","title":"Add a New Frontend Page + Components","text":""},{"location":"development/adding-features/#step-1-create-the-page","title":"Step 1 -- Create the page","text":"<p>Create <code>frontend/src/app/widgets/page.tsx</code>:</p> <pre><code>'use client';\n\nimport { useEffect } from 'react';\n\nimport { WidgetDashboard } from '@/components/widgets/WidgetDashboard';\n\nexport default function WidgetsPage() {\n  useEffect(() =&gt; {\n    document.title = 'Widgets | AXIS';\n  }, []);\n\n  return (\n    &lt;div className=\"py-6\"&gt;\n      &lt;div className=\"mb-5 flex items-center justify-between\"&gt;\n        &lt;h1 className=\"text-xl font-bold text-text-primary\"&gt;Widgets&lt;/h1&gt;\n      &lt;/div&gt;\n      &lt;div className=\"space-y-5\"&gt;\n        &lt;WidgetDashboard /&gt;\n      &lt;/div&gt;\n    &lt;/div&gt;\n  );\n}\n</code></pre>"},{"location":"development/adding-features/#step-2-create-the-component","title":"Step 2 -- Create the component","text":"<p>Create <code>frontend/src/components/widgets/WidgetDashboard.tsx</code>:</p> <pre><code>'use client';\n\nimport { useMemo } from 'react';\nimport { BarChart3 } from 'lucide-react';\n\nimport { cn } from '@/lib/utils';\n\ninterface WidgetDashboardProps {\n  className?: string;\n}\n\nexport function WidgetDashboard({ className }: WidgetDashboardProps) {\n  // Store hooks, state, derived data, handlers ...\n\n  return (\n    &lt;div className={cn('space-y-5', className)}&gt;\n      {/* KPI strip, charts, tables, etc. */}\n    &lt;/div&gt;\n  );\n}\n</code></pre>"},{"location":"development/adding-features/#step-3-add-barrel-export","title":"Step 3 -- Add barrel export","text":"<p>Create <code>frontend/src/components/widgets/index.ts</code>:</p> <pre><code>export { WidgetDashboard } from './WidgetDashboard';\n</code></pre>"},{"location":"development/adding-features/#step-4-add-types","title":"Step 4 -- Add types","text":"<p>Add any new types to <code>frontend/src/types/index.ts</code>:</p> <pre><code>// Widget types\nexport interface Widget {\n  id: string;\n  name: string;\n  category: string | null;\n  value: number;\n}\n\nexport interface WidgetSummary {\n  total_count: number;\n  average_value: number;\n  categories: string[];\n}\n</code></pre> <p>Single source of truth</p> <p>All types go in <code>types/index.ts</code>. Do not define types in individual component files unless they are component-specific props interfaces.</p>"},{"location":"development/adding-features/#step-5-add-api-functions","title":"Step 5 -- Add API functions","text":"<p>Add to <code>frontend/src/lib/api.ts</code>:</p> <pre><code>// Widgets\nexport async function getWidgets(): Promise&lt;{ widgets: Widget[] }&gt; {\n  return fetchApi&lt;{ widgets: Widget[] }&gt;('/api/widgets/');\n}\n\nexport async function getWidgetSummary(): Promise&lt;WidgetSummary&gt; {\n  return fetchApi&lt;WidgetSummary&gt;('/api/widgets/summary');\n}\n</code></pre>"},{"location":"development/adding-features/#step-6-add-react-query-hooks","title":"Step 6 -- Add React Query hooks","text":"<p>Add to <code>frontend/src/lib/hooks.ts</code> (or create a dedicated <code>lib/hooks/useWidgets.ts</code>):</p> <pre><code>export function useWidgets() {\n  return useQuery({\n    queryKey: ['widgets'],\n    queryFn: api.getWidgets,\n  });\n}\n\nexport function useWidgetSummary() {\n  return useQuery({\n    queryKey: ['widget-summary'],\n    queryFn: api.getWidgetSummary,\n  });\n}\n</code></pre>"},{"location":"development/adding-features/#add-a-new-zustand-store","title":"Add a New Zustand Store","text":""},{"location":"development/adding-features/#step-1-create-the-store-file","title":"Step 1 -- Create the store file","text":"<p>Create <code>frontend/src/stores/widgets-store.ts</code>:</p> <pre><code>import { create } from 'zustand';\n\ninterface WidgetsState {\n  // Data\n  selectedCategory: string | null;\n  isDetailOpen: boolean;\n  selectedWidgetId: string | null;\n\n  // Actions\n  setSelectedCategory: (category: string | null) =&gt; void;\n  openDetail: (widgetId: string) =&gt; void;\n  closeDetail: () =&gt; void;\n  reset: () =&gt; void;\n}\n\nexport const useWidgetsStore = create&lt;WidgetsState&gt;()((set) =&gt; ({\n  // Initial state\n  selectedCategory: null,\n  isDetailOpen: false,\n  selectedWidgetId: null,\n\n  // Actions\n  setSelectedCategory: (category) =&gt; set({ selectedCategory: category }),\n  openDetail: (widgetId) =&gt; set({ isDetailOpen: true, selectedWidgetId: widgetId }),\n  closeDetail: () =&gt; set({ isDetailOpen: false, selectedWidgetId: null }),\n  reset: () =&gt;\n    set({\n      selectedCategory: null,\n      isDetailOpen: false,\n      selectedWidgetId: null,\n    }),\n}));\n</code></pre>"},{"location":"development/adding-features/#step-2-register-in-barrel-export","title":"Step 2 -- Register in barrel export","text":"<p>Add to <code>frontend/src/stores/index.ts</code>:</p> <pre><code>export { useWidgetsStore } from './widgets-store';\n</code></pre>"},{"location":"development/adding-features/#when-to-use-persist-middleware","title":"When to use <code>persist</code> middleware","text":"<p>Use <code>persist</code> when state should survive page reloads (e.g., user preferences, filter selections):</p> <pre><code>import { create } from 'zustand';\nimport { persist } from 'zustand/middleware';\n\nexport const useWidgetsStore = create&lt;WidgetsState&gt;()(\n  persist(\n    (set) =&gt; ({\n      // ... state and actions\n    }),\n    {\n      name: 'axis-widgets',          // localStorage key\n      partialize: (state) =&gt; ({      // Only persist these fields\n        selectedCategory: state.selectedCategory,\n      }),\n    }\n  )\n);\n</code></pre>"},{"location":"development/adding-features/#add-a-new-environment-variable","title":"Add a New Environment Variable","text":""},{"location":"development/adding-features/#backend","title":"Backend","text":"<p>Step 1 -- Add to <code>backend/app/config.py</code>:</p> <pre><code>class Settings(BaseSettings):\n    # ... existing settings ...\n\n    # Widget API\n    widget_api_url: str | None = Field(\n        default=None,\n        description=\"External widget API base URL.\",\n    )\n    widget_api_key: str | None = Field(\n        default=None,\n        description=\"API key for widget service authentication.\",\n    )\n</code></pre> <p>Step 2 -- Add to <code>backend/.env</code>:</p> <pre><code>widget_api_url=https://api.widgets.example.com\nwidget_api_key=your_key_here\n</code></pre> <p>Step 3 -- Use in service code:</p> <pre><code>from app.config import settings\n\nasync def call_widget_api():\n    if not settings.widget_api_url:\n        raise WidgetsServiceError(\"Widget API URL not configured\")\n    # ...\n</code></pre>"},{"location":"development/adding-features/#frontend","title":"Frontend","text":"<p>Step 1 -- Add to <code>frontend/.env.local</code>:</p> <pre><code>NEXT_PUBLIC_WIDGET_FEATURE_FLAG=true\n</code></pre> <p>Step 2 -- Use in component code:</p> <pre><code>const isWidgetEnabled = process.env.NEXT_PUBLIC_WIDGET_FEATURE_FLAG === 'true';\n</code></pre> <p>Security reminder</p> <p><code>NEXT_PUBLIC_*</code> variables are embedded in the client bundle and visible to users. Never put secrets in frontend env vars.</p>"},{"location":"development/adding-features/#add-a-new-yaml-config","title":"Add a New YAML Config","text":"<p>For features that need structured configuration beyond simple env vars.</p> <p>Step 1 -- Create <code>custom/config/widgets.yaml</code> (or add a <code>backend/config/widgets.yaml.example</code> template and run <code>make setup</code> to copy it):</p> <pre><code>widgets:\n  default_category: \"general\"\n  max_items: 100\n  display:\n    chart_type: \"bar\"\n    color_scheme: \"primary\"\n</code></pre> <p>Step 2 -- Load in the service:</p> <pre><code>import yaml\n\nfrom app.config import resolve_config_path\n\n_CONFIG_PATH = resolve_config_path(\"widgets.yaml\")\n\n\ndef _load_config() -&gt; dict[str, Any]:\n    \"\"\"Load widget display configuration from YAML.\"\"\"\n    if not _CONFIG_PATH.exists():\n        logger.warning(\"widgets.yaml not found, using defaults\")\n        return {}\n    with _CONFIG_PATH.open() as f:\n        return yaml.safe_load(f).get(\"widgets\", {})\n</code></pre>"},{"location":"development/adding-features/#checklist","title":"Checklist","text":"<p>Use this checklist when adding a full-stack feature:</p> <ul> <li> Backend models in <code>models/*_schemas.py</code></li> <li> Backend service in <code>services/*_service.py</code> with custom exceptions</li> <li> Backend router in <code>routers/*.py</code> with error handling</li> <li> Router registered in <code>main.py</code> with <code>app.include_router()</code></li> <li> Frontend types in <code>types/index.ts</code></li> <li> API functions in <code>lib/api.ts</code></li> <li> React Query hooks in <code>lib/hooks.ts</code> or <code>lib/hooks/</code></li> <li> Zustand store in <code>stores/*-store.ts</code> (if needed)</li> <li> Store exported from <code>stores/index.ts</code></li> <li> Page in <code>app/*/page.tsx</code></li> <li> Components in <code>components/*/</code></li> <li> Barrel export in <code>components/*/index.ts</code></li> <li> Env vars in <code>config.py</code> and <code>.env</code> (if needed)</li> <li> Lint passes: <code>make lint</code></li> <li> Type check passes: <code>make typecheck</code></li> <li> Tests pass: <code>make test</code></li> </ul>"},{"location":"development/adding-features/#related-pages","title":"Related Pages","text":"<ul> <li>Code Conventions -- naming and structural patterns</li> <li>Testing -- writing and running tests</li> <li>Architecture: Backend -- router/service layer detail</li> <li>Architecture: State Management -- Zustand and React Query patterns</li> </ul>"},{"location":"development/code-conventions/","title":"Code Conventions","text":"<p>AXIS enforces consistent coding standards across the Python backend and TypeScript frontend. This page documents all conventions -- file naming, import ordering, type hints, and structural patterns.</p>"},{"location":"development/code-conventions/#backend-python","title":"Backend (Python)","text":""},{"location":"development/code-conventions/#file-naming","title":"File Naming","text":"Category Convention Examples Routers <code>snake_case.py</code> <code>data.py</code>, <code>eval_runner.py</code>, <code>monitoring_analytics.py</code> Services <code>snake_case</code> + <code>_service</code> suffix <code>database_service.py</code>, <code>memory_service.py</code>, <code>signals_service.py</code> Models <code>snake_case</code> + <code>_schemas</code> suffix <code>schemas.py</code>, <code>database_schemas.py</code>, <code>graph_schemas.py</code> Config <code>snake_case.py</code> <code>config.py</code>"},{"location":"development/code-conventions/#type-hints","title":"Type Hints","text":"<p>Use modern Python type syntax (3.10+). Ruff enforces these automatically.</p> <pre><code># Correct (modern)\ndef process(data: dict[str, Any]) -&gt; list[str]: ...\ndef find(name: str | None = None) -&gt; dict[str, Any] | None: ...\nisinstance(value, str | int)\n\n# Incorrect (legacy -- Ruff will flag these)\ndef process(data: Dict[str, Any]) -&gt; List[str]: ...       # UP006\ndef find(name: Optional[str] = None) -&gt; Optional[dict]: ...  # UP007\nisinstance(value, (str, int))                               # UP038\n</code></pre>"},{"location":"development/code-conventions/#router-structure","title":"Router Structure","text":"<p>Every router follows this pattern:</p> <pre><code>\"\"\"Brief description of what this router handles.\"\"\"\n\nimport logging\n\nfrom fastapi import APIRouter, HTTPException\n\nfrom app.models.schemas import SomeRequest, SomeResponse\nfrom app.services import some_service\n\nlogger = logging.getLogger(__name__)\n\nrouter = APIRouter()\n\n\n@router.post(\"/endpoint\", response_model=SomeResponse)\nasync def endpoint_name(request: SomeRequest) -&gt; SomeResponse:\n    \"\"\"Endpoint docstring.\"\"\"\n    try:\n        result = await some_service.do_something(request)\n        return SomeResponse(success=True, data=result)\n    except some_service.ServiceError as e:\n        raise HTTPException(status_code=400, detail=str(e))\n    except Exception:\n        logger.exception(\"Unexpected error\")\n        raise HTTPException(status_code=500, detail=\"An unexpected error occurred\")\n</code></pre> <p>Key points:</p> <ul> <li><code>router = APIRouter()</code> (no prefix -- that is set in <code>main.py</code>)</li> <li><code>try/except</code> with custom service exceptions mapped to HTTP status codes</li> <li>Catch-all <code>except Exception</code> with <code>logger.exception()</code> for unexpected errors</li> <li>Google-style docstrings on public functions</li> </ul>"},{"location":"development/code-conventions/#service-structure","title":"Service Structure","text":"<pre><code>\"\"\"Service module docstring.\"\"\"\n\nimport logging\nfrom typing import Any\n\nlogger = logging.getLogger(__name__)\n\n\nclass ServiceError(Exception):\n    \"\"\"Base exception for this service.\"\"\"\n    pass\n\n\nclass SpecificError(ServiceError):\n    \"\"\"More specific error (maps to 404, 401, etc. in the router).\"\"\"\n    pass\n\n\nasync def do_something(data: dict[str, Any]) -&gt; dict[str, Any]:\n    \"\"\"Process data and return results.\n\n    Args:\n        data: Input data dictionary.\n\n    Returns:\n        Processed result dictionary.\n\n    Raises:\n        ServiceError: If processing fails.\n    \"\"\"\n    logger.info(f\"Processing {len(data)} items\")\n    # Implementation\n    return result\n</code></pre> <p>Key points:</p> <ul> <li>Module-level <code>logger</code></li> <li>Custom <code>ServiceError</code> base class per service</li> <li>All I/O functions are <code>async</code></li> <li>Type hints on all parameters and return values</li> <li>Google-style docstrings with Args/Returns/Raises</li> </ul>"},{"location":"development/code-conventions/#error-handling-hierarchy","title":"Error Handling Hierarchy","text":"<pre><code># In the service\nclass DatabaseServiceError(Exception): ...\nclass ConnectionExpiredError(DatabaseServiceError): ...  # -&gt; 401\nclass TableNotFoundError(DatabaseServiceError): ...      # -&gt; 404\n\n# In the router\nexcept ConnectionExpiredError as e:\n    raise HTTPException(status_code=401, detail=str(e))\nexcept TableNotFoundError as e:\n    raise HTTPException(status_code=404, detail=str(e))\nexcept DatabaseServiceError as e:\n    raise HTTPException(status_code=400, detail=str(e))\n</code></pre>"},{"location":"development/code-conventions/#linting-and-formatting","title":"Linting and Formatting","text":"<p>AXIS uses Ruff for both linting and formatting.</p> <pre><code>ruff check app --fix    # Lint + auto-fix\nruff format app         # Format\n</code></pre> <p>Common Ruff rules you may encounter:</p> Rule What it means Fix <code>UP006</code> Use <code>dict</code> not <code>Dict</code> Change <code>Dict[str, Any]</code> to <code>dict[str, Any]</code> <code>UP007</code> Use <code>X \\| None</code> not <code>Optional[X]</code> Change <code>Optional[str]</code> to <code>str \\| None</code> <code>UP038</code> Use <code>X \\| Y</code> in isinstance Change <code>isinstance(v, (str, int))</code> to <code>isinstance(v, str \\| int)</code> <code>SIM102</code> Nested if can be collapsed Combine with <code>and</code> <code>F841</code> Unused variable Remove or prefix with <code>_</code> <code>PTH123</code> Use <code>Path.open()</code> Change <code>open(path)</code> to <code>Path(path).open()</code>"},{"location":"development/code-conventions/#frontend-typescript","title":"Frontend (TypeScript)","text":""},{"location":"development/code-conventions/#file-naming_1","title":"File Naming","text":"Category Convention Examples Components PascalCase <code>KPICard.tsx</code>, <code>CompareContent.tsx</code>, <code>SignalsTrendChart.tsx</code> Pages <code>page.tsx</code> in directory <code>app/monitoring/page.tsx</code> Stores kebab-case + <code>-store</code> suffix <code>ui-store.ts</code>, <code>monitoring-store.ts</code> Hooks camelCase with <code>use</code> prefix <code>usePlayback.ts</code>, <code>useSignalsUpload.ts</code> Utilities kebab-case <code>utils.ts</code>, <code>signals-utils.ts</code>, <code>executive-summary-utils.ts</code> Types All in <code>types/index.ts</code> Single source of truth Barrel exports <code>index.ts</code> One per component folder and in <code>stores/</code>"},{"location":"development/code-conventions/#import-order","title":"Import Order","text":"<p>ESLint enforces a strict import ordering with the <code>import/order</code> rule:</p> <pre><code>// 1. External packages\nimport { useState, useMemo } from 'react';\nimport { useQuery } from '@tanstack/react-query';\n\n// 2. Internal (absolute @/ imports)\nimport { useUIStore, useDataStore } from '@/stores';\nimport { cn } from '@/lib/utils';\n\n// 3. Relative imports (parent, sibling)\nimport { ChildComponent } from './ChildComponent';\n\n// 4. Type-only imports\nimport type { EvaluationRecord } from '@/types';\n</code></pre> <p>Rules enforced by <code>.eslintrc.json</code>:</p> <ul> <li>Groups: <code>builtin</code> &gt; <code>external</code> &gt; <code>internal</code> &gt; <code>parent/sibling</code> &gt; <code>index</code> &gt; <code>type</code></li> <li>Blank lines between groups (required)</li> <li>Alphabetical within each group (case-insensitive)</li> <li>No duplicate imports from the same module</li> <li>Type-only imports: <code>import type { ... }</code> enforced by <code>@typescript-eslint/consistent-type-imports</code></li> </ul>"},{"location":"development/code-conventions/#component-structure","title":"Component Structure","text":"<pre><code>'use client';\n\nimport { useState, useMemo } from 'react';\n\nimport { useUIStore, useDataStore } from '@/stores';\nimport { cn } from '@/lib/utils';\n\nimport type { EvaluationRecord } from '@/types';\n\ninterface ComponentNameProps {\n  title: string;\n  data?: EvaluationRecord[];\n  className?: string;\n}\n\nexport function ComponentName({ title, data = [], className }: ComponentNameProps) {\n  // 1. Store hooks\n  const { selectedMetrics } = useUIStore();\n\n  // 2. Local state\n  const [isExpanded, setIsExpanded] = useState(false);\n\n  // 3. Derived / memoized data\n  const filteredData = useMemo(() =&gt; {\n    return data.filter(/* ... */);\n  }, [data, selectedMetrics]);\n\n  // 4. Event handlers\n  const handleToggle = () =&gt; setIsExpanded((prev) =&gt; !prev);\n\n  // 5. Render\n  return (\n    &lt;div className={cn('rounded-lg border border-border bg-white p-4', className)}&gt;\n      {/* JSX */}\n    &lt;/div&gt;\n  );\n}\n</code></pre> <p>Key points:</p> <ul> <li><code>'use client'</code> directive on all components with hooks or interactivity</li> <li>Named exports (not default exports)</li> <li>Props interface defined inline above the component</li> <li>Internal organization: stores, state, derived, handlers, render</li> </ul>"},{"location":"development/code-conventions/#export-patterns","title":"Export Patterns","text":"<pre><code>// Named export (components)\nexport function MyComponent() { ... }\n\n// Barrel export (stores/index.ts)\nexport { useDataStore } from './data-store';\nexport { useUIStore } from './ui-store';\nexport type { HumanSignalsTimeRangePreset } from './human-signals-store';\n</code></pre> <p>All stores are barrel-exported from <code>stores/index.ts</code>. When adding a new store, always add the export there.</p>"},{"location":"development/code-conventions/#zustand-store-pattern","title":"Zustand Store Pattern","text":"<pre><code>import { create } from 'zustand';\nimport { persist } from 'zustand/middleware';\n\ninterface MyState {\n  count: number;\n  items: string[];\n  setCount: (n: number) =&gt; void;\n  addItem: (item: string) =&gt; void;\n  reset: () =&gt; void;\n}\n\nexport const useMyStore = create&lt;MyState&gt;()((set) =&gt; ({\n  count: 0,\n  items: [],\n  setCount: (n) =&gt; set({ count: n }),\n  addItem: (item) =&gt; set((state) =&gt; ({ items: [...state.items, item] })),\n  reset: () =&gt; set({ count: 0, items: [] }),\n}));\n</code></pre> <p>Note the double parentheses: <code>create&lt;State&gt;()(...)</code> -- this is required for TypeScript generic inference with Zustand v5.</p>"},{"location":"development/code-conventions/#react-query-hooks","title":"React Query Hooks","text":"<p>All data-fetching hooks wrap <code>fetchApi</code> calls from <code>lib/api.ts</code>:</p> <pre><code>import { useMutation, useQueryClient } from '@tanstack/react-query';\n\nimport { useDataStore } from '@/stores';\n\nimport * as api from './api';\n\nexport function useUploadFile() {\n  const queryClient = useQueryClient();\n  const { setData, setLoading, setError } = useDataStore();\n\n  return useMutation({\n    mutationFn: api.uploadFile,\n    onMutate: () =&gt; setLoading(true),\n    onSuccess: (response) =&gt; {\n      setData(response.data);\n      queryClient.invalidateQueries({ queryKey: ['summary'] });\n    },\n    onError: (error) =&gt; setError(error.message),\n  });\n}\n</code></pre>"},{"location":"development/code-conventions/#api-client","title":"API Client","text":"<p>The centralized API client is in <code>lib/api.ts</code>. All HTTP calls go through <code>fetchApi&lt;T&gt;()</code>:</p> <pre><code>const API_BASE = process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8500';\n\nasync function fetchApi&lt;T&gt;(endpoint: string, options?: RequestInit): Promise&lt;T&gt; {\n  const response = await fetch(`${API_BASE}${endpoint}`, options);\n  if (!response.ok) throw new Error(await response.text());\n  return response.json();\n}\n</code></pre>"},{"location":"development/code-conventions/#linting-and-formatting_1","title":"Linting and Formatting","text":"<pre><code># Format first (Prettier)\nnpm run format\n\n# Lint (ESLint -- includes import order, type-imports)\nnpm run lint\n\n# Type check\nnpx tsc --noEmit\n</code></pre> <p>Recommended order</p> <p>Run <code>prettier --write</code> first, then <code>eslint --fix</code>, then <code>prettier --write</code> again if ESLint modified files. The Makefile <code>lint-fix</code> target handles this sequence.</p>"},{"location":"development/code-conventions/#typescript-tips","title":"TypeScript Tips","text":"<ul> <li>Map iteration: <code>for...of</code> on Maps fails without <code>--downlevelIteration</code>. Use <code>Array.from(map.entries()).forEach()</code> instead.</li> <li>D3 zoom cast: <code>svg.call(zoom)</code> needs <code>svg.call(zoom as unknown as ...)</code> to satisfy strict null checks.</li> <li>Typed D3 selections: Use <code>selectAll&lt;SVGElement, DataType&gt;</code> for proper typing.</li> <li>D3 callbacks with <code>this</code>: Cast as <code>(this as SVGCircleElement)</code>.</li> </ul>"},{"location":"development/code-conventions/#shared-conventions","title":"Shared Conventions","text":""},{"location":"development/code-conventions/#docstrings-and-comments","title":"Docstrings and Comments","text":"<ul> <li>Python: Google-style docstrings on all public modules, classes, and functions</li> <li>TypeScript: JSDoc on exported functions and complex logic; TSDoc for library-facing code</li> <li>Both: Inline comments for non-obvious logic only -- prefer self-documenting code</li> </ul>"},{"location":"development/code-conventions/#git-commit-style","title":"Git Commit Style","text":"<p>Follow Conventional Commits:</p> <pre><code>feat: add knowledge graph visualization\nfix: correct time-series bucketing for monitoring trends\nrefactor: extract pagination into reusable component\ndocs: add deployment guide for Docker\n</code></pre>"},{"location":"development/code-conventions/#environment-variables","title":"Environment Variables","text":"<ul> <li>Backend: Add new vars to <code>app/config.py</code> <code>Settings</code> class, document in <code>.env.example</code></li> <li>Frontend: Only <code>NEXT_PUBLIC_*</code> vars are browser-accessible; add to <code>.env.local</code></li> <li>Naming: Backend uses <code>snake_case</code>, frontend uses <code>SCREAMING_SNAKE_CASE</code> with <code>NEXT_PUBLIC_</code> prefix</li> </ul>"},{"location":"development/code-conventions/#related-pages","title":"Related Pages","text":"<ul> <li>Setup -- install tools and configure your editor</li> <li>Adding Features -- step-by-step feature walkthroughs</li> <li>Architecture: Backend -- router/service architecture detail</li> <li>Architecture: Frontend -- component and state architecture</li> </ul>"},{"location":"development/design-system/","title":"Design System","text":"<p>AXIS uses a consistent design system built on Tailwind CSS with a custom color palette, reusable component patterns, and standardized Plotly chart defaults. This page is the reference for all UI conventions.</p>"},{"location":"development/design-system/#color-palette","title":"Color Palette","text":"<p>The color palette is driven by CSS custom properties, making it theme-aware. The default palette is Sage Green. See Theming for how to switch palettes or create custom ones.</p>"},{"location":"development/design-system/#primary-colors","title":"Primary Colors","text":"Token Default (Sage Green) Usage <code>primary</code> <code>#8B9F4F</code> Sidebar, primary buttons, chart accents <code>primary-light</code> <code>#A4B86C</code> Hover states, interactive highlights <code>primary-dark</code> <code>#6B7A3A</code> Headers, emphasis text, dark accents <code>primary-soft</code> <code>#B8C78A</code> Soft backgrounds, selected states <code>primary-pale</code> <code>#D4E0B8</code> Subtle backgrounds, card tints"},{"location":"development/design-system/#accent-colors","title":"Accent Colors","text":"Token Value Usage <code>accent-gold</code> <code>#D4AF37</code> Call-to-action highlights, premium indicators <code>accent-silver</code> <code>#B8C5D3</code> Secondary accents, muted borders"},{"location":"development/design-system/#semantic-colors","title":"Semantic Colors","text":"Token Value Usage <code>success</code> <code>#27AE60</code> Passing status, positive indicators <code>warning</code> <code>#F39C12</code> Caution states, threshold warnings <code>error</code> <code>#E74C3C</code> Failing status, error messages"},{"location":"development/design-system/#text-colors","title":"Text Colors","text":"Token Value Usage <code>text-primary</code> <code>#2C3E50</code> Headings, primary content <code>text-secondary</code> <code>#34495E</code> Body text, descriptions <code>text-muted</code> <code>#7F8C8D</code> Labels, captions, secondary info"},{"location":"development/design-system/#ui-surface-colors","title":"UI Surface Colors","text":"Token Value Usage <code>background</code> <code>#FAFBFC</code> Page background <code>surface</code> <code>#FFFFFF</code> Cards, panels, modals <code>border</code> <code>#E1E5EA</code> Card borders, dividers"},{"location":"development/design-system/#using-colors-in-tailwind","title":"Using Colors in Tailwind","text":"<p>Colors are registered in <code>tailwind.config.ts</code> via CSS custom properties. Use them directly in class names:</p> <pre><code>&lt;!-- Background --&gt;\n&lt;div class=\"bg-primary\"&gt;...&lt;/div&gt;\n&lt;div class=\"bg-primary/10\"&gt;...&lt;/div&gt;     &lt;!-- 10% opacity --&gt;\n\n&lt;!-- Text --&gt;\n&lt;span class=\"text-text-primary\"&gt;Heading&lt;/span&gt;\n&lt;span class=\"text-text-muted\"&gt;Caption&lt;/span&gt;\n\n&lt;!-- Border --&gt;\n&lt;div class=\"border border-border\"&gt;...&lt;/div&gt;\n\n&lt;!-- Status --&gt;\n&lt;span class=\"text-success\"&gt;Passed&lt;/span&gt;\n&lt;span class=\"text-error\"&gt;Failed&lt;/span&gt;\n</code></pre>"},{"location":"development/design-system/#typography","title":"Typography","text":"Style Font Usage Sans Inter, system-ui, sans-serif All UI text Mono JetBrains Mono, monospace Code blocks, data values <p>Tailwind classes: <code>font-sans</code> (default), <code>font-mono</code>.</p>"},{"location":"development/design-system/#component-patterns","title":"Component Patterns","text":""},{"location":"development/design-system/#compact-kpi-strip","title":"Compact KPI Strip","text":"<p>Use this pattern for at-a-glance metrics at the top of dashboard pages. This is the preferred style -- avoid oversized stat cards with <code>text-4xl/5xl</code>.</p> <pre><code>&lt;div class=\"grid grid-cols-2 gap-3 lg:grid-cols-4\"&gt;\n  &lt;!-- Repeat for each KPI --&gt;\n  &lt;div class=\"flex items-center gap-3 rounded-lg border border-border bg-white px-4 py-3\"&gt;\n    &lt;div class=\"flex h-9 w-9 items-center justify-center rounded-lg bg-primary/10\"&gt;\n      &lt;Icon class=\"h-[18px] w-[18px] text-primary\" /&gt;\n    &lt;/div&gt;\n    &lt;div&gt;\n      &lt;div class=\"text-xl font-bold text-text-primary\"&gt;1,234&lt;/div&gt;\n      &lt;div class=\"text-xs text-text-muted\"&gt;Total Items&lt;/div&gt;\n    &lt;/div&gt;\n  &lt;/div&gt;\n&lt;/div&gt;\n</code></pre> <p>Key characteristics:</p> <ul> <li><code>flex items-center gap-3</code> layout (icon + text side by side)</li> <li><code>text-xl font-bold</code> for values (not <code>text-4xl</code>)</li> <li><code>text-xs text-text-muted</code> for labels</li> <li>9x9 icon container with <code>bg-primary/10</code> tint</li> <li><code>border border-border</code> outline</li> <li>Responsive grid: 2 columns on mobile, 4 on large screens</li> </ul>"},{"location":"development/design-system/#chart-container","title":"Chart Container","text":"<p>All Plotly charts are wrapped in a bordered container with a header bar:</p> <pre><code>&lt;div class=\"overflow-hidden rounded-lg border border-border bg-white\"&gt;\n  &lt;div class=\"border-b border-border px-4 py-2\"&gt;\n    &lt;h3 class=\"text-sm font-medium text-text-primary\"&gt;Chart Title&lt;/h3&gt;\n  &lt;/div&gt;\n  &lt;div class=\"px-2 py-2\"&gt;\n    &lt;!-- Plotly chart here --&gt;\n  &lt;/div&gt;\n&lt;/div&gt;\n</code></pre> <p>Key characteristics:</p> <ul> <li><code>rounded-lg border border-border</code> outer container</li> <li>Header row: <code>border-b border-border px-4 py-2</code> with <code>text-sm font-medium</code> title</li> <li>Chart area: <code>px-2 py-2</code> padding around the plot</li> <li><code>overflow-hidden</code> to clip rounded corners</li> </ul>"},{"location":"development/design-system/#pagination-controls","title":"Pagination Controls","text":"<p>Inline pagination with pill-style page buttons. Used on tables and card lists.</p> <pre><code>&lt;div class=\"flex items-center justify-between border-t border-border px-1 pt-3\"&gt;\n  &lt;span class=\"text-xs text-text-muted\"&gt;\n    Showing 1-15 of 73 items\n  &lt;/span&gt;\n  &lt;div class=\"flex items-center gap-1\"&gt;\n    &lt;!-- Previous button --&gt;\n    &lt;button class=\"rounded-md px-2 py-1 text-text-muted hover:bg-gray-100\"&gt;\n      &lt;ChevronLeft /&gt;\n    &lt;/button&gt;\n\n    &lt;!-- Page numbers --&gt;\n    &lt;button class=\"rounded-md px-2.5 py-1 text-xs font-medium bg-primary text-white\"&gt;1&lt;/button&gt;\n    &lt;button class=\"rounded-md px-2.5 py-1 text-xs font-medium text-text-muted hover:bg-gray-100\"&gt;2&lt;/button&gt;\n\n    &lt;!-- Next button --&gt;\n    &lt;button class=\"rounded-md px-2 py-1 text-text-muted hover:bg-gray-100\"&gt;\n      &lt;ChevronRight /&gt;\n    &lt;/button&gt;\n  &lt;/div&gt;\n&lt;/div&gt;\n</code></pre> <p>Behavioral rules:</p> <ul> <li>Reset <code>currentPage</code> to 1 when filters change (via <code>useEffect</code> on filter values)</li> <li>Hide pagination entirely when <code>totalPages &lt;= 1</code></li> <li>Show at most 5 page buttons centered around the current page</li> <li>Active page: <code>bg-primary text-white</code>; inactive: <code>text-text-muted hover:bg-gray-100</code></li> </ul>"},{"location":"development/design-system/#severity-card","title":"Severity Card","text":"<p>Used for hard stops, error details, and alert cards. A left-accent border conveys severity without overwhelming red backgrounds.</p> <pre><code>&lt;div class=\"rounded-lg border border-l-4 border-border border-l-red-400 bg-white p-4\"&gt;\n  &lt;h4 class=\"text-sm font-semibold text-text-primary\"&gt;Card Title&lt;/h4&gt;\n  &lt;p class=\"mt-1 text-xs text-text-muted\"&gt;Subtitle or timestamp&lt;/p&gt;\n  &lt;p class=\"mt-2 text-sm text-text-secondary\"&gt;Description or body content.&lt;/p&gt;\n  &lt;div class=\"mt-3 flex gap-2\"&gt;\n    &lt;span class=\"rounded-full bg-red-50 px-2.5 py-0.5 text-xs font-medium text-red-600\"&gt;\n      Critical\n    &lt;/span&gt;\n    &lt;span class=\"rounded-full bg-gray-100 px-2.5 py-0.5 text-xs font-medium text-text-muted\"&gt;\n      Category\n    &lt;/span&gt;\n  &lt;/div&gt;\n&lt;/div&gt;\n</code></pre> <p>Key characteristics:</p> <ul> <li><code>border-l-4 border-l-red-400</code> left accent (not an all-red background)</li> <li>White background (<code>bg-white</code>)</li> <li>Neutral text colors for titles and body</li> <li>Metadata pills: subtle red (<code>bg-red-50 text-red-600</code>) or neutral (<code>bg-gray-100 text-text-muted</code>)</li> </ul>"},{"location":"development/design-system/#scrollable-column","title":"Scrollable Column","text":"<p>Used for grouped content lists (decision quality, batch details) to prevent page stretching.</p> <pre><code>&lt;div class=\"rounded-lg border border-border bg-white p-4\"&gt;\n  &lt;div class=\"mb-3 flex items-center gap-2\"&gt;\n    &lt;Icon class=\"h-4 w-4 text-primary\" /&gt;\n    &lt;h3 class=\"text-sm font-semibold text-text-primary\"&gt;Section Title&lt;/h3&gt;\n    &lt;span class=\"ml-auto rounded-full bg-primary/10 px-2.5 py-0.5 text-xs font-semibold text-primary\"&gt;\n      12\n    &lt;/span&gt;\n  &lt;/div&gt;\n  &lt;div class=\"max-h-[500px] space-y-2 overflow-y-auto\"&gt;\n    &lt;!-- Scrollable items here --&gt;\n  &lt;/div&gt;\n&lt;/div&gt;\n</code></pre> <p>Key characteristics:</p> <ul> <li><code>max-h-[500px] overflow-y-auto</code> on the content area</li> <li>Count badge in the header with <code>ml-auto</code></li> <li><code>space-y-2</code> gap between items</li> <li>Bordered outer container</li> </ul>"},{"location":"development/design-system/#spacing-conventions","title":"Spacing Conventions","text":""},{"location":"development/design-system/#page-layout","title":"Page Layout","text":"Element Class Value Content padding (vertical) <code>py-6</code> 24px Section gaps <code>space-y-5</code> 20px Card padding <code>p-4</code> 16px Header bar padding <code>px-4 py-2</code> 16px / 8px"},{"location":"development/design-system/#common-spacing","title":"Common Spacing","text":"Context Class Value Inline element gap <code>gap-2</code> 8px Card group gap <code>gap-3</code> 12px Section gap <code>gap-4</code> 16px Component padding <code>p-4</code> or <code>p-5</code> 16px or 20px"},{"location":"development/design-system/#rounded-corners","title":"Rounded Corners","text":"Context Class Cards, containers <code>rounded-lg</code> Tables, modals <code>rounded-xl</code> Hero sections <code>rounded-2xl</code> Badges, pills <code>rounded-full</code>"},{"location":"development/design-system/#plotly-chart-defaults","title":"Plotly Chart Defaults","text":"<p>All Plotly charts in AXIS should use these standardized defaults for consistent appearance.</p>"},{"location":"development/design-system/#layout-defaults","title":"Layout Defaults","text":"<pre><code>const defaultLayout = {\n  autosize: true,\n  margin: { l: 50, r: 30, t: 30, b: 50 },\n  paper_bgcolor: 'transparent',\n  plot_bgcolor: 'transparent',\n  font: {\n    family: 'Inter, system-ui, sans-serif',\n  },\n  colorway: ChartColors,\n};\n</code></pre>"},{"location":"development/design-system/#axis-configuration","title":"Axis Configuration","text":"<p>Apply to both <code>xaxis</code> and <code>yaxis</code> for consistent grid styling:</p> <pre><code>const axisConfig = {\n  showgrid: true,\n  gridcolor: 'rgba(0,0,0,0.05)',\n  zeroline: false,\n  showline: true,\n  linecolor: 'rgba(0,0,0,0.1)',\n  tickfont: { size: 10 },\n};\n</code></pre> <p>Usage:</p> <pre><code>layout: {\n  xaxis: { ...axisConfig, showgrid: false },\n  yaxis: { ...axisConfig, automargin: true },\n}\n</code></pre>"},{"location":"development/design-system/#chart-height","title":"Chart Height","text":"Context Height Margin top Dashboard summary charts <code>180px</code> <code>t: 5</code> Full-page charts <code>300-400px</code> <code>t: 30</code> Detail/modal charts <code>250px</code> <code>t: 20</code> <p>When a chart is inside a <code>ChartContainer</code> with its own header, set <code>t: 5</code> to avoid double spacing.</p>"},{"location":"development/design-system/#chart-color-sequence","title":"Chart Color Sequence","text":"<p>The <code>ChartColors</code> array is defined in <code>types/index.ts</code> and used as the default <code>colorway</code>:</p> <pre><code>const ChartColors = [\n  '#8B9F4F',  // primary (sage green)\n  '#A4B86C',  // primary-light\n  '#6B7A3A',  // primary-dark\n  '#B8C78A',  // primary-soft\n  '#D4AF37',  // accent-gold\n  '#B8C5D3',  // accent-silver\n  '#D4E0B8',  // primary-pale\n  '#1f77b4',  // blue\n  '#ff7f0e',  // orange\n  '#2ca02c',  // green\n];\n</code></pre> <p>For single-series charts, use <code>ChartColors[0]</code> (<code>#8B9F4F</code>). For multi-series, Plotly cycles through <code>colorway</code> automatically.</p>"},{"location":"development/design-system/#plotly-config","title":"Plotly Config","text":"<p>Disable unnecessary toolbar buttons for a cleaner look:</p> <pre><code>const plotlyConfig = {\n  displayModeBar: true,\n  displaylogo: false,\n  modeBarButtonsToRemove: [\n    'lasso2d',\n    'select2d',\n    'autoScale2d',\n  ],\n  responsive: true,\n};\n</code></pre>"},{"location":"development/design-system/#css-utility-classes","title":"CSS Utility Classes","text":"<p>These custom classes are defined in <code>frontend/src/app/globals.css</code>:</p> Class Description <code>.card</code> Base card: <code>rounded-xl</code>, border, shadow <code>.card-interactive</code> Card with hover elevation transition <code>.card-glass</code> Glassmorphism card with backdrop blur <code>.badge-success</code> Green status badge <code>.badge-warning</code> Yellow status badge <code>.badge-error</code> Red status badge <p><code>.stat-card</code> is deprecated</p> <p>The <code>.stat-card</code> class with oversized centered numbers is deprecated. Use the Compact KPI Strip pattern instead.</p>"},{"location":"development/design-system/#responsive-breakpoints","title":"Responsive Breakpoints","text":"<p>AXIS uses Tailwind's default breakpoints:</p> Prefix Min Width Usage <code>sm</code> 640px Stack to row transitions <code>md</code> 768px Tablet layout adjustments <code>lg</code> 1024px Desktop layouts, 4-column grids <code>xl</code> 1280px Wide desktop optimizations <code>2xl</code> 1536px Ultra-wide monitors <p>Common responsive patterns:</p> <pre><code>&lt;!-- 2 cols mobile, 4 cols desktop --&gt;\n&lt;div class=\"grid grid-cols-2 gap-3 lg:grid-cols-4\"&gt;\n\n&lt;!-- Stack on mobile, side-by-side on desktop --&gt;\n&lt;div class=\"flex flex-col gap-4 lg:flex-row\"&gt;\n\n&lt;!-- Full width mobile, constrained desktop --&gt;\n&lt;div class=\"w-full lg:max-w-[600px]\"&gt;\n</code></pre>"},{"location":"development/design-system/#related-pages","title":"Related Pages","text":"<ul> <li>Theming -- switch palettes, create custom themes, branding assets</li> <li>Code Conventions -- file naming and component structure patterns</li> <li>Architecture: Frontend -- component organization and state management</li> </ul>"},{"location":"development/repository-model/","title":"Repository Model (Framework + Use-Case + Deploy)","text":"<p>AXIS supports multiple deployments (use-cases / customers) without forking or mixing proprietary configuration into the framework codebase.</p> <p>This page defines a 3-repo model and walks through exactly how to deploy each piece.</p> <p>Default recommendation</p> <p>Use backend asset proxy URLs as the production contract: - <code>/api/config/assets/branding/&lt;file&gt;</code> - <code>/api/config/assets/agents/&lt;file&gt;</code></p> <p>Keep <code>/branding/*</code> and <code>/agents/*</code> as local-dev convenience paths only.</p>"},{"location":"development/repository-model/#the-three-repos","title":"The three repos","text":"Repo Example name Contains Visibility A \u2014 Framework <code>ax-foundry/axis</code> All backend + frontend code, <code>.example</code> configs, docs Public / open-source B \u2014 Use-case config <code>your-org/axis-custom-acme</code> Only <code>custom/</code> \u2014 YAML configs, branding images, agent avatars Private C \u2014 Deploy/Platform <code>your-org/acme-platform</code> Terraform, Docker base images, GitHub Actions that assemble A + B and deploy Private <pre><code>flowchart LR\n  A[Repo A: axis&lt;br/&gt;framework code] --&gt; C[Repo C: platform&lt;br/&gt;assembles + deploys]\n  B[Repo B: axis-custom-acme&lt;br/&gt;custom/ config] --&gt; C\n  C --&gt;|frontend image| V[Vercel]\n  C --&gt;|backend image| G[GCP Cloud Run]\n  C --&gt;|infra| T[Terraform&lt;br/&gt;DNS \u00b7 DB \u00b7 Secrets]</code></pre>"},{"location":"development/repository-model/#repo-a-framework-axis","title":"Repo A \u2014 Framework (<code>axis</code>)","text":""},{"location":"development/repository-model/#what-belongs-here","title":"What belongs here","text":"<ul> <li><code>backend/app/**</code> \u2014 FastAPI routers, services, models, copilot</li> <li><code>frontend/src/**</code> \u2014 Next.js App Router, components, stores</li> <li><code>backend/config/*.yaml.example</code> \u2014 config templates (tracked)</li> <li><code>docs/**</code>, <code>mkdocs.yml</code> \u2014 documentation site</li> <li><code>Makefile</code>, <code>scripts/**</code>, pre-commit config</li> <li><code>custom/README.md</code> \u2014 documents the config contract (tracked)</li> <li><code>backend/Dockerfile</code>, <code>frontend/Dockerfile</code> \u2014 build definitions</li> </ul>"},{"location":"development/repository-model/#what-does-not-belong-here","title":"What does NOT belong here","text":"<ul> <li>Real YAML configs (<code>custom/config/*.yaml</code> is gitignored)</li> <li>Branding images or agent avatars</li> <li>Secrets (API keys, DB passwords)</li> <li>Terraform / CI / deployment workflows</li> </ul>"},{"location":"development/repository-model/#ci-runs-on-every-pr-to-master","title":"CI (runs on every PR to <code>master</code>)","text":"<pre><code># .github/workflows/ci.yml \u2014 runs in Repo A\njobs:\n  backend:\n    steps:\n      - ruff check app --fix &amp;&amp; ruff format app\n      - pytest\n  frontend:\n    steps:\n      - npm run lint &amp;&amp; npx tsc --noEmit\n      - npm run build\n  docs:\n    steps:\n      - mkdocs build --strict\n</code></pre>"},{"location":"development/repository-model/#repo-b-use-case-config-axis-custom-name","title":"Repo B \u2014 Use-case config (<code>axis-custom-&lt;name&gt;</code>)","text":""},{"location":"development/repository-model/#structure","title":"Structure","text":"<pre><code>axis-custom-acme/\n\u251c\u2500\u2500 config/\n\u2502   \u251c\u2500\u2500 theme.yaml              # Branding: app name, palette, hero image paths\n\u2502   \u251c\u2500\u2500 agents.yaml             # Agent registry (name, label, role, avatar)\n\u2502   \u251c\u2500\u2500 eval_db.yaml            # Eval DB connection + queries (no passwords)\n\u2502   \u251c\u2500\u2500 monitoring_db.yaml      # Monitoring thresholds, anomaly detection\n\u2502   \u251c\u2500\u2500 human_signals_db.yaml   # Human signals schema + visible metrics\n\u2502   \u251c\u2500\u2500 kpi_db.yaml             # KPI categories, display overrides\n\u2502   \u251c\u2500\u2500 duckdb.yaml             # Sync mode, chunk size, concurrency\n\u2502   \u251c\u2500\u2500 memory.yaml             # Memory field roles, action colors\n\u2502   \u251c\u2500\u2500 signals_metrics.yaml    # Signals dashboard display overrides\n\u2502   \u251c\u2500\u2500 agent_replay.yaml       # Langfuse defaults\n\u2502   \u2514\u2500\u2500 agent_replay_db.yaml    # Per-agent table/column overrides\n\u251c\u2500\u2500 branding/\n\u2502   \u251c\u2500\u2500 hero.svg                # Hero background image\n\u2502   \u251c\u2500\u2500 favicon.ico             # Browser tab icon\n\u2502   \u251c\u2500\u2500 app-icon.ico            # Sidebar logo\n\u2502   \u2514\u2500\u2500 logo.png                # (optional) header logo\n\u251c\u2500\u2500 agents/\n\u2502   \u251c\u2500\u2500 agent-alpha.ico         # Agent avatars\n\u2502   \u2514\u2500\u2500 agent-beta.ico\n\u2514\u2500\u2500 README.md\n</code></pre>"},{"location":"development/repository-model/#rules","title":"Rules","text":"<ul> <li>No credentials, ever. Repo B must never contain passwords, API keys, tokens, or connection strings. YAML files set non-secret fields (<code>host</code>, <code>port</code>, <code>ssl_mode</code>, <code>query</code>, <code>table</code>, flags) and leave credential fields as <code>null</code> or omitted. Actual credentials are injected at runtime as env vars from GCP Secret Manager (backend) or Vercel project settings (frontend). If <code>grep -rE '(password|secret|key)\\s*:' config/</code> matches a non-null value, the commit should be rejected.</li> <li>No application code. If you need custom behavior, it goes in Repo A behind a config flag.</li> <li>No infrastructure. Terraform, Docker, CI \u2192 Repo C.</li> </ul>"},{"location":"development/repository-model/#example-themeyaml","title":"Example <code>theme.yaml</code>","text":"<pre><code>theme:\n  active: \"professional_blue\"\n  branding:\n    app_name: \"Acme Eval\"\n    tagline: \"AI Quality for Acme\"\n    subtitle: \"Acme Evaluation Studio\"\n    report_footer: \"Report generated by Acme Eval\"\n    footer_name: \"Acme\"\n  palettes:\n    professional_blue:\n      name: \"Professional Blue\"\n      primary: \"#3D5A80\"\n      primaryLight: \"#5C7AA3\"\n      primaryDark: \"#2B3C73\"\n      primarySoft: \"#8BA4C4\"\n      primaryPale: \"#C5D4E8\"\n      accentGold: \"#D4AF37\"\n      accentSilver: \"#B8C5D3\"\n      heroImage: \"/api/config/assets/branding/hero.svg\"\n      faviconUrl: \"/api/config/assets/branding/favicon.ico\"\n      appIconUrl: \"/api/config/assets/branding/app-icon.ico\"\n      heroMode: \"light\"\n      heroOpacity: 0.6\n</code></pre> <p>Image paths use <code>/api/config/assets/branding/*</code> \u2014 the backend serves these from <code>CUSTOM_DIR/branding/</code>. This works in both local dev (via Next.js rewrite) and production (via reverse proxy).</p>"},{"location":"development/repository-model/#repo-c-deployplatform-acme-platform","title":"Repo C \u2014 Deploy/Platform (<code>acme-platform</code>)","text":""},{"location":"development/repository-model/#what-belongs-here_1","title":"What belongs here","text":"<ul> <li>Terraform: DNS, TLS, Cloud Run services, databases, IAM, Secret Manager entries</li> <li>Docker base images (if any)</li> <li>GitHub Actions workflows that:<ol> <li>Check out Repo A + Repo B</li> <li>Inject <code>custom/</code> into the framework workspace</li> <li>Build + push Docker images</li> <li>Deploy to Vercel / Cloud Run</li> </ol> </li> <li>Environment overlays: per-environment variables (prod, staging)</li> <li>Use-case selector: which Repo B to deploy (a variable or input)</li> </ul>"},{"location":"development/repository-model/#what-does-not-belong-here_1","title":"What does NOT belong here","text":"<ul> <li>Application code changes (\u2192 Repo A)</li> <li>Raw secrets in plaintext (\u2192 GCP Secret Manager, Vercel env vars)</li> <li>YAML configs (\u2192 Repo B)</li> </ul>"},{"location":"development/repository-model/#deploying-the-frontend-vercel","title":"Deploying the frontend (Vercel)","text":"<p>The frontend is fully generic. It has zero dependency on Repo B at build time \u2014 no branding images, no YAML configs, no agent avatars need to be present in the Vercel build workspace.</p> <p>This works because:</p> <ul> <li>Theme/branding text is fetched at runtime via <code>GET /api/config/theme</code> (backend API)</li> <li>Branding images are served by the backend at <code>/api/config/assets/branding/{filename}</code> \u2014 the frontend never serves these from its own <code>public/</code> directory in production</li> <li>Agent avatars are served the same way at <code>/api/config/assets/agents/{filename}</code></li> <li><code>next.config.js</code> contains a rewrite rule that proxies <code>/api/*</code> requests to the backend, so image <code>src=\"/api/config/assets/branding/hero.svg\"</code> works without the browser needing to know the backend URL</li> </ul> <p>There is no symlink or file-copy step needed for Vercel builds. The <code>make setup</code> symlinks (<code>frontend/public/branding \u2192 custom/branding</code>) are a local dev convenience only.</p>"},{"location":"development/repository-model/#what-vercel-needs","title":"What Vercel needs","text":"Setting Value Where to set <code>NEXT_PUBLIC_API_URL</code> <code>https://api.acme.example.com</code> Vercel project \u2192 Environment Variables <p>That's it. One env var.</p>"},{"location":"development/repository-model/#how-it-works","title":"How it works","text":"<ol> <li>Vercel builds the frontend from Repo A's <code>frontend/</code> directory (no Repo B checkout needed)</li> <li><code>NEXT_PUBLIC_API_URL</code> is baked into the JS bundle at build time</li> <li>At runtime, the frontend fetches <code>/api/config/theme</code> from the backend to get branding, colors, and image paths</li> <li>Image <code>src</code> attributes like <code>/api/config/assets/branding/hero.svg</code> are proxied to the backend via the Next.js rewrite rule in <code>next.config.js</code> \u2014 the browser never calls the backend directly for these</li> </ol>"},{"location":"development/repository-model/#vercel-project-setup","title":"Vercel project setup","text":"<p>Connect Vercel to Repo A (the framework repo):</p> <ul> <li>Root directory: <code>frontend</code></li> <li>Build command: <code>npm run build</code></li> <li>Output directory: <code>.next</code></li> <li>Install command: <code>npm ci</code></li> </ul> <p>Or trigger deploys from Repo C's CI:</p> <pre><code># In Repo C's GitHub Actions workflow\nvercel deploy --prod \\\n  --token=$VERCEL_TOKEN \\\n  --env NEXT_PUBLIC_API_URL=https://api.acme.example.com\n</code></pre>"},{"location":"development/repository-model/#preview-deployments","title":"Preview deployments","text":"<p>Every PR to Repo A gets a Vercel preview URL automatically. Since the frontend is generic, previews work against any backend \u2014 just set <code>NEXT_PUBLIC_API_URL</code> in the preview environment to point at a staging backend.</p>"},{"location":"development/repository-model/#deploying-the-backend-gcp-cloud-run","title":"Deploying the backend (GCP Cloud Run)","text":"<p>The backend image includes the use-case config. Repo C's CI assembles Repo A + Repo B, builds the image, and deploys it.</p>"},{"location":"development/repository-model/#build-pipeline-repo-cs-github-actions","title":"Build pipeline (Repo C's GitHub Actions)","text":"<pre><code># .github/workflows/deploy-backend.yml \u2014 lives in Repo C\nname: Deploy Backend\non:\n  push:\n    branches: [main]\n  workflow_dispatch:\n    inputs:\n      framework_ref:\n        description: 'Framework repo ref (tag or SHA)'\n        default: 'master'\n      config_ref:\n        description: 'Config repo ref (tag or SHA)'\n        default: 'main'\n\nenv:\n  REGION: us-central1\n  PROJECT_ID: your-gcp-project\n  SERVICE_NAME: axis-api\n  IMAGE: us-central1-docker.pkg.dev/your-gcp-project/axis/api\n\njobs:\n  build-deploy:\n    runs-on: ubuntu-latest\n    permissions:\n      contents: read\n      id-token: write  # For Workload Identity Federation\n\n    steps:\n      # 1. Check out Repo A (framework)\n      - name: Checkout framework\n        uses: actions/checkout@v4\n        with:\n          repository: ax-foundry/axis\n          ref: ${{ inputs.framework_ref || 'master' }}\n          path: axis\n\n      # 2. Check out Repo B (use-case config)\n      - name: Checkout config\n        uses: actions/checkout@v4\n        with:\n          repository: your-org/axis-custom-acme\n          ref: ${{ inputs.config_ref || 'main' }}\n          path: config\n          token: ${{ secrets.CONFIG_REPO_PAT }}\n\n      # 3. Inject custom/ into framework workspace\n      - name: Assemble workspace\n        run: |\n          cp -r config/config axis/backend/custom/config\n          cp -r config/branding axis/backend/custom/branding\n          cp -r config/agents axis/backend/custom/agents\n\n      # 4. Authenticate to GCP\n      - name: Auth to GCP\n        uses: google-github-actions/auth@v2\n        with:\n          workload_identity_provider: ${{ secrets.WIF_PROVIDER }}\n          service_account: ${{ secrets.WIF_SA }}\n\n      # 5. Build + push Docker image\n      - name: Build and push\n        run: |\n          gcloud auth configure-docker ${{ env.REGION }}-docker.pkg.dev --quiet\n          docker build \\\n            -t ${{ env.IMAGE }}:${{ github.sha }} \\\n            -t ${{ env.IMAGE }}:latest \\\n            axis/backend\n          docker push ${{ env.IMAGE }} --all-tags\n\n      # 6. Deploy to Cloud Run\n      - name: Deploy to Cloud Run\n        run: |\n          gcloud run deploy ${{ env.SERVICE_NAME }} \\\n            --image=${{ env.IMAGE }}:${{ github.sha }} \\\n            --region=${{ env.REGION }} \\\n            --platform=managed \\\n            --allow-unauthenticated \\\n            --set-env-vars=\"AXIS_CUSTOM_DIR=/app/custom,DEBUG=false\" \\\n            --set-secrets=\"OPENAI_API_KEY=openai-api-key:latest,ANTHROPIC_API_KEY=anthropic-api-key:latest,EVAL_DB_URL=eval-db-url:latest,MONITORING_DB_URL=monitoring-db-url:latest\" \\  # pragma: allowlist secret\n            --port=8500 \\\n            --memory=1Gi \\\n            --cpu=1 \\\n            --min-instances=0 \\\n            --max-instances=4\n</code></pre>"},{"location":"development/repository-model/#what-the-dockerfile-does","title":"What the Dockerfile does","text":"<pre><code># backend/Dockerfile (lives in Repo A)\nFROM python:3.12-slim\nWORKDIR /app\n\nCOPY requirements.txt .\nRUN pip install --no-cache-dir -r requirements.txt\n\nCOPY . .\n\n# Ensure custom/ dirs exist (empty if no config injected)\nRUN mkdir -p /app/custom/config /app/custom/branding /app/custom/agents\nENV AXIS_CUSTOM_DIR=/app/custom\n\nRUN useradd -m -u 1000 appuser &amp;&amp; chown -R appuser:appuser /app\nUSER appuser\n\nEXPOSE 8500\nCMD [\"sh\", \"-c\", \"uvicorn app.main:app --host 0.0.0.0 --port ${PORT:-8500} --proxy-headers --forwarded-allow-ips='*'\"]\n</code></pre> <p>The <code>COPY . .</code> picks up whatever is in the build context \u2014 including <code>custom/</code> if Repo C's pipeline placed it there. The <code>mkdir</code> ensures the build succeeds even without config (empty defaults).</p>"},{"location":"development/repository-model/#how-branding-images-are-served","title":"How branding images are served","text":"<p>The backend has an asset proxy endpoint:</p> <pre><code>GET /api/config/assets/branding/{filename}  \u2192 serves custom/branding/{filename}\nGET /api/config/assets/agents/{filename}    \u2192 serves custom/agents/{filename}\n</code></pre> <p>Branding files get a 1-year immutable cache header. Agent avatars get a 24-hour cache. Path traversal is blocked.</p>"},{"location":"development/repository-model/#secrets-management","title":"Secrets management","text":"<p>Secrets never live in Repo A or Repo B. They're injected at runtime from the deployment environment.</p> Secret Where it lives How it's injected <code>OPENAI_API_KEY</code> GCP Secret Manager <code>--set-secrets</code> in Cloud Run deploy <code>ANTHROPIC_API_KEY</code> GCP Secret Manager <code>--set-secrets</code> in Cloud Run deploy <code>EVAL_DB_URL</code> GCP Secret Manager <code>--set-secrets</code> in Cloud Run deploy <code>MONITORING_DB_URL</code> GCP Secret Manager <code>--set-secrets</code> in Cloud Run deploy <code>HUMAN_SIGNALS_DB_URL</code> GCP Secret Manager <code>--set-secrets</code> in Cloud Run deploy <code>LANGFUSE_*_SECRET_KEY</code> GCP Secret Manager <code>--set-secrets</code> in Cloud Run deploy <code>NEXT_PUBLIC_API_URL</code> Vercel project settings Build-time env var <p>YAML config files in Repo B set connection details like <code>host</code>, <code>port</code>, <code>ssl_mode</code>, and <code>query</code> \u2014 but passwords stay <code>null</code>. The <code>url</code> field in env vars (from Secret Manager) takes precedence and provides the full connection string including credentials.</p>"},{"location":"development/repository-model/#local-development","title":"Local development","text":""},{"location":"development/repository-model/#framework-only-generic-axis-defaults","title":"Framework-only (generic AXIS defaults)","text":"<pre><code>git clone ax-foundry/axis &amp;&amp; cd axis\nmake setup    # copies .example templates into custom/, creates symlinks\nmake dev      # starts backend + frontend + FalkorDB\n</code></pre> <p>This gives you AXIS with default branding and empty database connections. Good for developing features in Repo A.</p>"},{"location":"development/repository-model/#with-use-case-config","title":"With use-case config","text":"<p>Clone both repos side by side and point AXIS at the config repo via env var:</p> <pre><code>git clone ax-foundry/axis &amp;&amp; cd axis\ngit clone ax-foundry/axis-custom-acme ../axis-custom-acme\n\n# Point AXIS at the config repo (absolute path)\nexport AXIS_CUSTOM_DIR=$(cd ../axis-custom-acme &amp;&amp; pwd)\n\nmake dev\n</code></pre> <p>This is the recommended approach because:</p> <ul> <li>No nested <code>.git</code> directories (avoids tooling confusion, accidental commits to the wrong repo)</li> <li>No manual copy step \u2014 changes in <code>axis-custom-acme/</code> are picked up on backend restart</li> <li><code>custom/</code> in the framework repo stays gitignored and empty</li> </ul> <p>Persist the env var</p> <p>Add <code>AXIS_CUSTOM_DIR=/absolute/path/to/axis-custom-acme</code> to your shell profile or a local <code>.envrc</code> (if using direnv) so you don't have to re-export it every session.</p> Alternative: copy into custom/ <p>If you prefer a self-contained workspace, you can copy files instead:</p> <pre><code>cp -r ../axis-custom-acme/config custom/config\ncp -r ../axis-custom-acme/branding custom/branding\ncp -r ../axis-custom-acme/agents custom/agents\nmake dev\n</code></pre> <p>Downside: you must re-copy after pulling config changes, and <code>custom/</code> now contains untracked files that could cause confusion with git.</p>"},{"location":"development/repository-model/#docker-compose-local","title":"Docker Compose (local)","text":"<p>The <code>docker-compose.yml</code> in Repo A mounts <code>custom/</code> as a read-only volume:</p> <pre><code>services:\n  backend:\n    environment:\n      - AXIS_CUSTOM_DIR=/app/custom\n    volumes:\n      - ./custom:/app/custom:ro\n</code></pre> <p>If using Option A above, change the volume mount to point at the config repo:</p> <pre><code>    volumes:\n      - ../axis-custom-acme:/app/custom:ro\n</code></pre>"},{"location":"development/repository-model/#assembly-patterns","title":"Assembly patterns","text":""},{"location":"development/repository-model/#ci-checkout-recommended","title":"CI checkout (recommended)","text":"<p>Pipeline checks out both repos side by side and copies Repo B into Repo A's workspace. This is shown in the Cloud Run deploy workflow above.</p> <p>Pros: Simple, explicit, no git submodule friction. Cons: Requires a PAT or deploy key to access the private config repo.</p>"},{"location":"development/repository-model/#git-submodule","title":"Git submodule","text":"<p>Repo C pins exact commits of A and B via submodules.</p> <p>Pros: Reproducible \u2014 <code>git submodule update --init</code> gives you the exact versions. Cons: Submodules add friction (forgotten updates, detached HEAD). Not worth it unless you need strict reproducibility.</p>"},{"location":"development/repository-model/#bake-vs-mount","title":"Bake vs. mount","text":"Approach How Best for Bake into image CI copies <code>custom/</code> into build context before <code>docker build</code> Cloud Run, ECS, any immutable deploy Volume mount Mount <code>custom/</code> at runtime via <code>-v</code> or k8s ConfigMap Docker Compose, Kubernetes, when you want to change config without rebuilding <p>For Cloud Run + Vercel, bake into the image. Cloud Run doesn't support volume mounts, so config must be in the image. This also makes deploys fully immutable \u2014 the image is the artifact.</p>"},{"location":"development/repository-model/#versioning-strategy","title":"Versioning strategy","text":"<p>Pin exact commits per environment. This is not optional for production \u2014 you must be able to answer \"what code and config is running right now?\" and reproduce any deploy.</p> <p>Repo C maintains a versions file (or workflow inputs) that pins both repos:</p> <pre><code># versions.yaml (in Repo C, or hardcoded in the workflow)\nproduction:\n  framework_ref: v1.2.0            # Repo A tag or SHA\n  config_ref: v2024.02.23          # Repo B tag or SHA\n\nstaging:\n  framework_ref: master            # Track latest for staging (acceptable)\n  config_ref: main                 # Track latest for staging (acceptable)\n</code></pre>"},{"location":"development/repository-model/#deploy-workflows","title":"Deploy workflows","text":"<ul> <li>New framework version: bump <code>framework_ref</code> in Repo C, push \u2192 CI rebuilds and deploys</li> <li>Config change (branding, thresholds, new agent): bump <code>config_ref</code> in Repo C, push \u2192 CI rebuilds and deploys</li> <li>Both: bump both in one commit</li> </ul>"},{"location":"development/repository-model/#why-pinning-matters","title":"Why pinning matters","text":"<p>Without pinning, a push to Repo A's <code>master</code> or Repo B's <code>main</code> could silently change what's running in production. Pinning ensures:</p> <ul> <li>Every deploy is an explicit, reviewable change in Repo C</li> <li>You can roll back by reverting a single commit</li> <li>Staging can track branches for fast iteration while production stays locked</li> </ul>"},{"location":"development/repository-model/#related-docs","title":"Related docs","text":"<ul> <li>Customization \u2014 what goes in <code>custom/</code> and how it's loaded</li> <li>Docker \u2014 container workflow and <code>docker-compose.yml</code> reference</li> <li>Production Deployment \u2014 reverse proxy, health checks, scaling</li> <li>Environment Variables \u2014 complete env var reference</li> </ul>"},{"location":"development/setup/","title":"Development Setup","text":"<p>This page covers the full development environment setup: installing tools, configuring your IDE, enabling pre-commit hooks, and creating environment files.</p>"},{"location":"development/setup/#prerequisites","title":"Prerequisites","text":"Tool Version Purpose Python 3.12+ Backend runtime Node.js 20+ Frontend runtime npm (bundled) Frontend package manager pip (bundled) Backend package manager make any Monorepo task runner pre-commit 3.5+ Git hook manager <p>Verify versions</p> <pre><code>python --version   # 3.12.x\nnode --version     # v20.x.x\nmake --version\npre-commit --version\n</code></pre>"},{"location":"development/setup/#install-dependencies","title":"Install Dependencies","text":""},{"location":"development/setup/#one-command-install","title":"One-command install","text":"<p>From the repository root:</p> <pre><code>make install\n</code></pre> <p>This runs three steps:</p> <ol> <li>Installs pre-commit hooks</li> <li><code>pip install -e \".[dev,graph]\"</code> in <code>backend/</code> (all runtime, dev, and graph deps from <code>pyproject.toml</code>)</li> <li><code>npm install</code> in <code>frontend/</code></li> </ol>"},{"location":"development/setup/#manual-install","title":"Manual install","text":"BackendFrontendPre-commit <pre><code>cd backend\npip install -e .               # runtime only\npip install -e \".[dev]\"        # + linters &amp; tests\npip install -e \".[dev,graph]\"  # full development with graph features\n</code></pre> <pre><code>cd frontend\nnpm install\n</code></pre> <pre><code>pip install pre-commit\npre-commit install\n</code></pre>"},{"location":"development/setup/#pre-commit-hooks","title":"Pre-commit Hooks","text":"<p>AXIS uses pre-commit to run quality checks on every commit. The hooks are defined in <code>.pre-commit-config.yaml</code> at the repo root.</p>"},{"location":"development/setup/#what-runs-on-commit","title":"What runs on commit","text":"Hook Scope What it does <code>trailing-whitespace</code> All files Strips trailing whitespace <code>end-of-file-fixer</code> All files Ensures files end with a newline <code>check-yaml</code> YAML files Validates YAML syntax <code>check-json</code> JSON files Validates JSON syntax <code>check-added-large-files</code> All files Blocks files over 500KB <code>check-merge-conflict</code> All files Detects merge conflict markers <code>detect-private-key</code> All files Blocks accidental key commits <code>ruff</code> <code>backend/</code> Lint + auto-fix Python <code>ruff-format</code> <code>backend/</code> Format Python <code>prettier</code> <code>frontend/</code> Format JS/TS/CSS/JSON/MD <code>eslint</code> <code>frontend/</code> Lint TypeScript"},{"location":"development/setup/#run-hooks-manually","title":"Run hooks manually","text":"<pre><code># Run on staged files\npre-commit run\n\n# Run on all files\npre-commit run --all-files\n\n# Or via Makefile\nmake pre-commit-all\n</code></pre>"},{"location":"development/setup/#skip-hooks-escape-hatch","title":"Skip hooks (escape hatch)","text":"<p>In rare cases where you need to bypass hooks temporarily:</p> <pre><code>git commit --no-verify -m \"WIP: work in progress\"\n</code></pre> <p>Warning</p> <p>Only skip hooks for temporary WIP commits. CI will still enforce all checks.</p>"},{"location":"development/setup/#environment-files","title":"Environment Files","text":"<p>AXIS uses <code>.env</code> files for configuration. These are git-ignored and must be created manually.</p>"},{"location":"development/setup/#backend-backendenv","title":"Backend: <code>backend/.env</code>","text":"backend/.env<pre><code># Server (required)\nHOST=127.0.0.1\nPORT=8500\nDEBUG=true\nFRONTEND_URL=http://localhost:3500\n\n# AI / Copilot (optional)\nOPENAI_API_KEY=your_key_here\nANTHROPIC_API_KEY=your_key_here\nLLM_MODEL_NAME=gpt-4\n\n# Database (optional -- only needed for DB features)\nhuman_signals_db_host=localhost\nhuman_signals_db_port=5432\nhuman_signals_db_name=human_signals\nhuman_signals_db_user=postgres\nhuman_signals_db_password=secret\n\n# Graph DB (optional -- only needed for Knowledge Graph)\ngraph_db_host=localhost\ngraph_db_port=6379\ngraph_db_name=axis\ngraph_db_password=\n</code></pre>"},{"location":"development/setup/#frontend-frontendenvlocal","title":"Frontend: <code>frontend/.env.local</code>","text":"frontend/.env.local<pre><code>NEXT_PUBLIC_API_URL=http://localhost:8500\n</code></pre> <p>Frontend env var rules</p> <p>Only <code>NEXT_PUBLIC_*</code> variables are exposed to the browser. Never place secrets in this file.</p> <p>Keep secrets out of version control</p> <p>The <code>.gitignore</code> already excludes <code>.env</code> files, but never paste API keys into tracked files.</p>"},{"location":"development/setup/#ide-configuration","title":"IDE Configuration","text":""},{"location":"development/setup/#vscode-recommended","title":"VSCode (Recommended)","text":""},{"location":"development/setup/#recommended-extensions","title":"Recommended Extensions","text":"<p>Create or merge into <code>.vscode/extensions.json</code>:</p> .vscode/extensions.json<pre><code>{\n  \"recommendations\": [\n    \"ms-python.python\",\n    \"charliermarsh.ruff\",\n    \"ms-python.mypy-type-checker\",\n    \"dbaeumer.vscode-eslint\",\n    \"esbenp.prettier-vscode\",\n    \"bradlc.vscode-tailwindcss\",\n    \"ms-playwright.playwright\",\n    \"yzhang.markdown-all-in-one\"\n  ]\n}\n</code></pre>"},{"location":"development/setup/#workspace-settings","title":"Workspace Settings","text":"<p>Create or merge into <code>.vscode/settings.json</code>:</p> .vscode/settings.json<pre><code>{\n  \"editor.formatOnSave\": true,\n  \"editor.defaultFormatter\": \"esbenp.prettier-vscode\",\n  \"editor.codeActionsOnSave\": {\n    \"source.fixAll.eslint\": \"explicit\",\n    \"source.organizeImports\": \"never\"\n  },\n\n  \"[python]\": {\n    \"editor.defaultFormatter\": \"charliermarsh.ruff\",\n    \"editor.codeActionsOnSave\": {\n      \"source.fixAll.ruff\": \"explicit\",\n      \"source.organizeImports.ruff\": \"explicit\"\n    }\n  },\n\n  \"python.analysis.typeCheckingMode\": \"basic\",\n  \"ruff.lint.args\": [\"--config=backend/pyproject.toml\"],\n\n  \"typescript.preferences.importModuleSpecifier\": \"non-relative\",\n  \"typescript.tsdk\": \"frontend/node_modules/typescript/lib\",\n\n  \"tailwindCSS.experimental.classRegex\": [\n    [\"cn\\\\(([^)]*)\\\\)\", \"'([^']*)'\"]\n  ],\n\n  \"files.exclude\": {\n    \"**/__pycache__\": true,\n    \"**/.pytest_cache\": true,\n    \"**/.ruff_cache\": true,\n    \"**/.mypy_cache\": true,\n    \"**/node_modules\": true,\n    \"**/.next\": true\n  }\n}\n</code></pre>"},{"location":"development/setup/#other-editors","title":"Other Editors","text":"<p>The key requirements for any editor:</p> <ul> <li>Python: Ruff for linting/formatting, mypy for type checking</li> <li>TypeScript: ESLint with <code>next/core-web-vitals</code> config, Prettier for formatting</li> <li>Path alias: Configure <code>@/</code> to resolve to <code>frontend/src/</code></li> <li>Tailwind: IntelliSense for class name autocomplete</li> </ul>"},{"location":"development/setup/#start-development","title":"Start Development","text":"<p>Once everything is installed, start both servers:</p> <pre><code>make dev\n</code></pre> <p>Or start them individually:</p> BackendFrontend <pre><code>make dev-backend\n# or: cd backend &amp;&amp; uvicorn app.main:app --reload --port 8500\n</code></pre> <pre><code>make dev-frontend\n# or: cd frontend &amp;&amp; npm run dev\n</code></pre> <p>Verify the services are running:</p> <ul> <li>Frontend: http://localhost:3500</li> <li>Backend health: http://localhost:8500/health</li> <li>API docs: http://localhost:8500/docs</li> </ul>"},{"location":"development/setup/#before-every-commit","title":"Before Every Commit","text":"<p>Run the full check suite to catch issues before CI:</p> Quick Check (minimum)Full Check <pre><code># Backend\ncd backend &amp;&amp; ruff check app --fix &amp;&amp; ruff format app\n\n# Frontend\ncd frontend &amp;&amp; npm run format &amp;&amp; npm run lint &amp;&amp; npx tsc --noEmit\n</code></pre> <pre><code>make lint-fix\nmake typecheck\nmake test\n</code></pre>"},{"location":"development/setup/#next-steps","title":"Next Steps","text":"<ul> <li>Code Conventions -- naming, imports, and structural patterns</li> <li>Adding Features -- step-by-step feature development guide</li> <li>Testing -- test frameworks and how to run them</li> </ul>"},{"location":"development/testing/","title":"Testing","text":"<p>AXIS uses three testing frameworks: pytest for the backend, Vitest for frontend unit tests, and Playwright for end-to-end browser tests. All can be run individually or together via the Makefile.</p>"},{"location":"development/testing/#quick-reference","title":"Quick Reference","text":"<pre><code># Run everything\nmake test\n\n# Individual targets\nmake test-backend      # pytest\nmake test-frontend     # Vitest\nmake test-e2e          # Playwright\n</code></pre>"},{"location":"development/testing/#backend-tests-pytest","title":"Backend Tests (pytest)","text":""},{"location":"development/testing/#setup","title":"Setup","text":"<p>Backend tests use pytest with the <code>pytest-asyncio</code> plugin for async test support and <code>pytest-cov</code> for coverage.</p> <p>These packages are included in <code>backend/requirements.txt</code>. No additional installation is needed beyond <code>make install</code>.</p>"},{"location":"development/testing/#directory-structure","title":"Directory Structure","text":"<pre><code>backend/\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 conftest.py         # Shared fixtures\n\u2502   \u251c\u2500\u2500 test_data.py        # Data processing tests\n\u2502   \u251c\u2500\u2500 test_analytics.py   # Analytics tests\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 app/                    # Source code\n</code></pre>"},{"location":"development/testing/#running-tests","title":"Running Tests","text":"<pre><code>cd backend\n\n# Run all tests\npytest tests -v\n\n# Run with coverage\npytest tests --cov=app --cov-report=term-missing\n\n# Stop on first failure\npytest tests -x\n\n# Run a specific test file\npytest tests/test_data.py -v\n\n# Run a specific test function\npytest tests/test_data.py::test_upload_csv -v\n\n# Run tests matching a keyword\npytest tests -k \"analytics\" -v\n</code></pre>"},{"location":"development/testing/#writing-a-backend-test","title":"Writing a Backend Test","text":"<pre><code>\"\"\"Tests for the widgets service.\"\"\"\n\nimport pytest\n\nfrom app.services import widgets_service\n\n\nclass TestGetAllWidgets:\n    \"\"\"Tests for get_all_widgets().\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_returns_list(self):\n        \"\"\"Should return a list of widget dictionaries.\"\"\"\n        result = await widgets_service.get_all_widgets()\n        assert isinstance(result, list)\n\n    @pytest.mark.asyncio\n    async def test_empty_data(self):\n        \"\"\"Should return empty list when no data is loaded.\"\"\"\n        result = await widgets_service.get_all_widgets()\n        assert result == []\n\n\nclass TestGetWidgetSummary:\n    \"\"\"Tests for get_widget_summary().\"\"\"\n\n    @pytest.mark.asyncio\n    async def test_raises_on_empty_data(self):\n        \"\"\"Should raise ServiceError when no widgets exist.\"\"\"\n        with pytest.raises(widgets_service.WidgetsServiceError, match=\"No widget data\"):\n            await widgets_service.get_widget_summary()\n</code></pre>"},{"location":"development/testing/#fixtures","title":"Fixtures","text":"<p>Define shared fixtures in <code>tests/conftest.py</code>:</p> <pre><code>import pytest\n\n\n@pytest.fixture\ndef sample_widgets():\n    \"\"\"Sample widget data for testing.\"\"\"\n    return [\n        {\"id\": \"1\", \"name\": \"Widget A\", \"category\": \"tools\", \"value\": 0.85},\n        {\"id\": \"2\", \"name\": \"Widget B\", \"category\": \"tools\", \"value\": 0.72},\n        {\"id\": \"3\", \"name\": \"Widget C\", \"category\": \"utils\", \"value\": 0.91},\n    ]\n\n\n@pytest.fixture\ndef empty_widgets():\n    \"\"\"Empty widget list.\"\"\"\n    return []\n</code></pre>"},{"location":"development/testing/#async-test-pattern","title":"Async Test Pattern","text":"<p>All service functions in AXIS are <code>async</code>. Use the <code>@pytest.mark.asyncio</code> decorator:</p> <pre><code>@pytest.mark.asyncio\nasync def test_async_operation():\n    result = await some_service.do_something()\n    assert result is not None\n</code></pre>"},{"location":"development/testing/#frontend-unit-tests-vitest","title":"Frontend Unit Tests (Vitest)","text":""},{"location":"development/testing/#setup_1","title":"Setup","text":"<p>Frontend tests use Vitest with <code>@vitejs/plugin-react</code> for JSX support.</p> <p>Configuration is in <code>frontend/vitest.config.ts</code>:</p> <pre><code>import { defineConfig } from 'vitest/config';\nimport react from '@vitejs/plugin-react';\nimport path from 'path';\n\nexport default defineConfig({\n  plugins: [react()],\n  test: {\n    include: ['src/**/*.{test,spec}.{js,ts,jsx,tsx}'],\n    exclude: ['node_modules', 'e2e/**'],\n  },\n  resolve: {\n    alias: {\n      '@': path.resolve(__dirname, './src'),\n    },\n  },\n});\n</code></pre> <p>Key points:</p> <ul> <li>Tests live alongside source code in <code>src/</code> (not a separate directory)</li> <li>File pattern: <code>*.test.ts</code> or <code>*.spec.ts</code> (and <code>.tsx</code> variants)</li> <li>The <code>@/</code> alias works in tests, matching <code>tsconfig.json</code></li> <li>E2E tests in <code>e2e/</code> are excluded</li> </ul>"},{"location":"development/testing/#running-tests_1","title":"Running Tests","text":"<pre><code>cd frontend\n\n# Run all unit tests (watch mode)\nnpm run test\n\n# Run once (no watch -- used in CI and Makefile)\nnpm run test -- --run\n\n# Interactive UI\nnpm run test:ui\n\n# Run a specific file\nnpx vitest run src/lib/utils.test.ts\n\n# Run tests matching a pattern\nnpx vitest run --grep \"formatting\"\n</code></pre>"},{"location":"development/testing/#writing-a-frontend-test","title":"Writing a Frontend Test","text":"<pre><code>import { describe, it, expect } from 'vitest';\n\nimport { formatPercentage, cn } from '@/lib/utils';\n\ndescribe('formatPercentage', () =&gt; {\n  it('formats decimal as percentage string', () =&gt; {\n    expect(formatPercentage(0.856)).toBe('85.6%');\n  });\n\n  it('handles zero', () =&gt; {\n    expect(formatPercentage(0)).toBe('0.0%');\n  });\n\n  it('handles values above 1', () =&gt; {\n    expect(formatPercentage(1.5)).toBe('150.0%');\n  });\n});\n\ndescribe('cn', () =&gt; {\n  it('merges class names', () =&gt; {\n    expect(cn('foo', 'bar')).toBe('foo bar');\n  });\n\n  it('handles conditional classes', () =&gt; {\n    expect(cn('base', false &amp;&amp; 'hidden', 'visible')).toBe('base visible');\n  });\n});\n</code></pre>"},{"location":"development/testing/#testing-zustand-stores","title":"Testing Zustand Stores","text":"<pre><code>import { describe, it, expect, beforeEach } from 'vitest';\n\nimport { useWidgetsStore } from '@/stores/widgets-store';\n\ndescribe('useWidgetsStore', () =&gt; {\n  beforeEach(() =&gt; {\n    // Reset store between tests\n    useWidgetsStore.setState({\n      selectedCategory: null,\n      isDetailOpen: false,\n      selectedWidgetId: null,\n    });\n  });\n\n  it('sets selected category', () =&gt; {\n    useWidgetsStore.getState().setSelectedCategory('tools');\n    expect(useWidgetsStore.getState().selectedCategory).toBe('tools');\n  });\n\n  it('opens detail modal', () =&gt; {\n    useWidgetsStore.getState().openDetail('widget-123');\n    const state = useWidgetsStore.getState();\n    expect(state.isDetailOpen).toBe(true);\n    expect(state.selectedWidgetId).toBe('widget-123');\n  });\n\n  it('resets all state', () =&gt; {\n    useWidgetsStore.getState().setSelectedCategory('tools');\n    useWidgetsStore.getState().openDetail('widget-123');\n    useWidgetsStore.getState().reset();\n\n    const state = useWidgetsStore.getState();\n    expect(state.selectedCategory).toBeNull();\n    expect(state.isDetailOpen).toBe(false);\n    expect(state.selectedWidgetId).toBeNull();\n  });\n});\n</code></pre>"},{"location":"development/testing/#end-to-end-tests-playwright","title":"End-to-End Tests (Playwright)","text":""},{"location":"development/testing/#setup_2","title":"Setup","text":"<p>E2E tests use Playwright for browser automation.</p> <p>Configuration is in <code>frontend/playwright.config.ts</code>:</p> <pre><code>import { defineConfig } from '@playwright/test';\n\nexport default defineConfig({\n  testDir: './e2e',\n  testMatch: '**/*.spec.ts',\n  fullyParallel: true,\n  forbidOnly: !!process.env.CI,\n  retries: process.env.CI ? 2 : 0,\n  workers: process.env.CI ? 1 : undefined,\n  reporter: 'html',\n  use: {\n    baseURL: 'http://localhost:3500',\n    trace: 'on-first-retry',\n  },\n  webServer: {\n    command: 'npm run dev',\n    url: 'http://localhost:3500',\n    reuseExistingServer: !process.env.CI,\n  },\n});\n</code></pre> <p>Key points:</p> <ul> <li>Tests live in <code>frontend/e2e/</code></li> <li>Playwright auto-starts the dev server (unless one is already running)</li> <li>CI runs with 1 worker and 2 retries</li> <li>Traces are captured on first retry for debugging</li> </ul>"},{"location":"development/testing/#directory-structure_1","title":"Directory Structure","text":"<pre><code>frontend/\n\u251c\u2500\u2500 e2e/\n\u2502   \u251c\u2500\u2500 home.spec.ts          # Landing page tests\n\u2502   \u251c\u2500\u2500 evaluate.spec.ts      # Evaluation workflow tests\n\u2502   \u251c\u2500\u2500 monitoring.spec.ts    # Monitoring tests\n\u2502   \u2514\u2500\u2500 ...\n\u2514\u2500\u2500 playwright.config.ts\n</code></pre>"},{"location":"development/testing/#running-e2e-tests","title":"Running E2E Tests","text":"<pre><code>cd frontend\n\n# Run all E2E tests\nnpm run test:e2e\n\n# Run with headed browser (visible)\nnpx playwright test --headed\n\n# Run a specific spec file\nnpx playwright test e2e/home.spec.ts\n\n# Run in debug mode (step through)\nnpx playwright test --debug\n\n# View HTML report after run\nnpx playwright show-report\n</code></pre> <p>Or from the repo root:</p> <pre><code>make test-e2e\n</code></pre>"},{"location":"development/testing/#writing-an-e2e-test","title":"Writing an E2E Test","text":"<pre><code>import { test, expect } from '@playwright/test';\n\ntest.describe('Home Page', () =&gt; {\n  test('displays the AXIS landing page', async ({ page }) =&gt; {\n    await page.goto('/');\n    await expect(page.locator('h1')).toContainText('AXIS');\n  });\n\n  test('navigates to evaluation page', async ({ page }) =&gt; {\n    await page.goto('/');\n    await page.click('text=Evaluate');\n    await expect(page).toHaveURL(/\\/evaluate/);\n  });\n});\n\ntest.describe('Monitoring Upload', () =&gt; {\n  test('uploads a CSV file', async ({ page }) =&gt; {\n    await page.goto('/monitoring');\n    const fileInput = page.locator('input[type=\"file\"]');\n    await fileInput.setInputFiles('fixtures/sample-monitoring.csv');\n    await expect(page.locator('[data-testid=\"upload-success\"]')).toBeVisible();\n  });\n});\n</code></pre>"},{"location":"development/testing/#makefile-targets","title":"Makefile Targets","text":"<p>The root <code>Makefile</code> provides convenience targets that orchestrate testing across both services.</p> Target What it runs When to use <code>make test</code> <code>test-backend</code> + <code>test-frontend</code> Full test suite before merging <code>make test-backend</code> <code>cd backend &amp;&amp; pytest tests -v</code> After backend changes <code>make test-frontend</code> <code>cd frontend &amp;&amp; npm run test -- --run</code> After frontend changes <code>make test-e2e</code> <code>cd frontend &amp;&amp; npm run test:e2e</code> After UI/flow changes"},{"location":"development/testing/#ci-pipeline","title":"CI Pipeline","text":"<p>CI runs these checks in order:</p> <ol> <li><code>make lint</code> -- Ruff + ESLint + Prettier</li> <li><code>make typecheck</code> -- mypy + <code>tsc --noEmit</code></li> <li><code>make test</code> -- pytest + Vitest</li> <li>(optional) <code>make test-e2e</code> -- Playwright</li> </ol> <p>If any step fails, the pipeline stops. Run the full suite locally before pushing:</p> <pre><code>make lint &amp;&amp; make typecheck &amp;&amp; make test\n</code></pre>"},{"location":"development/testing/#coverage","title":"Coverage","text":""},{"location":"development/testing/#backend-coverage","title":"Backend Coverage","text":"<pre><code>cd backend\npytest tests --cov=app --cov-report=term-missing --cov-report=html\n</code></pre> <p>The HTML report is generated at <code>backend/htmlcov/index.html</code>.</p>"},{"location":"development/testing/#frontend-coverage","title":"Frontend Coverage","text":"<pre><code>cd frontend\nnpx vitest run --coverage\n</code></pre> <p>Info</p> <p>You may need to install <code>@vitest/coverage-v8</code> for coverage support: <pre><code>npm install -D @vitest/coverage-v8\n</code></pre></p>"},{"location":"development/testing/#related-pages","title":"Related Pages","text":"<ul> <li>Setup -- install test dependencies</li> <li>Code Conventions -- patterns to follow when writing tests</li> <li>Adding Features -- includes testing in the feature checklist</li> </ul>"},{"location":"getting-started/","title":"Getting Started","text":"<p>AXIS is a monorepo containing a Next.js 14 frontend and a FastAPI backend for AI evaluation dashboards. The two services communicate over HTTP and can run locally for development or be deployed as containers in production.</p>"},{"location":"getting-started/#local-development","title":"Local Development","text":"<p>For local development, both services run on your machine:</p> Service URL Port Frontend http://localhost:3500 3500 Backend http://localhost:8500 8500 API Docs http://localhost:8500/docs 8500"},{"location":"getting-started/#production-deployment","title":"Production Deployment","text":"<p>In production, AXIS runs as Docker containers behind a reverse proxy. The URLs are determined by your infrastructure:</p> Service Typical Setup Frontend <code>https://your-domain.com</code> (served by Next.js standalone) Backend <code>https://your-domain.com/api</code> or <code>https://api.your-domain.com</code> Database PostgreSQL + DuckDB (analytics cache) <p>See the Deployment guide for Docker Compose, container orchestration, reverse proxy setup, and the production checklist.</p>"},{"location":"getting-started/#next-steps","title":"Next Steps","text":"<ul> <li> <p> Installation</p> <p>Install prerequisites, clone the repo, and configure environment files for local development.</p> <p> Installation guide</p> </li> <li> <p> First Run</p> <p>Start the dev servers, load data, and explore the dashboard locally.</p> <p> First run guide</p> </li> <li> <p> Deploy</p> <p>Run AXIS in production with Docker, reverse proxy, and database configuration.</p> <p> Deployment guide</p> </li> </ul>"},{"location":"getting-started/first-run/","title":"First Run","text":"<p>With dependencies installed and environment files configured, you are ready to start the development servers and explore the dashboard.</p> <p>This page covers local development</p> <p>For production deployment with Docker and reverse proxy, see the Deployment guide.</p>"},{"location":"getting-started/first-run/#start-the-dev-servers","title":"Start the Dev Servers","text":""},{"location":"getting-started/first-run/#one-command-start-recommended","title":"One-command start (recommended)","text":"<p>From the repository root:</p> <pre><code>make dev\n</code></pre> <p>This launches both services concurrently:</p> <ul> <li>Backend at http://localhost:8500 (uvicorn with hot-reload)</li> <li>Frontend at http://localhost:3500 (Next.js dev server)</li> </ul>"},{"location":"getting-started/first-run/#manual-start","title":"Manual start","text":"<p>If you need to run the services in separate terminals:</p> BackendFrontend <pre><code>cd backend\nuvicorn app.main:app --reload --port 8500\n</code></pre> <pre><code>cd frontend\nnpm run dev\n</code></pre> <p>Tip</p> <p>Running in separate terminals is useful when you only need to restart one service, or when you want to isolate log output.</p>"},{"location":"getting-started/first-run/#open-the-dashboard","title":"Open the Dashboard","text":"<p>Navigate to http://localhost:3500 in your browser. You will see the AXIS landing page.</p>"},{"location":"getting-started/first-run/#load-data","title":"Load Data","text":"<p>AXIS needs evaluation data to display. You have two options on first launch:</p> Upload a CSVUse example data <p>Click Upload CSV on the landing page and select an evaluation results file. AXIS will parse the data and populate the dashboard automatically.</p> <p>Click one of the example dataset buttons to load sample data without uploading anything:</p> <ul> <li>Example Single Model -- loads a single-model evaluation dataset for exploring the Evaluate and Analytics tabs.</li> <li>Example Model Comparison -- loads a two-model dataset for exploring the Compare tab alongside Evaluate.</li> </ul> <p>No data required for all features</p> <p>Some features (Monitoring, Annotation, Simulation, Memory) have their own data pipelines and may require additional configuration. The example datasets are designed to get you started with core evaluation workflows.</p>"},{"location":"getting-started/first-run/#explore-the-interface","title":"Explore the Interface","text":"<p>Once data is loaded, use the top navigation to explore the main modules:</p> Tab What it does Evaluate Hierarchical metric tree, score distributions, and per-sample drill-down Analytics Eight chart types for slicing evaluation results across dimensions Compare Side-by-side model comparison with score deltas and metadata alignment"},{"location":"getting-started/first-run/#verify-the-backend-api","title":"Verify the Backend API","text":"<p>The backend serves interactive API documentation at:</p> <ul> <li>Swagger UI: http://localhost:8500/docs</li> <li>ReDoc: http://localhost:8500/redoc</li> </ul> <p>Use these to inspect available endpoints, test requests, and review response schemas.</p>"},{"location":"getting-started/first-run/#next-steps","title":"Next Steps","text":"<ul> <li>User Guide -- deep dives into each feature module (Evaluate, Monitoring, Compare, Annotation, and more).</li> <li>Configuration -- environment variables, YAML configs, data sources, and theming.</li> <li>Architecture -- how the frontend and backend are structured.</li> </ul>"},{"location":"getting-started/installation/","title":"Installation","text":"<p>This page covers prerequisites, dependency installation, and environment file setup for local development. For containerized deployment, see the Docker guide.</p>"},{"location":"getting-started/installation/#prerequisites","title":"Prerequisites","text":"Tool Version Purpose Node.js 20+ Frontend runtime Python 3.12+ Backend runtime npm (bundled with Node) Frontend package manager pip (bundled with Python) Backend package manager make any Task runner (Makefile) <p>Version check</p> <p>Verify your versions before proceeding:</p> <pre><code>node --version   # v20.x.x\npython --version # 3.12.x\nmake --version\n</code></pre>"},{"location":"getting-started/installation/#install-dependencies","title":"Install Dependencies","text":""},{"location":"getting-started/installation/#one-command-install-recommended","title":"One-command install (recommended)","text":"<p>From the repository root:</p> <pre><code>make install\n</code></pre> <p>This runs <code>pip install -e \".[dev,graph]\"</code> in <code>backend/</code> and <code>npm install</code> in <code>frontend/</code>, plus installs pre-commit hooks.</p>"},{"location":"getting-started/installation/#manual-install","title":"Manual install","text":"<p>If you prefer to install each service separately:</p> BackendFrontend <pre><code>cd backend\npip install -e .               # runtime only\npip install -e \".[dev]\"        # + linters &amp; tests\npip install -e \".[dev,graph]\"  # full development with graph features\n</code></pre> <pre><code>cd frontend\nnpm install\n</code></pre>"},{"location":"getting-started/installation/#environment-files","title":"Environment Files","text":"<p>AXIS uses <code>.env</code> files for configuration. These files are git-ignored and must be created manually.</p>"},{"location":"getting-started/installation/#backend-backendenv","title":"Backend: <code>backend/.env</code>","text":"<p>Create <code>backend/.env</code> with your server settings and optional API keys:</p> backend/.env<pre><code># Server (required)\nHOST=127.0.0.1\nPORT=8500\nDEBUG=true\nFRONTEND_URL=http://localhost:3500\n\n# AI / Copilot (optional)\nOPENAI_API_KEY=your_key_here\nANTHROPIC_API_KEY=your_key_here\nLLM_MODEL_NAME=gpt-4\n</code></pre> <p>Keep secrets out of version control</p> <p>Never commit <code>.env</code> files. The <code>.gitignore</code> already excludes them, but take care not to paste keys into tracked files.</p>"},{"location":"getting-started/installation/#frontend-frontendenvlocal","title":"Frontend: <code>frontend/.env.local</code>","text":"<p>Create <code>frontend/.env.local</code> with the backend URL:</p> frontend/.env.local<pre><code>NEXT_PUBLIC_API_URL=http://localhost:8500\n</code></pre> <p>Info</p> <p>Only <code>NEXT_PUBLIC_*</code> variables are exposed to the browser. Do not place secrets in this file.</p>"},{"location":"getting-started/installation/#docker-alternative","title":"Docker Alternative","text":"<p>If you prefer containers over a local install, use Docker Compose.</p>"},{"location":"getting-started/installation/#prerequisites_1","title":"Prerequisites","text":"<ul> <li>Docker Desktop</li> </ul>"},{"location":"getting-started/installation/#configuration","title":"Configuration","text":"<p>Create a root-level <code>.env</code> file. The <code>docker-compose.yml</code> passes this into the backend container:</p> .env (repo root)<pre><code>OPENAI_API_KEY=your_key\nANTHROPIC_API_KEY=your_key\nDB_PASSWORD=your_db_password\n# Optional: override local graph connection values\n# GRAPH_DB_HOST=falkordb\n# GRAPH_DB_PORT=6379\n</code></pre>"},{"location":"getting-started/installation/#run","title":"Run","text":"<pre><code>docker compose up --build\n</code></pre> <p>Frontend and backend start on the same ports (frontend on 3500, backend on 8500). The default Compose stack also starts a local FalkorDB container on port 6379 for graph features.</p>"},{"location":"getting-started/installation/#next-step","title":"Next Step","text":"<p>Once dependencies are installed and environment files are in place, proceed to the First Run guide.</p>"},{"location":"user-guide/","title":"User Guide","text":"<p>This guide covers the main features of AXIS and how to use them effectively.</p>"},{"location":"user-guide/#modules","title":"Modules","text":""},{"location":"user-guide/#evaluate","title":"Evaluate","text":"<p>Upload evaluation data, run batch evaluations with the Axion engine, and explore results through interactive tree visualizations and multi-chart analytics.</p> <p> Evaluate guide</p>"},{"location":"user-guide/#production","title":"Production","text":"<p>Executive overview combining Agent KPIs, AI quality monitoring, and human-in-the-loop signals in a single at-a-glance dashboard with sparkline trends.</p> <p> Production guide</p>"},{"location":"user-guide/#monitoring","title":"Monitoring","text":"<p>Deep-dive production observability \u2014 time-series score trends, metric breakdowns, latency distributions, classification analysis, and anomaly alerts.</p> <p> Monitoring guide</p>"},{"location":"user-guide/#annotation-studio","title":"Annotation Studio","text":"<p>Human-in-the-loop quality assessment with 3 annotation formats, tag-based critiques, keyboard shortcuts, and CSV export.</p> <p> Annotation Studio guide</p>"},{"location":"user-guide/#caliberhq","title":"CaliberHQ","text":"<p>LLM judge calibration with a 3-step workflow \u2014 annotate ground truth, configure the judge, and validate alignment with Cohen's Kappa, confusion matrices, EvidencePipeline-powered pattern discovery, and actionable learning insights.</p> <p> Calibration guide</p>"},{"location":"user-guide/#simulation","title":"Simulation","text":"<p>Synthetic persona-based agent testing with configurable personas, knowledge base upload, and conversation replay.</p> <p> Simulation guide</p>"},{"location":"user-guide/#memory","title":"Memory","text":"<p>Decision memory dashboard with rule extraction, hard stops, batch analysis, decision quality metrics, and knowledge graph visualization.</p> <p> Memory guide</p>"},{"location":"user-guide/#human-signals","title":"Human Signals","text":"<p>Data-driven HITL dashboard showing signal trends, classification distributions, case-level drill-down, and dynamic KPI strips.</p> <p> Human Signals guide</p>"},{"location":"user-guide/#agent-replay","title":"Agent Replay","text":"<p>Debug and review AI agent execution traces from Langfuse \u2014 step through observation trees, inspect inputs/outputs, and submit verdicts for continuous improvement.</p> <p> Agent Replay guide</p>"},{"location":"user-guide/#learn","title":"Learn","text":"<p>Interactive learning modules and guided tutorials for mastering AXIS features, evaluation methodology, and AI quality best practices.</p> <p> Learn guide</p>"},{"location":"user-guide/#settings","title":"Settings","text":"<p>System configuration, database connections, theme customization, and agent registry \u2014 all managed from a single page.</p> <p> Settings guide</p>"},{"location":"user-guide/#getting-data-in","title":"Getting Data In","text":"<p>AXIS supports two data ingestion paths:</p> <ol> <li>CSV Upload (default) \u2014 Drag and drop files through the UI</li> <li>Database Auto-Load \u2014 Configure PostgreSQL connections in YAML</li> </ol> <p>See Data Sources for setup details.</p>"},{"location":"user-guide/agent-replay/","title":"Agent Replay","text":"<p>Redirecting to the interactive Agent Replay guide...</p>"},{"location":"user-guide/annotation/","title":"Annotation Studio","text":"<p>Redirecting to the interactive Annotation guide...</p>"},{"location":"user-guide/calibration/","title":"CaliberHQ","text":"<p>Redirecting to the interactive CaliberHQ guide...</p>"},{"location":"user-guide/evaluate/","title":"Evaluate","text":"<p>Redirecting to the interactive Evaluate guide...</p>"},{"location":"user-guide/human-signals/","title":"Human Signals","text":"<p>Redirecting to the interactive Human Signals guide...</p>"},{"location":"user-guide/learn/","title":"Learn","text":"<p>Redirecting to the interactive Learn guide...</p>"},{"location":"user-guide/memory/","title":"Memory","text":"<p>Redirecting to the interactive Memory guide...</p>"},{"location":"user-guide/monitoring/","title":"Monitoring","text":"<p>Redirecting to the interactive Monitoring guide...</p>"},{"location":"user-guide/production/","title":"Production","text":"<p>Redirecting to the interactive Production guide...</p>"},{"location":"user-guide/settings/","title":"Settings","text":"<p>Redirecting to the interactive Settings guide...</p>"},{"location":"user-guide/simulation/","title":"Simulation","text":"<p>Redirecting to the interactive Simulation guide...</p>"}]}